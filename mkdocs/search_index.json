{
    "docs": [
        {
            "location": "/", 
            "text": "QuantEcon\n\n\nQuantEcon.jl\n is a \nJulia\n package for doing quantitative economics.\n\n\nThe library is split into two modules: \nQuantEcon\n and \nQuantEcon.Models\n. The main \nQuantEcon\n module includes various tools and the \nQuantEcon.Models\n module leverages these tools to provide implementations of standard economic models.\n\n\nMany of the concepts in the library are discussed in the lectures on the website \nquant-econ.net\n.\n\n\nFor a listing of the functions, methods, and types provided by the library see the \nOverview\n page.\n\n\nFor more detailed documentation of each object in each of the two modules \nAPI Docs/QuantEcon\n and \nAPI Docs/QuantEcon.Models\n pages.\n\n\nSome examples of usage can be found in the \nexamples directory\n or the listing of \nexercise solutions\n that accompany the lectures on \nquant-econ.net\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#quantecon", 
            "text": "QuantEcon.jl  is a  Julia  package for doing quantitative economics.  The library is split into two modules:  QuantEcon  and  QuantEcon.Models . The main  QuantEcon  module includes various tools and the  QuantEcon.Models  module leverages these tools to provide implementations of standard economic models.  Many of the concepts in the library are discussed in the lectures on the website  quant-econ.net .  For a listing of the functions, methods, and types provided by the library see the  Overview  page.  For more detailed documentation of each object in each of the two modules  API Docs/QuantEcon  and  API Docs/QuantEcon.Models  pages.  Some examples of usage can be found in the  examples directory  or the listing of  exercise solutions  that accompany the lectures on  quant-econ.net .", 
            "title": "QuantEcon"
        }, 
        {
            "location": "/api/", 
            "text": "API-INDEX\n\n\nMODULE: QuantEcon\n\n\n\n\nFunctions [Exported]\n\n\ndo_quad\n  Approximate the integral of \nf\n, given quadrature \nnodes\n and \nweights\n\n\necdf\n  Evaluate the empirical cdf at one or more points\n\n\ngth_solve\n  solve x(P-I)=0 using either an eigendecomposition, lu factorization, or an\n\n\nperiodogram\n  Computes the periodogram\n\n\nqnwbeta\n  Computes nodes and weights for beta distribution\n\n\nqnwcheb\n  Computes multivariate Guass-Checbychev quadrature nodes and weights.\n\n\nqnwequi\n  Generates equidistributed sequences with property that averages\n\n\nqnwgamma\n  Computes nodes and weights for beta distribution\n\n\nqnwlege\n  Computes multivariate Guass-Legendre  quadrature nodes and weights.\n\n\nqnwnorm\n  Computes nodes and weights for multivariate normal distribution\n\n\nqnwsimp\n  Computes multivariate Simpson quadrature nodes and weights.\n\n\nqnwtrap\n  Computes multivariate trapezoid quadrature nodes and weights.\n\n\nquadrect\n  Integrate the d-dimensional function f on a rectangle with lower and upper bound\n\n\n\n\nMethods [Exported]\n\n\nF_to_K(rlq::QuantEcon.RBLQ,  F::Array{T, 2})\n  Compute agent 2's best cost-minimizing response \nK\n, given \nF\n.\n\n\nK_to_F(rlq::QuantEcon.RBLQ,  K::Array{T, 2})\n  Compute agent 1's best cost-minimizing response \nK\n, given \nF\n.\n\n\nar_periodogram(x::Array{T, N})\n  Compute periodogram from data \nx\n, using prewhitening, smoothing and recoloring.\n\n\nar_periodogram(x::Array{T, N},  window::AbstractString)\n  Compute periodogram from data \nx\n, using prewhitening, smoothing and recoloring.\n\n\nar_periodogram(x::Array{T, N},  window::AbstractString,  window_len::Int64)\n  Compute periodogram from data \nx\n, using prewhitening, smoothing and recoloring.\n\n\nautocovariance(arma::QuantEcon.ARMA)\n  Compute the autocovariance function from the ARMA parameters\n\n\nb_operator(rlq::QuantEcon.RBLQ,  P::Array{T, 2})\n  The D operator, mapping P into\n\n\ncompute_deterministic_entropy(rlq::QuantEcon.RBLQ,  F,  K,  x0)\n  Given \nK\n and \nF\n, compute the value of deterministic entropy, which is sum_t\n\n\ncompute_fixed_point{TV}(T::Function,  v::TV)\n  Repeatedly apply a function to search for a fixed point\n\n\nd_operator(rlq::QuantEcon.RBLQ,  P::Array{T, 2})\n  The D operator, mapping P into\n\n\ndraw(d::QuantEcon.DiscreteRV{T\n:Real})\n  Make a single draw from the discrete distribution\n\n\ndraw{T}(d::QuantEcon.DiscreteRV{T},  k::Int64)\n  Make multiple draws from the discrete distribution represented by a\n\n\nevaluate_F(rlq::QuantEcon.RBLQ,  F::Array{T, 2})\n  Given a fixed policy \nF\n, with the interpretation u = -F x, this function\n\n\nimpulse_response(arma::QuantEcon.ARMA)\n  Get the impulse response corresponding to our model.\n\n\nlae_est{T}(l::QuantEcon.LAE,  y::AbstractArray{T, N})\n  A vectorized function that returns the value of the look ahead estimate at the\n\n\nm_quadratic_sum(A::Array{T, 2},  B::Array{T, 2})\n  Computes the quadratic sum\n\n\nmc_compute_stationary(mc::QuantEcon.MarkovChain)\n  calculate the stationary distributions associated with a N-state markov chain\n\n\nmc_sample_path!(mc::QuantEcon.MarkovChain,  samples::Array{T, N})\n  Fill \nsamples\n with samples from the Markov chain \nmc\n\n\nmc_sample_path(mc::QuantEcon.MarkovChain)\n  Simulate a Markov chain starting from an initial state\n\n\nmc_sample_path(mc::QuantEcon.MarkovChain,  init::Array{T, 1})\n  Simulate a Markov chain starting from an initial distribution\n\n\nmc_sample_path(mc::QuantEcon.MarkovChain,  init::Array{T, 1},  sample_size::Int64)\n  Simulate a Markov chain starting from an initial distribution\n\n\nmc_sample_path(mc::QuantEcon.MarkovChain,  init::Int64)\n  Simulate a Markov chain starting from an initial state\n\n\nmc_sample_path(mc::QuantEcon.MarkovChain,  init::Int64,  sample_size::Int64)\n  Simulate a Markov chain starting from an initial state\n\n\nnnash(a,  b1,  b2,  r1,  r2,  q1,  q2,  s1,  s2,  w1,  w2,  m1,  m2)\n  Compute the limit of a Nash linear quadratic dynamic game.\n\n\npdf(d::QuantEcon.BetaBinomial)\n  Evaluate the pdf of the distributions at the points 0, 1, ..., k\n\n\nqnwlogn(n,  mu,  sig2)\n  Computes quadrature nodes and weights for multivariate uniform distribution\n\n\nqnwunif(n,  a,  b)\n  Computes quadrature nodes and weights for multivariate uniform distribution\n\n\nrobust_rule(rlq::QuantEcon.RBLQ)\n  Solves the robust control problem.\n\n\nrobust_rule_simple(rlq::QuantEcon.RBLQ)\n  Solve the robust LQ problem\n\n\nrobust_rule_simple(rlq::QuantEcon.RBLQ,  P::Array{T, 2})\n  Solve the robust LQ problem\n\n\nrouwenhorst(N::Int64,  \u03c1::Real,  \u03c3::Real)\n  Rouwenhorst's method to approximate AR(1) processes.\n\n\nrouwenhorst(N::Int64,  \u03c1::Real,  \u03c3::Real,  \u03bc::Real)\n  Rouwenhorst's method to approximate AR(1) processes.\n\n\nsimulation(arma::QuantEcon.ARMA)\n  Compute a simulated sample path assuming Gaussian shocks.\n\n\nsmooth(x::Array{T, N})\n  Version of \nsmooth\n where \nwindow_len\n and \nwindow\n are keyword arguments\n\n\nsmooth(x::Array{T, N},  window_len::Int64)\n  Smooth the data in x using convolution with a window of requested size and type.\n\n\nsmooth(x::Array{T, N},  window_len::Int64,  window::AbstractString)\n  Smooth the data in x using convolution with a window of requested size and type.\n\n\nsolve_discrete_lyapunov(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}})\n  Solves the discrete lyapunov equation.\n\n\nsolve_discrete_lyapunov(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}},  max_it::Int64)\n  Solves the discrete lyapunov equation.\n\n\nsolve_discrete_riccati(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}},  Q::Union{T, Array{T, N}},  R::Union{T, Array{T, N}})\n  Solves the discrete-time algebraic Riccati equation\n\n\nsolve_discrete_riccati(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}},  Q::Union{T, Array{T, N}},  R::Union{T, Array{T, N}},  N::Union{T, Array{T, N}})\n  Solves the discrete-time algebraic Riccati equation\n\n\nspectral_density(arma::QuantEcon.ARMA)\n  Compute the spectral density function.\n\n\ntauchen(N::Int64,  \u03c1::Real,  \u03c3::Real)\n  Tauchen's (1996) method for approximating AR(1) process with finite markov chain\n\n\ntauchen(N::Int64,  \u03c1::Real,  \u03c3::Real,  \u03bc::Real)\n  Tauchen's (1996) method for approximating AR(1) process with finite markov chain\n\n\ntauchen(N::Int64,  \u03c1::Real,  \u03c3::Real,  \u03bc::Real,  n_std::Int64)\n  Tauchen's (1996) method for approximating AR(1) process with finite markov chain\n\n\nvar_quadratic_sum(A::Union{T, Array{T, N}},  C::Union{T, Array{T, N}},  H::Union{T, Array{T, N}},  bet::Real,  x0::Union{T, Array{T, N}})\n  Computes the expected discounted quadratic sum\n\n\n\n\nTypes [Exported]\n\n\nQuantEcon.ARMA\n  Represents a scalar ARMA(p, q) process\n\n\nQuantEcon.BetaBinomial\n  The Beta-Binomial distribution\n\n\nQuantEcon.DiscreteRV{T\n:Real}\n  Generates an array of draws from a discrete random variable with\n\n\nQuantEcon.ECDF\n  One-dimensional empirical distribution function given a vector of\n\n\nQuantEcon.LAE\n  A look ahead estimator associated with a given stochastic kernel p and a vector\n\n\nQuantEcon.MarkovChain\n  Finite-state discrete-time Markov chain.\n\n\nQuantEcon.RBLQ\n  Represents infinite horizon robust LQ control problems of the form\n\n\n\n\nFunctions [Internal]\n\n\neigen_solve\n  solve x(P-I)=0 using either an eigendecomposition, lu factorization, or an\n\n\nlu_solve\n  solve x(P-I)=0 using either an eigendecomposition, lu factorization, or an\n\n\n\n\nMethods [Internal]\n\n\nirreducible_subsets(mc::QuantEcon.MarkovChain)\n  Find the irreducible subsets of the \nMarkovChain\n\n\nn_states(mc::QuantEcon.MarkovChain)\n  Number of states in the markov chain \nmc\n\n\nMODULE: QuantEcon.Models\n\n\n\n\nFunctions [Exported]\n\n\nbellman_operator\n  Apply the Bellman operator for a given model and initial value\n\n\nbellman_operator!\n  Apply the Bellman operator for a given model and initial value\n\n\nget_greedy\n  Extract the greedy policy (policy function) of the model\n\n\nget_greedy!\n  Extract the greedy policy (policy function) of the model\n\n\n\n\nMethods [Exported]\n\n\nbellman_operator!(cp::QuantEcon.Models.CareerWorkerProblem,  v::Array{T, N},  out::Array{T, N})\n  Apply the Bellman operator for a given model and initial value\n\n\nbellman_operator!(cp::QuantEcon.Models.ConsumerProblem,  V::Array{T, 2},  out::Array{T, 2})\n  Apply the Bellman operator for a given model and initial value\n\n\nbellman_operator!(g::QuantEcon.Models.GrowthModel,  w::Array{T, 1},  out::Array{T, 1})\n  Apply the Bellman operator for a given model and initial value\n\n\nbellman_operator!(jv::QuantEcon.Models.JvWorker,  V::Array{T, 1},  out::Union{Tuple{Array{T, 1}, Array{T, 1}}, Array{T, 1}})\n  Apply the Bellman operator for a given model and initial value\n\n\nbellman_operator!(sp::QuantEcon.Models.SearchProblem,  v::Array{T, 2},  out::Array{T, 2})\n  Apply the Bellman operator for a given model and initial value\n\n\ncall_option(ap::QuantEcon.Models.AssetPrices,  zet::Real,  p_s::Real)\n  Computes price of a call option on a consol bond, both finite and infinite\n\n\ncall_option(ap::QuantEcon.Models.AssetPrices,  zet::Real,  p_s::Real,  T::Array{Int64, 1})\n  Computes price of a call option on a consol bond, both finite and infinite\n\n\ncall_option(ap::QuantEcon.Models.AssetPrices,  zet::Real,  p_s::Real,  T::Array{Int64, 1},  epsilon)\n  Computes price of a call option on a consol bond, both finite and infinite\n\n\ncoleman_operator!(cp::QuantEcon.Models.ConsumerProblem,  c::Array{T, 2},  out::Array{T, 2})\n  The approximate Coleman operator.\n\n\ncoleman_operator(cp::QuantEcon.Models.ConsumerProblem,  c::Array{T, 2})\n  Apply the Coleman operator for a given model and initial value\n\n\ncompute_lt_price(lt::QuantEcon.Models.LucasTree)\n  Compute the equilibrium price function associated with Lucas tree \nlt\n\n\nconsol_price(ap::QuantEcon.Models.AssetPrices,  zet::Real)\n  Computes price of a consol bond with payoff zeta\n\n\nget_greedy!(cp::QuantEcon.Models.CareerWorkerProblem,  v::Array{T, N},  out::Array{T, N})\n  Extract the greedy policy (policy function) of the model\n\n\nget_greedy!(cp::QuantEcon.Models.ConsumerProblem,  V::Array{T, 2},  out::Array{T, 2})\n  Extract the greedy policy (policy function) of the model\n\n\nget_greedy!(g::QuantEcon.Models.GrowthModel,  w::Array{T, 1},  out::Array{T, 1})\n  Extract the greedy policy (policy function) of the model\n\n\nget_greedy!(jv::QuantEcon.Models.JvWorker,  V::Array{T, 1},  out::Tuple{Array{T, 1}, Array{T, 1}})\n  Extract the greedy policy (policy function) of the model\n\n\nget_greedy!(sp::QuantEcon.Models.SearchProblem,  v::Array{T, 2},  out::Array{T, 2})\n  Extract the greedy policy (policy function) of the model\n\n\nlucas_operator(lt::QuantEcon.Models.LucasTree,  f::AbstractArray{T, 1})\n  The approximate Lucas operator, which computes and returns the updated function\n\n\nres_wage_operator!(sp::QuantEcon.Models.SearchProblem,  phi::Array{T, 1},  out::Array{T, 1})\n  Updates the reservation wage function guess phi via the operator Q.\n\n\nres_wage_operator(sp::QuantEcon.Models.SearchProblem,  phi::Array{T, 1})\n  Updates the reservation wage function guess phi via the operator Q.\n\n\ntree_price(ap::QuantEcon.Models.AssetPrices)\n  Computes the function v such that the price of the lucas tree is v(lambda)C_t\n\n\n\n\nTypes [Exported]\n\n\nQuantEcon.Models.AssetPrices\n  A class to compute asset prices when the endowment follows a finite Markov chain\n\n\nQuantEcon.Models.CareerWorkerProblem\n  Career/job choice model fo Derek Neal (1999)\n\n\nQuantEcon.Models.ConsumerProblem\n  Income fluctuation problem\n\n\nQuantEcon.Models.GrowthModel\n  Neoclassical growth model\n\n\nQuantEcon.Models.JvWorker\n  A Jovanovic-type model of employment with on-the-job search.\n\n\nQuantEcon.Models.LucasTree\n  The Lucas asset pricing model\n\n\nQuantEcon.Models.SearchProblem\n  Unemployment/search problem where offer distribution is unknown\n\n\n\n\nMethods [Internal]\n\n\ncall(::Type{QuantEcon.Models.AssetPrices},  bet::Real,  P::Array{T, 2},  s::Array{T, 1},  gamm::Real)\n  Construct an instance of \nAssetPrices\n, where \nn\n, \nP_tilde\n, and \nP_check\n are\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real)\n  Constructor with default values for \nCareerWorkerProblem\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real)\n  Constructor with default values for \nCareerWorkerProblem\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real)\n  Constructor with default values for \nCareerWorkerProblem\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real)\n  Constructor with default values for \nCareerWorkerProblem\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real,  F_b::Real)\n  Constructor with default values for \nCareerWorkerProblem\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real,  F_b::Real,  G_a::Real)\n  Constructor with default values for \nCareerWorkerProblem\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real,  F_b::Real,  G_a::Real,  G_b::Real)\n  Constructor with default values for \nCareerWorkerProblem\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r)\n  Constructor with default values for \nConsumerProblem\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet)\n  Constructor with default values for \nConsumerProblem\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi)\n  Constructor with default values for \nConsumerProblem\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals)\n  Constructor with default values for \nConsumerProblem\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b)\n  Constructor with default values for \nConsumerProblem\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max)\n  Constructor with default values for \nConsumerProblem\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max,  grid_size)\n  Constructor with default values for \nConsumerProblem\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max,  grid_size,  u)\n  Constructor with default values for \nConsumerProblem\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max,  grid_size,  u,  du)\n  Constructor with default values for \nConsumerProblem\n\n\ncall(::Type{QuantEcon.Models.GrowthModel})\n  Constructor of \nGrowthModel\n\n\ncall(::Type{QuantEcon.Models.GrowthModel},  f)\n  Constructor of \nGrowthModel\n\n\ncall(::Type{QuantEcon.Models.GrowthModel},  f,  bet)\n  Constructor of \nGrowthModel\n\n\ncall(::Type{QuantEcon.Models.GrowthModel},  f,  bet,  u)\n  Constructor of \nGrowthModel\n\n\ncall(::Type{QuantEcon.Models.GrowthModel},  f,  bet,  u,  grid_max)\n  Constructor of \nGrowthModel\n\n\ncall(::Type{QuantEcon.Models.GrowthModel},  f,  bet,  u,  grid_max,  grid_size)\n  Constructor of \nGrowthModel\n\n\ncall(::Type{QuantEcon.Models.JvWorker},  A)\n  Constructor with default values for \nJvWorker\n\n\ncall(::Type{QuantEcon.Models.JvWorker},  A,  alpha)\n  Constructor with default values for \nJvWorker\n\n\ncall(::Type{QuantEcon.Models.JvWorker},  A,  alpha,  bet)\n  Constructor with default values for \nJvWorker\n\n\ncall(::Type{QuantEcon.Models.JvWorker},  A,  alpha,  bet,  grid_size)\n  Constructor with default values for \nJvWorker\n\n\ncall(::Type{QuantEcon.Models.LucasTree},  gam::Real,  bet::Real,  alpha::Real,  sigma::Real)\n  Constructor for LucasTree\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet)\n  Constructor for \nSearchProblem\n with default values\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c)\n  Constructor for \nSearchProblem\n with default values\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a)\n  Constructor for \nSearchProblem\n with default values\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b)\n  Constructor for \nSearchProblem\n with default values\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a)\n  Constructor for \nSearchProblem\n with default values\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b)\n  Constructor for \nSearchProblem\n with default values\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b,  w_max)\n  Constructor for \nSearchProblem\n with default values\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b,  w_max,  w_grid_size)\n  Constructor for \nSearchProblem\n with default values\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b,  w_max,  w_grid_size,  pi_grid_size)\n  Constructor for \nSearchProblem\n with default values\n\n\ndefault_du{T\n:Real}(x::T\n:Real)\n  Marginal utility for log utility function", 
            "title": "Overview"
        }, 
        {
            "location": "/api/#api-index", 
            "text": "", 
            "title": "API-INDEX"
        }, 
        {
            "location": "/api/#module-quantecon", 
            "text": "", 
            "title": "MODULE: QuantEcon"
        }, 
        {
            "location": "/api/#functions-exported", 
            "text": "do_quad   Approximate the integral of  f , given quadrature  nodes  and  weights  ecdf   Evaluate the empirical cdf at one or more points  gth_solve   solve x(P-I)=0 using either an eigendecomposition, lu factorization, or an  periodogram   Computes the periodogram  qnwbeta   Computes nodes and weights for beta distribution  qnwcheb   Computes multivariate Guass-Checbychev quadrature nodes and weights.  qnwequi   Generates equidistributed sequences with property that averages  qnwgamma   Computes nodes and weights for beta distribution  qnwlege   Computes multivariate Guass-Legendre  quadrature nodes and weights.  qnwnorm   Computes nodes and weights for multivariate normal distribution  qnwsimp   Computes multivariate Simpson quadrature nodes and weights.  qnwtrap   Computes multivariate trapezoid quadrature nodes and weights.  quadrect   Integrate the d-dimensional function f on a rectangle with lower and upper bound", 
            "title": "Functions [Exported]"
        }, 
        {
            "location": "/api/#methods-exported", 
            "text": "F_to_K(rlq::QuantEcon.RBLQ,  F::Array{T, 2})   Compute agent 2's best cost-minimizing response  K , given  F .  K_to_F(rlq::QuantEcon.RBLQ,  K::Array{T, 2})   Compute agent 1's best cost-minimizing response  K , given  F .  ar_periodogram(x::Array{T, N})   Compute periodogram from data  x , using prewhitening, smoothing and recoloring.  ar_periodogram(x::Array{T, N},  window::AbstractString)   Compute periodogram from data  x , using prewhitening, smoothing and recoloring.  ar_periodogram(x::Array{T, N},  window::AbstractString,  window_len::Int64)   Compute periodogram from data  x , using prewhitening, smoothing and recoloring.  autocovariance(arma::QuantEcon.ARMA)   Compute the autocovariance function from the ARMA parameters  b_operator(rlq::QuantEcon.RBLQ,  P::Array{T, 2})   The D operator, mapping P into  compute_deterministic_entropy(rlq::QuantEcon.RBLQ,  F,  K,  x0)   Given  K  and  F , compute the value of deterministic entropy, which is sum_t  compute_fixed_point{TV}(T::Function,  v::TV)   Repeatedly apply a function to search for a fixed point  d_operator(rlq::QuantEcon.RBLQ,  P::Array{T, 2})   The D operator, mapping P into  draw(d::QuantEcon.DiscreteRV{T :Real})   Make a single draw from the discrete distribution  draw{T}(d::QuantEcon.DiscreteRV{T},  k::Int64)   Make multiple draws from the discrete distribution represented by a  evaluate_F(rlq::QuantEcon.RBLQ,  F::Array{T, 2})   Given a fixed policy  F , with the interpretation u = -F x, this function  impulse_response(arma::QuantEcon.ARMA)   Get the impulse response corresponding to our model.  lae_est{T}(l::QuantEcon.LAE,  y::AbstractArray{T, N})   A vectorized function that returns the value of the look ahead estimate at the  m_quadratic_sum(A::Array{T, 2},  B::Array{T, 2})   Computes the quadratic sum  mc_compute_stationary(mc::QuantEcon.MarkovChain)   calculate the stationary distributions associated with a N-state markov chain  mc_sample_path!(mc::QuantEcon.MarkovChain,  samples::Array{T, N})   Fill  samples  with samples from the Markov chain  mc  mc_sample_path(mc::QuantEcon.MarkovChain)   Simulate a Markov chain starting from an initial state  mc_sample_path(mc::QuantEcon.MarkovChain,  init::Array{T, 1})   Simulate a Markov chain starting from an initial distribution  mc_sample_path(mc::QuantEcon.MarkovChain,  init::Array{T, 1},  sample_size::Int64)   Simulate a Markov chain starting from an initial distribution  mc_sample_path(mc::QuantEcon.MarkovChain,  init::Int64)   Simulate a Markov chain starting from an initial state  mc_sample_path(mc::QuantEcon.MarkovChain,  init::Int64,  sample_size::Int64)   Simulate a Markov chain starting from an initial state  nnash(a,  b1,  b2,  r1,  r2,  q1,  q2,  s1,  s2,  w1,  w2,  m1,  m2)   Compute the limit of a Nash linear quadratic dynamic game.  pdf(d::QuantEcon.BetaBinomial)   Evaluate the pdf of the distributions at the points 0, 1, ..., k  qnwlogn(n,  mu,  sig2)   Computes quadrature nodes and weights for multivariate uniform distribution  qnwunif(n,  a,  b)   Computes quadrature nodes and weights for multivariate uniform distribution  robust_rule(rlq::QuantEcon.RBLQ)   Solves the robust control problem.  robust_rule_simple(rlq::QuantEcon.RBLQ)   Solve the robust LQ problem  robust_rule_simple(rlq::QuantEcon.RBLQ,  P::Array{T, 2})   Solve the robust LQ problem  rouwenhorst(N::Int64,  \u03c1::Real,  \u03c3::Real)   Rouwenhorst's method to approximate AR(1) processes.  rouwenhorst(N::Int64,  \u03c1::Real,  \u03c3::Real,  \u03bc::Real)   Rouwenhorst's method to approximate AR(1) processes.  simulation(arma::QuantEcon.ARMA)   Compute a simulated sample path assuming Gaussian shocks.  smooth(x::Array{T, N})   Version of  smooth  where  window_len  and  window  are keyword arguments  smooth(x::Array{T, N},  window_len::Int64)   Smooth the data in x using convolution with a window of requested size and type.  smooth(x::Array{T, N},  window_len::Int64,  window::AbstractString)   Smooth the data in x using convolution with a window of requested size and type.  solve_discrete_lyapunov(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}})   Solves the discrete lyapunov equation.  solve_discrete_lyapunov(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}},  max_it::Int64)   Solves the discrete lyapunov equation.  solve_discrete_riccati(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}},  Q::Union{T, Array{T, N}},  R::Union{T, Array{T, N}})   Solves the discrete-time algebraic Riccati equation  solve_discrete_riccati(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}},  Q::Union{T, Array{T, N}},  R::Union{T, Array{T, N}},  N::Union{T, Array{T, N}})   Solves the discrete-time algebraic Riccati equation  spectral_density(arma::QuantEcon.ARMA)   Compute the spectral density function.  tauchen(N::Int64,  \u03c1::Real,  \u03c3::Real)   Tauchen's (1996) method for approximating AR(1) process with finite markov chain  tauchen(N::Int64,  \u03c1::Real,  \u03c3::Real,  \u03bc::Real)   Tauchen's (1996) method for approximating AR(1) process with finite markov chain  tauchen(N::Int64,  \u03c1::Real,  \u03c3::Real,  \u03bc::Real,  n_std::Int64)   Tauchen's (1996) method for approximating AR(1) process with finite markov chain  var_quadratic_sum(A::Union{T, Array{T, N}},  C::Union{T, Array{T, N}},  H::Union{T, Array{T, N}},  bet::Real,  x0::Union{T, Array{T, N}})   Computes the expected discounted quadratic sum", 
            "title": "Methods [Exported]"
        }, 
        {
            "location": "/api/#types-exported", 
            "text": "QuantEcon.ARMA   Represents a scalar ARMA(p, q) process  QuantEcon.BetaBinomial   The Beta-Binomial distribution  QuantEcon.DiscreteRV{T :Real}   Generates an array of draws from a discrete random variable with  QuantEcon.ECDF   One-dimensional empirical distribution function given a vector of  QuantEcon.LAE   A look ahead estimator associated with a given stochastic kernel p and a vector  QuantEcon.MarkovChain   Finite-state discrete-time Markov chain.  QuantEcon.RBLQ   Represents infinite horizon robust LQ control problems of the form", 
            "title": "Types [Exported]"
        }, 
        {
            "location": "/api/#functions-internal", 
            "text": "eigen_solve   solve x(P-I)=0 using either an eigendecomposition, lu factorization, or an  lu_solve   solve x(P-I)=0 using either an eigendecomposition, lu factorization, or an", 
            "title": "Functions [Internal]"
        }, 
        {
            "location": "/api/#methods-internal", 
            "text": "irreducible_subsets(mc::QuantEcon.MarkovChain)   Find the irreducible subsets of the  MarkovChain  n_states(mc::QuantEcon.MarkovChain)   Number of states in the markov chain  mc", 
            "title": "Methods [Internal]"
        }, 
        {
            "location": "/api/#module-quanteconmodels", 
            "text": "", 
            "title": "MODULE: QuantEcon.Models"
        }, 
        {
            "location": "/api/#functions-exported_1", 
            "text": "bellman_operator   Apply the Bellman operator for a given model and initial value  bellman_operator!   Apply the Bellman operator for a given model and initial value  get_greedy   Extract the greedy policy (policy function) of the model  get_greedy!   Extract the greedy policy (policy function) of the model", 
            "title": "Functions [Exported]"
        }, 
        {
            "location": "/api/#methods-exported_1", 
            "text": "bellman_operator!(cp::QuantEcon.Models.CareerWorkerProblem,  v::Array{T, N},  out::Array{T, N})   Apply the Bellman operator for a given model and initial value  bellman_operator!(cp::QuantEcon.Models.ConsumerProblem,  V::Array{T, 2},  out::Array{T, 2})   Apply the Bellman operator for a given model and initial value  bellman_operator!(g::QuantEcon.Models.GrowthModel,  w::Array{T, 1},  out::Array{T, 1})   Apply the Bellman operator for a given model and initial value  bellman_operator!(jv::QuantEcon.Models.JvWorker,  V::Array{T, 1},  out::Union{Tuple{Array{T, 1}, Array{T, 1}}, Array{T, 1}})   Apply the Bellman operator for a given model and initial value  bellman_operator!(sp::QuantEcon.Models.SearchProblem,  v::Array{T, 2},  out::Array{T, 2})   Apply the Bellman operator for a given model and initial value  call_option(ap::QuantEcon.Models.AssetPrices,  zet::Real,  p_s::Real)   Computes price of a call option on a consol bond, both finite and infinite  call_option(ap::QuantEcon.Models.AssetPrices,  zet::Real,  p_s::Real,  T::Array{Int64, 1})   Computes price of a call option on a consol bond, both finite and infinite  call_option(ap::QuantEcon.Models.AssetPrices,  zet::Real,  p_s::Real,  T::Array{Int64, 1},  epsilon)   Computes price of a call option on a consol bond, both finite and infinite  coleman_operator!(cp::QuantEcon.Models.ConsumerProblem,  c::Array{T, 2},  out::Array{T, 2})   The approximate Coleman operator.  coleman_operator(cp::QuantEcon.Models.ConsumerProblem,  c::Array{T, 2})   Apply the Coleman operator for a given model and initial value  compute_lt_price(lt::QuantEcon.Models.LucasTree)   Compute the equilibrium price function associated with Lucas tree  lt  consol_price(ap::QuantEcon.Models.AssetPrices,  zet::Real)   Computes price of a consol bond with payoff zeta  get_greedy!(cp::QuantEcon.Models.CareerWorkerProblem,  v::Array{T, N},  out::Array{T, N})   Extract the greedy policy (policy function) of the model  get_greedy!(cp::QuantEcon.Models.ConsumerProblem,  V::Array{T, 2},  out::Array{T, 2})   Extract the greedy policy (policy function) of the model  get_greedy!(g::QuantEcon.Models.GrowthModel,  w::Array{T, 1},  out::Array{T, 1})   Extract the greedy policy (policy function) of the model  get_greedy!(jv::QuantEcon.Models.JvWorker,  V::Array{T, 1},  out::Tuple{Array{T, 1}, Array{T, 1}})   Extract the greedy policy (policy function) of the model  get_greedy!(sp::QuantEcon.Models.SearchProblem,  v::Array{T, 2},  out::Array{T, 2})   Extract the greedy policy (policy function) of the model  lucas_operator(lt::QuantEcon.Models.LucasTree,  f::AbstractArray{T, 1})   The approximate Lucas operator, which computes and returns the updated function  res_wage_operator!(sp::QuantEcon.Models.SearchProblem,  phi::Array{T, 1},  out::Array{T, 1})   Updates the reservation wage function guess phi via the operator Q.  res_wage_operator(sp::QuantEcon.Models.SearchProblem,  phi::Array{T, 1})   Updates the reservation wage function guess phi via the operator Q.  tree_price(ap::QuantEcon.Models.AssetPrices)   Computes the function v such that the price of the lucas tree is v(lambda)C_t", 
            "title": "Methods [Exported]"
        }, 
        {
            "location": "/api/#types-exported_1", 
            "text": "QuantEcon.Models.AssetPrices   A class to compute asset prices when the endowment follows a finite Markov chain  QuantEcon.Models.CareerWorkerProblem   Career/job choice model fo Derek Neal (1999)  QuantEcon.Models.ConsumerProblem   Income fluctuation problem  QuantEcon.Models.GrowthModel   Neoclassical growth model  QuantEcon.Models.JvWorker   A Jovanovic-type model of employment with on-the-job search.  QuantEcon.Models.LucasTree   The Lucas asset pricing model  QuantEcon.Models.SearchProblem   Unemployment/search problem where offer distribution is unknown", 
            "title": "Types [Exported]"
        }, 
        {
            "location": "/api/#methods-internal_1", 
            "text": "call(::Type{QuantEcon.Models.AssetPrices},  bet::Real,  P::Array{T, 2},  s::Array{T, 1},  gamm::Real)   Construct an instance of  AssetPrices , where  n ,  P_tilde , and  P_check  are  call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real)   Constructor with default values for  CareerWorkerProblem  call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real)   Constructor with default values for  CareerWorkerProblem  call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real)   Constructor with default values for  CareerWorkerProblem  call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real)   Constructor with default values for  CareerWorkerProblem  call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real,  F_b::Real)   Constructor with default values for  CareerWorkerProblem  call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real,  F_b::Real,  G_a::Real)   Constructor with default values for  CareerWorkerProblem  call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real,  F_b::Real,  G_a::Real,  G_b::Real)   Constructor with default values for  CareerWorkerProblem  call(::Type{QuantEcon.Models.ConsumerProblem},  r)   Constructor with default values for  ConsumerProblem  call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet)   Constructor with default values for  ConsumerProblem  call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi)   Constructor with default values for  ConsumerProblem  call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals)   Constructor with default values for  ConsumerProblem  call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b)   Constructor with default values for  ConsumerProblem  call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max)   Constructor with default values for  ConsumerProblem  call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max,  grid_size)   Constructor with default values for  ConsumerProblem  call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max,  grid_size,  u)   Constructor with default values for  ConsumerProblem  call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max,  grid_size,  u,  du)   Constructor with default values for  ConsumerProblem  call(::Type{QuantEcon.Models.GrowthModel})   Constructor of  GrowthModel  call(::Type{QuantEcon.Models.GrowthModel},  f)   Constructor of  GrowthModel  call(::Type{QuantEcon.Models.GrowthModel},  f,  bet)   Constructor of  GrowthModel  call(::Type{QuantEcon.Models.GrowthModel},  f,  bet,  u)   Constructor of  GrowthModel  call(::Type{QuantEcon.Models.GrowthModel},  f,  bet,  u,  grid_max)   Constructor of  GrowthModel  call(::Type{QuantEcon.Models.GrowthModel},  f,  bet,  u,  grid_max,  grid_size)   Constructor of  GrowthModel  call(::Type{QuantEcon.Models.JvWorker},  A)   Constructor with default values for  JvWorker  call(::Type{QuantEcon.Models.JvWorker},  A,  alpha)   Constructor with default values for  JvWorker  call(::Type{QuantEcon.Models.JvWorker},  A,  alpha,  bet)   Constructor with default values for  JvWorker  call(::Type{QuantEcon.Models.JvWorker},  A,  alpha,  bet,  grid_size)   Constructor with default values for  JvWorker  call(::Type{QuantEcon.Models.LucasTree},  gam::Real,  bet::Real,  alpha::Real,  sigma::Real)   Constructor for LucasTree  call(::Type{QuantEcon.Models.SearchProblem},  bet)   Constructor for  SearchProblem  with default values  call(::Type{QuantEcon.Models.SearchProblem},  bet,  c)   Constructor for  SearchProblem  with default values  call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a)   Constructor for  SearchProblem  with default values  call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b)   Constructor for  SearchProblem  with default values  call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a)   Constructor for  SearchProblem  with default values  call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b)   Constructor for  SearchProblem  with default values  call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b,  w_max)   Constructor for  SearchProblem  with default values  call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b,  w_max,  w_grid_size)   Constructor for  SearchProblem  with default values  call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b,  w_max,  w_grid_size,  pi_grid_size)   Constructor for  SearchProblem  with default values  default_du{T :Real}(x::T :Real)   Marginal utility for log utility function", 
            "title": "Methods [Internal]"
        }, 
        {
            "location": "/api/QuantEcon/", 
            "text": "QuantEcon\n\n\nExported\n\n\n\n\n\n\ndo_quad \n\u00b6\n\n\nApproximate the integral of \nf\n, given quadrature \nnodes\n and \nweights\n\n\nArguments\n\n\n\n\nf::Function\n: A callable function that is to be approximated over the domain\nspanned by \nnodes\n.\n\n\nnodes::Array\n: Quadrature nodes\n\n\nweights::Array\n: Quadrature nodes\n\n\n;args...\n: additional positional arguments to pass to \nf\n\n\n;kwargs...\n: additional keyword arguments to pass to \nf\n\n\n\n\nReturns\n\n\n\n\nout::Float64\n : The scalar that approximates integral of \nf\n on the hypercube\nformed by \n[a, b]\n\n\n\n\nsource:\n\n\nQuantEcon/src/quad.jl:811\n\n\n\n\n\n\necdf \n\u00b6\n\n\nEvaluate the empirical cdf at one or more points\n\n\nArguments\n\n\n\n\ne::ECDF\n: The \nECDF\n instance\n\n\nx::Union{Real, Array}\n: The point(s) at which to evaluate the ECDF\n\n\n\n\nsource:\n\n\nQuantEcon/src/ecdf.jl:35\n\n\n\n\n\n\ngth_solve \n\u00b6\n\n\nsolve x(P-I)=0 using either an eigendecomposition, lu factorization, or an\nalgorithm presented by Grassmann-Taksar-Heyman (GTH)\n\n\nArguments\n\n\n\n\np::Matrix\n : valid stochastic matrix\n\n\n\n\nReturns\n\n\n\n\nx::Matrix\n: A matrix whose columns contain stationary vectors of \np\n\n\n\n\nReferences\n\n\nThe following references were consulted for the GTH algorithm\n\n\n\n\nW. K. Grassmann, M. I. Taksar and D. P. Heyman, \"Regenerative Analysis and\nSteady State Distributions for Markov Chains,\" Operations Research (1985),\n1107-1116.\n\n\nW. J. Stewart, Probability, Markov Chains, Queues, and Simulation, Princeton\nUniversity Press, 2009.\n\n\n\n\nsource:\n\n\nQuantEcon/src/mc_tools.jl:139\n\n\n\n\n\n\nperiodogram \n\u00b6\n\n\nComputes the periodogram\n\n\nI(w) = (1 / n) | sum_{t=0}^{n-1} x_t e^{itw} |^2\n\n\n\nat the Fourier frequences w_j := 2 pi j / n, j = 0, ..., n - 1, using the fast\nFourier transform.  Only the frequences w_j in [0, pi] and corresponding values\nI(w_j) are returned.  If a window type is given then smoothing is performed.\n\n\nArguments\n\n\n\n\nx::Array\n: An array containing the data to smooth\n\n\nwindow_len::Int(7)\n: An odd integer giving the length of the window\n\n\nwindow::String(\"hanning\")\n: A string giving the window type. Possible values\nare \nflat\n, \nhanning\n, \nhamming\n, \nbartlett\n, or \nblackman\n\n\n\n\nReturns\n\n\n\n\nw::Array{Float64}\n: Fourier frequencies at which the periodogram is evaluated\n\n\nI_w::Array{Float64}\n: The periodogram at frequences \nw\n\n\n\n\nsource:\n\n\nQuantEcon/src/estspec.jl:115\n\n\n\n\n\n\nqnwbeta \n\u00b6\n\n\nComputes nodes and weights for beta distribution\n\n\nArguments\n\n\n\n\nn::Union(Int, Vector{Int})\n : Number of desired nodes along each dimension\n\n\na::Union(Real, Vector{Real})\n : First parameter of the beta distribution,\nalong each dimension\n\n\nb::Union(Real, Vector{Real})\n : Second parameter of the beta distribution,\nalong each dimension\n\n\n\n\nReturns\n\n\n\n\nnodes::Array{Float64}\n : An array of quadrature nodes\n\n\nweights::Array{Float64}\n : An array of corresponding quadrature weights\n\n\n\n\nNotes\n\n\nIf any of the parameters to this function are scalars while others are\n\nVector\ns of length \nn\n, the the scalar parameter is repeated \nn\n times.\n\n\nReferences\n\n\nMiranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.\n\n\nsource:\n\n\nQuantEcon/src/quad.jl:354\n\n\n\n\n\n\nqnwcheb \n\u00b6\n\n\nComputes multivariate Guass-Checbychev quadrature nodes and weights.\n\n\nArguments\n\n\n\n\nn::Union(Int, Vector{Int})\n : Number of desired nodes along each dimension\n\n\na::Union(Real, Vector{Real})\n : Lower endpoint along each dimension\n\n\nb::Union(Real, Vector{Real})\n : Upper endpoint along each dimension\n\n\n\n\nReturns\n\n\n\n\nnodes::Array{Float64}\n : An array of quadrature nodes\n\n\nweights::Array{Float64}\n : An array of corresponding quadrature weights\n\n\n\n\nNotes\n\n\nIf any of the parameters to this function are scalars while others are\n\nVector\ns of length \nn\n, the the scalar parameter is repeated \nn\n times.\n\n\nReferences\n\n\nMiranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.\n\n\nsource:\n\n\nQuantEcon/src/quad.jl:167\n\n\n\n\n\n\nqnwequi \n\u00b6\n\n\nGenerates equidistributed sequences with property that averages\nvalue of integrable function evaluated over the sequence converges\nto the integral as n goes to infinity.\n\n\nArguments\n\n\n\n\nn::Union(Int, Vector{Int})\n : Number of desired nodes along each dimension\n\n\na::Union(Real, Vector{Real})\n : Lower endpoint along each dimension\n\n\nb::Union(Real, Vector{Real})\n : Upper endpoint along each dimension\n\n\nkind::String(\"N\")\n: One of the following:\n\n\nN - Neiderreiter (default)\n\n\nW - Weyl\n\n\nH - Haber\n\n\nR - pseudo Random\n\n\n\n\n\n\n\n\nReturns\n\n\n\n\nnodes::Array{Float64}\n : An array of quadrature nodes\n\n\nweights::Array{Float64}\n : An array of corresponding quadrature weights\n\n\n\n\nNotes\n\n\nIf any of the parameters to this function are scalars while others are\n\nVector\ns of length \nn\n, the the scalar parameter is repeated \nn\n times.\n\n\nReferences\n\n\nMiranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.\n\n\nsource:\n\n\nQuantEcon/src/quad.jl:726\n\n\n\n\n\n\nqnwgamma \n\u00b6\n\n\nComputes nodes and weights for beta distribution\n\n\nArguments\n\n\n\n\nn::Union(Int, Vector{Int})\n : Number of desired nodes along each dimension\n\n\na::Union(Real, Vector{Real})\n : First parameter of the gamma distribution,\nalong each dimension\n\n\nb::Union(Real, Vector{Real})\n : Second parameter of the gamma distribution,\nalong each dimension\n\n\n\n\nReturns\n\n\n\n\nnodes::Array{Float64}\n : An array of quadrature nodes\n\n\nweights::Array{Float64}\n : An array of corresponding quadrature weights\n\n\n\n\nNotes\n\n\nIf any of the parameters to this function are scalars while others are\n\nVector\ns of length \nn\n, the the scalar parameter is repeated \nn\n times.\n\n\nReferences\n\n\nMiranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.\n\n\nsource:\n\n\nQuantEcon/src/quad.jl:464\n\n\n\n\n\n\nqnwlege \n\u00b6\n\n\nComputes multivariate Guass-Legendre  quadrature nodes and weights.\n\n\nArguments\n\n\n\n\nn::Union(Int, Vector{Int})\n : Number of desired nodes along each dimension\n\n\na::Union(Real, Vector{Real})\n : Lower endpoint along each dimension\n\n\nb::Union(Real, Vector{Real})\n : Upper endpoint along each dimension\n\n\n\n\nReturns\n\n\n\n\nnodes::Array{Float64}\n : An array of quadrature nodes\n\n\nweights::Array{Float64}\n : An array of corresponding quadrature weights\n\n\n\n\nNotes\n\n\nIf any of the parameters to this function are scalars while others are\n\nVector\ns of length \nn\n, the the scalar parameter is repeated \nn\n times.\n\n\nReferences\n\n\nMiranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.\n\n\nsource:\n\n\nQuantEcon/src/quad.jl:99\n\n\n\n\n\n\nqnwnorm \n\u00b6\n\n\nComputes nodes and weights for multivariate normal distribution\n\n\nArguments\n\n\n\n\nn::Union(Int, Vector{Int})\n : Number of desired nodes along each dimension\n\n\nmu::Union(Real, Vector{Real})\n : Mean along each dimension\n\n\nsig2::Union(Real, Vector{Real}, Matrix{Real})(eye(length(n)))\n : Covariance\nstructure\n\n\n\n\nReturns\n\n\n\n\nnodes::Array{Float64}\n : An array of quadrature nodes\n\n\nweights::Array{Float64}\n : An array of corresponding quadrature weights\n\n\n\n\nNotes\n\n\nThis function has many methods. I try to describe them here.\n\n\nn\n or \nmu\n can be a vector or a scalar. If just one is a scalar the other is\nrepeated to match the length of the other. If both are scalars, then the number\nof repeats is inferred from \nsig2\n.\n\n\nsig2\n can be a matrix, vector or scalar. If it is a matrix, it is treated as\nthe covariance matrix. If it is a vector, it is considered the diagonal of a\ndiagonal covariance matrix. If it is a scalar it is repeated along the diagonal\nas many times as necessary, where the number of repeats is determined by the\nlength of either n and/or mu (which ever is a vector).\n\n\nIf all 3 are scalars, then 1d nodes are computed. \nmu\n and \nsig2\n are treated as\nthe mean and variance of a 1d normal distribution\n\n\nReferences\n\n\nMiranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.\n\n\nsource:\n\n\nQuantEcon/src/quad.jl:207\n\n\n\n\n\n\nqnwsimp \n\u00b6\n\n\nComputes multivariate Simpson quadrature nodes and weights.\n\n\nArguments\n\n\n\n\nn::Union(Int, Vector{Int})\n : Number of desired nodes along each dimension\n\n\na::Union(Real, Vector{Real})\n : Lower endpoint along each dimension\n\n\nb::Union(Real, Vector{Real})\n : Upper endpoint along each dimension\n\n\n\n\nReturns\n\n\n\n\nnodes::Array{Float64}\n : An array of quadrature nodes\n\n\nweights::Array{Float64}\n : An array of corresponding quadrature weights\n\n\n\n\nNotes\n\n\nIf any of the parameters to this function are scalars while others are\n\nVector\ns of length \nn\n, the the scalar parameter is repeated \nn\n times.\n\n\nReferences\n\n\nMiranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.\n\n\nsource:\n\n\nQuantEcon/src/quad.jl:286\n\n\n\n\n\n\nqnwtrap \n\u00b6\n\n\nComputes multivariate trapezoid quadrature nodes and weights.\n\n\nArguments\n\n\n\n\nn::Union(Int, Vector{Int})\n : Number of desired nodes along each dimension\n\n\na::Union(Real, Vector{Real})\n : Lower endpoint along each dimension\n\n\nb::Union(Real, Vector{Real})\n : Upper endpoint along each dimension\n\n\n\n\nReturns\n\n\n\n\nnodes::Array{Float64}\n : An array of quadrature nodes\n\n\nweights::Array{Float64}\n : An array of corresponding quadrature weights\n\n\n\n\nNotes\n\n\nIf any of the parameters to this function are scalars while others are\n\nVector\ns of length \nn\n, the the scalar parameter is repeated \nn\n times.\n\n\nReferences\n\n\nMiranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.\n\n\nsource:\n\n\nQuantEcon/src/quad.jl:323\n\n\n\n\n\n\nquadrect \n\u00b6\n\n\nIntegrate the d-dimensional function f on a rectangle with lower and upper bound\nfor dimension i defined by a[i] and b[i], respectively; using n[i] points.\n\n\nArguments\n\n\n\n\nf::Function\n The function to integrate over. This should be a function that\naccepts as its first argument a matrix representing points along each dimension\n(each dimension is a column). Other arguments that need to be passed to the\nfunction are caught by \nargs...\n and `kwargs...``\n\n\nn::Union(Int, Vector{Int})\n : Number of desired nodes along each dimension\n\n\na::Union(Real, Vector{Real})\n : Lower endpoint along each dimension\n\n\nb::Union(Real, Vector{Real})\n : Upper endpoint along each dimension\n\n\nkind::String(\"lege\")\n Specifies which type of integration to perform. Valid\nvalues are:\n\n\n\"lege\"\n : Gauss-Legendre\n\n\n\"cheb\"\n : Gauss-Chebyshev\n\n\n\"trap\"\n : trapezoid rule\n\n\n\"simp\"\n : Simpson rule\n\n\n\"N\"\n : Neiderreiter equidistributed sequence\n\n\n\"W\"\n : Weyl equidistributed sequence\n\n\n\"H\"\n : Haber  equidistributed sequence\n\n\n\"R\"\n : Monte Carlo\n\n\n\n\n\n\n;args...\n: additional positional arguments to pass to \nf\n\n\n;kwargs...\n: additional keyword arguments to pass to \nf\n\n\n\n\nReturns\n\n\n\n\nout::Float64\n : The scalar that approximates integral of \nf\n on the hypercube\nformed by \n[a, b]\n\n\n\n\nReferences\n\n\nMiranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.\n\n\nsource:\n\n\nQuantEcon/src/quad.jl:853\n\n\n\n\n\n\nF_to_K(rlq::QuantEcon.RBLQ,  F::Array{T, 2}) \n\u00b6\n\n\nCompute agent 2's best cost-minimizing response \nK\n, given \nF\n.\n\n\nArguments\n\n\n\n\nrlq::RBLQ\n: Instance of \nRBLQ\n type\n\n\nF::Matrix{Float64}\n: A k x n array representing agent 1's policy\n\n\n\n\nReturns\n\n\n\n\nK::Matrix{Float64}\n : Agent's best cost minimizing response corresponding to\n\nF\n\n\nP::Matrix{Float64}\n : The value function corresponding to \nF\n\n\n\n\nsource:\n\n\nQuantEcon/src/robustlq.jl:245\n\n\n\n\n\n\nK_to_F(rlq::QuantEcon.RBLQ,  K::Array{T, 2}) \n\u00b6\n\n\nCompute agent 1's best cost-minimizing response \nK\n, given \nF\n.\n\n\nArguments\n\n\n\n\nrlq::RBLQ\n: Instance of \nRBLQ\n type\n\n\nK::Matrix{Float64}\n: A k x n array representing the worst case matrix\n\n\n\n\nReturns\n\n\n\n\nF::Matrix{Float64}\n : Agent's best cost minimizing response corresponding to\n\nK\n\n\nP::Matrix{Float64}\n : The value function corresponding to \nK\n\n\n\n\nsource:\n\n\nQuantEcon/src/robustlq.jl:277\n\n\n\n\n\n\nar_periodogram(x::Array{T, N}) \n\u00b6\n\n\nCompute periodogram from data \nx\n, using prewhitening, smoothing and recoloring.\nThe data is fitted to an AR(1) model for prewhitening, and the residuals are\nused to compute a first-pass periodogram with smoothing.  The fitted\ncoefficients are then used for recoloring.\n\n\nArguments\n\n\n\n\nx::Array\n: An array containing the data to smooth\n\n\nwindow_len::Int(7)\n: An odd integer giving the length of the window\n\n\nwindow::String(\"hanning\")\n: A string giving the window type. Possible values\nare \nflat\n, \nhanning\n, \nhamming\n, \nbartlett\n, or \nblackman\n\n\n\n\nReturns\n\n\n\n\nw::Array{Float64}\n: Fourier frequencies at which the periodogram is evaluated\n\n\nI_w::Array{Float64}\n: The periodogram at frequences \nw\n\n\n\n\nsource:\n\n\nQuantEcon/src/estspec.jl:136\n\n\n\n\n\n\nar_periodogram(x::Array{T, N},  window::AbstractString) \n\u00b6\n\n\nCompute periodogram from data \nx\n, using prewhitening, smoothing and recoloring.\nThe data is fitted to an AR(1) model for prewhitening, and the residuals are\nused to compute a first-pass periodogram with smoothing.  The fitted\ncoefficients are then used for recoloring.\n\n\nArguments\n\n\n\n\nx::Array\n: An array containing the data to smooth\n\n\nwindow_len::Int(7)\n: An odd integer giving the length of the window\n\n\nwindow::String(\"hanning\")\n: A string giving the window type. Possible values\nare \nflat\n, \nhanning\n, \nhamming\n, \nbartlett\n, or \nblackman\n\n\n\n\nReturns\n\n\n\n\nw::Array{Float64}\n: Fourier frequencies at which the periodogram is evaluated\n\n\nI_w::Array{Float64}\n: The periodogram at frequences \nw\n\n\n\n\nsource:\n\n\nQuantEcon/src/estspec.jl:136\n\n\n\n\n\n\nar_periodogram(x::Array{T, N},  window::AbstractString,  window_len::Int64) \n\u00b6\n\n\nCompute periodogram from data \nx\n, using prewhitening, smoothing and recoloring.\nThe data is fitted to an AR(1) model for prewhitening, and the residuals are\nused to compute a first-pass periodogram with smoothing.  The fitted\ncoefficients are then used for recoloring.\n\n\nArguments\n\n\n\n\nx::Array\n: An array containing the data to smooth\n\n\nwindow_len::Int(7)\n: An odd integer giving the length of the window\n\n\nwindow::String(\"hanning\")\n: A string giving the window type. Possible values\nare \nflat\n, \nhanning\n, \nhamming\n, \nbartlett\n, or \nblackman\n\n\n\n\nReturns\n\n\n\n\nw::Array{Float64}\n: Fourier frequencies at which the periodogram is evaluated\n\n\nI_w::Array{Float64}\n: The periodogram at frequences \nw\n\n\n\n\nsource:\n\n\nQuantEcon/src/estspec.jl:136\n\n\n\n\n\n\nautocovariance(arma::QuantEcon.ARMA) \n\u00b6\n\n\nCompute the autocovariance function from the ARMA parameters\nover the integers range(num_autocov) using the spectral density\nand the inverse Fourier transform.\n\n\nArguments\n\n\n\n\narma::ARMA\n: Instance of \nARMA\n type\n\n\n;num_autocov::Integer(16)\n : The number of autocovariances to calculate\n\n\n\n\nsource:\n\n\nQuantEcon/src/arma.jl:137\n\n\n\n\n\n\nb_operator(rlq::QuantEcon.RBLQ,  P::Array{T, 2}) \n\u00b6\n\n\nThe D operator, mapping P into\n\n\nB(P) := R - beta^2 A'PB(Q + beta B'PB)^{-1}B'PA + beta A'PA\n\n\n\nand also returning\n\n\nF := (Q + beta B'PB)^{-1} beta B'PA\n\n\n\nArguments\n\n\n\n\nrlq::RBLQ\n: Instance of \nRBLQ\n type\n\n\nP::Matrix{Float64}\n : \nsize\n is n x n\n\n\n\n\nReturns\n\n\n\n\nF::Matrix{Float64}\n : The F matrix as defined above\n\n\nnew_p::Matrix{Float64}\n : The matrix P after applying the B operator\n\n\n\n\nsource:\n\n\nQuantEcon/src/robustlq.jl:116\n\n\n\n\n\n\ncompute_deterministic_entropy(rlq::QuantEcon.RBLQ,  F,  K,  x0) \n\u00b6\n\n\nGiven \nK\n and \nF\n, compute the value of deterministic entropy, which is sum_t\nbeta^t x_t' K'K x_t with x_{t+1} = (A - BF + CK) x_t.\n\n\nArguments\n\n\n\n\nrlq::RBLQ\n: Instance of \nRBLQ\n type\n\n\nF::Matrix{Float64}\n The policy function, a k x n array\n\n\nK::Matrix{Float64}\n The worst case matrix, a j x n array\n\n\nx0::Vector{Float64}\n : The initial condition for state\n\n\n\n\nReturns\n\n\n\n\ne::Float64\n The deterministic entropy\n\n\n\n\nsource:\n\n\nQuantEcon/src/robustlq.jl:305\n\n\n\n\n\n\ncompute_fixed_point{TV}(T::Function,  v::TV) \n\u00b6\n\n\nRepeatedly apply a function to search for a fixed point\n\n\nApproximates \nT^\u221e v\n, where \nT\n is an operator (function) and \nv\n is an initial\nguess for the fixed point. Will terminate either when \nT^{k+1}(v) - T^k v \n\nerr_tol\n or \nmax_iter\n iterations has been exceeded.\n\n\nProvided that \nT\n is a contraction mapping or similar,  the return value will\nbe an approximation to the fixed point of \nT\n.\n\n\nArguments\n\n\n\n\nT\n: A function representing the operator \nT\n\n\nv::TV\n: The initial condition. An object of type \nTV\n\n\n;err_tol(1e-3)\n: Stopping tolerance for iterations\n\n\n;max_iter(50)\n: Maximum number of iterations\n\n\n;verbose(true)\n: Whether or not to print status updates to the user\n\n\n;print_skip(10)\n : if \nverbose\n is true, how many iterations to apply between\n  print messages\n\n\n\n\nReturns\n\n\n\n\n\n\n'::TV': The fixed point of the operator \nT\n. Has type \nTV\n\n\n\n\nExample\n\n\nusing QuantEcon\nT(x, \u03bc) = 4.0 * \u03bc * x * (1.0 - x)\nx_star = compute_fixed_point(x-\nT(x, 0.3), 0.4)  # (4\u03bc - 1)/(4\u03bc)\n\n\n\n\nsource:\n\n\nQuantEcon/src/compute_fp.jl:50\n\n\n\n\n\n\nd_operator(rlq::QuantEcon.RBLQ,  P::Array{T, 2}) \n\u00b6\n\n\nThe D operator, mapping P into\n\n\nD(P) := P + PC(theta I - C'PC)^{-1} C'P.\n\n\n\nArguments\n\n\n\n\nrlq::RBLQ\n: Instance of \nRBLQ\n type\n\n\nP::Matrix{Float64}\n : \nsize\n is n x n\n\n\n\n\nReturns\n\n\n\n\ndP::Matrix{Float64}\n : The matrix P after applying the D operator\n\n\n\n\nsource:\n\n\nQuantEcon/src/robustlq.jl:87\n\n\n\n\n\n\ndraw(d::QuantEcon.DiscreteRV{T\n:Real}) \n\u00b6\n\n\nMake a single draw from the discrete distribution\n\n\nArguments\n\n\n\n\nd::DiscreteRV\n: The \nDiscreteRV\n type represetning the distribution\n\n\n\n\nReturns\n\n\n\n\nout::Int\n: One draw from the discrete distribution\n\n\n\n\nsource:\n\n\nQuantEcon/src/discrete_rv.jl:51\n\n\n\n\n\n\ndraw{T}(d::QuantEcon.DiscreteRV{T},  k::Int64) \n\u00b6\n\n\nMake multiple draws from the discrete distribution represented by a\n\nDiscreteRV\n instance\n\n\nArguments\n\n\n\n\nd::DiscreteRV\n: The \nDiscreteRV\n type representing the distribution\n\n\nk::Int\n:\n\n\n\n\nReturns\n\n\n\n\nout::Vector{Int}\n: \nk\n draws from \nd\n\n\n\n\nsource:\n\n\nQuantEcon/src/discrete_rv.jl:66\n\n\n\n\n\n\nevaluate_F(rlq::QuantEcon.RBLQ,  F::Array{T, 2}) \n\u00b6\n\n\nGiven a fixed policy \nF\n, with the interpretation u = -F x, this function\ncomputes the matrix P_F and constant d_F associated with discounted cost J_F(x) =\nx' P_F x + d_F.\n\n\nArguments\n\n\n\n\nrlq::RBLQ\n: Instance of \nRBLQ\n type\n\n\nF::Matrix{Float64}\n :  The policy function, a k x n array\n\n\n\n\nReturns\n\n\n\n\nP_F::Matrix{Float64}\n : Matrix for discounted cost\n\n\nd_F::Float64\n : Constant for discounted cost\n\n\nK_F::Matrix{Float64}\n : Worst case policy\n\n\nO_F::Matrix{Float64}\n : Matrix for discounted entropy\n\n\no_F::Float64\n : Constant for discounted entropy\n\n\n\n\nsource:\n\n\nQuantEcon/src/robustlq.jl:332\n\n\n\n\n\n\nimpulse_response(arma::QuantEcon.ARMA) \n\u00b6\n\n\nGet the impulse response corresponding to our model.\n\n\nArguments\n\n\n\n\narma::ARMA\n: Instance of \nARMA\n type\n\n\n;impulse_length::Integer(30)\n: Length of horizon for calucluating impulse\nreponse. Must be at least as long as the \np\n fields of \narma\n\n\n\n\nReturns\n\n\n\n\npsi::Vector{Float64}\n: \npsi[j]\n is the response at lag j of the impulse\nresponse. We take psi[1] as unity.\n\n\n\n\nsource:\n\n\nQuantEcon/src/arma.jl:162\n\n\n\n\n\n\nlae_est{T}(l::QuantEcon.LAE,  y::AbstractArray{T, N}) \n\u00b6\n\n\nA vectorized function that returns the value of the look ahead estimate at the\nvalues in the array y.\n\n\nArguments\n\n\n\n\nl::LAE\n: Instance of \nLAE\n type\n\n\ny::Array\n: Array that becomes the \ny\n in \nl.p(l.x, y)\n\n\n\n\nReturns\n\n\n\n\npsi_vals::Vector\n: Density at \n(x, y)\n\n\n\n\nsource:\n\n\nQuantEcon/src/lae.jl:58\n\n\n\n\n\n\nm_quadratic_sum(A::Array{T, 2},  B::Array{T, 2}) \n\u00b6\n\n\nComputes the quadratic sum\n\n\nV = sum_{j=0}^{infty} A^j B A^{j'}\n\n\n\nV is computed by solving the corresponding discrete lyapunov equation using the\ndoubling algorithm.  See the documentation of \nsolve_discrete_lyapunov\n for\nmore information.\n\n\nArguments\n\n\n\n\nA::Matrix{Float64}\n : An n x n matrix as described above.  We assume in order\nfor convergence that the eigenvalues of A have moduli bounded by unity\n\n\nB::Matrix{Float64}\n : An n x n matrix as described above.  We assume in order\nfor convergence that the eigenvalues of B have moduli bounded by unity\n\n\nmax_it::Int(50)\n : Maximum number of iterations\n\n\n\n\nReturns\n\n\n\n\ngamma1::Matrix{Float64}\n : Represents the value V\n\n\n\n\nsource:\n\n\nQuantEcon/src/quadsums.jl:81\n\n\n\n\n\n\nmc_compute_stationary(mc::QuantEcon.MarkovChain) \n\u00b6\n\n\ncalculate the stationary distributions associated with a N-state markov chain\n\n\nArguments\n\n\n\n\nmc::MarkovChain\n : MarkovChain instance containing a valid stochastic matrix\n\n\n;method::Symbol(:gth)\n: One of \ngth\n, \nlu\n, and \neigen\n; specifying which\nof the three \n_solve\n methods to use.\n\n\n\n\nReturns\n\n\n\n\ndists::Matrix{Float64}\n: N x M matrix where each column is a stationary\ndistribution of \nmc.p\n\n\n\n\nsource:\n\n\nQuantEcon/src/mc_tools.jl:197\n\n\n\n\n\n\nmc_sample_path!(mc::QuantEcon.MarkovChain,  samples::Array{T, N}) \n\u00b6\n\n\nFill \nsamples\n with samples from the Markov chain \nmc\n\n\nArguments\n\n\n\n\nmc::MarkovChain\n : MarkovChain instance containing a valid stochastic matrix\n\n\nsamples::Array{Int}\n : Pre-allocated vector of integers to be filled with\nsamples from the markov chain \nmc\n. The first element will be used as the\ninitial state and all other elements will be over-written.\n\n\n\n\nReturns\n\n\nNone modifies \nsamples\n in place\n\n\nsource:\n\n\nQuantEcon/src/mc_tools.jl:286\n\n\n\n\n\n\nmc_sample_path(mc::QuantEcon.MarkovChain) \n\u00b6\n\n\nSimulate a Markov chain starting from an initial state\n\n\nArguments\n\n\n\n\nmc::MarkovChain\n : MarkovChain instance containing a valid stochastic matrix\n\n\ninit::Int(rand(1:n_states(mc)))\n : The index of the initial state. This should\nbe an integer between 1 and \nn_states(mc)\n\n\nsample_size::Int(1000)\n: The number of samples to collect\n\n\n;burn::Int(0)\n: The burn in length. Routine drops first \nburn\n of the\n\nsample_size\n total samples collected\n\n\n\n\nReturns\n\n\n\n\nsamples::Vector{Int}\n: Vector of simulated states\n\n\n\n\nsource:\n\n\nQuantEcon/src/mc_tools.jl:238\n\n\n\n\n\n\nmc_sample_path(mc::QuantEcon.MarkovChain,  init::Array{T, 1}) \n\u00b6\n\n\nSimulate a Markov chain starting from an initial distribution\n\n\nArguments\n\n\n\n\nmc::MarkovChain\n : MarkovChain instance containing a valid stochastic matrix\n\n\ninit::Vector\n : A vector of length \nn_state(mc)\n specifying the number\nprobability of being in seach state in the initial period\n\n\nsample_size::Int(1000)\n: The number of samples to collect\n\n\n;burn::Int(0)\n: The burn in length. Routine drops first \nburn\n of the\n\nsample_size\n total samples collected\n\n\n\n\nReturns\n\n\n\n\nsamples::Vector{Int}\n: Vector of simulated states\n\n\n\n\nsource:\n\n\nQuantEcon/src/mc_tools.jl:265\n\n\n\n\n\n\nmc_sample_path(mc::QuantEcon.MarkovChain,  init::Array{T, 1},  sample_size::Int64) \n\u00b6\n\n\nSimulate a Markov chain starting from an initial distribution\n\n\nArguments\n\n\n\n\nmc::MarkovChain\n : MarkovChain instance containing a valid stochastic matrix\n\n\ninit::Vector\n : A vector of length \nn_state(mc)\n specifying the number\nprobability of being in seach state in the initial period\n\n\nsample_size::Int(1000)\n: The number of samples to collect\n\n\n;burn::Int(0)\n: The burn in length. Routine drops first \nburn\n of the\n\nsample_size\n total samples collected\n\n\n\n\nReturns\n\n\n\n\nsamples::Vector{Int}\n: Vector of simulated states\n\n\n\n\nsource:\n\n\nQuantEcon/src/mc_tools.jl:265\n\n\n\n\n\n\nmc_sample_path(mc::QuantEcon.MarkovChain,  init::Int64) \n\u00b6\n\n\nSimulate a Markov chain starting from an initial state\n\n\nArguments\n\n\n\n\nmc::MarkovChain\n : MarkovChain instance containing a valid stochastic matrix\n\n\ninit::Int(rand(1:n_states(mc)))\n : The index of the initial state. This should\nbe an integer between 1 and \nn_states(mc)\n\n\nsample_size::Int(1000)\n: The number of samples to collect\n\n\n;burn::Int(0)\n: The burn in length. Routine drops first \nburn\n of the\n\nsample_size\n total samples collected\n\n\n\n\nReturns\n\n\n\n\nsamples::Vector{Int}\n: Vector of simulated states\n\n\n\n\nsource:\n\n\nQuantEcon/src/mc_tools.jl:238\n\n\n\n\n\n\nmc_sample_path(mc::QuantEcon.MarkovChain,  init::Int64,  sample_size::Int64) \n\u00b6\n\n\nSimulate a Markov chain starting from an initial state\n\n\nArguments\n\n\n\n\nmc::MarkovChain\n : MarkovChain instance containing a valid stochastic matrix\n\n\ninit::Int(rand(1:n_states(mc)))\n : The index of the initial state. This should\nbe an integer between 1 and \nn_states(mc)\n\n\nsample_size::Int(1000)\n: The number of samples to collect\n\n\n;burn::Int(0)\n: The burn in length. Routine drops first \nburn\n of the\n\nsample_size\n total samples collected\n\n\n\n\nReturns\n\n\n\n\nsamples::Vector{Int}\n: Vector of simulated states\n\n\n\n\nsource:\n\n\nQuantEcon/src/mc_tools.jl:238\n\n\n\n\n\n\nnnash(a,  b1,  b2,  r1,  r2,  q1,  q2,  s1,  s2,  w1,  w2,  m1,  m2) \n\u00b6\n\n\nCompute the limit of a Nash linear quadratic dynamic game.\n\n\nPlayer \ni\n minimizes\n\n\nsum_{t=1}^{inf}(x_t' r_i x_t + 2 x_t' w_i\nu_{it} +u_{it}' q_i u_{it} + u_{jt}' s_i u_{jt} + 2 u_{jt}'\nm_i u_{it})\n\n\n\nsubject to the law of motion\n\n\nx_{t+1} = A x_t + b_1 u_{1t} + b_2 u_{2t}\n\n\n\nand a perceived control law :math:\nu_j(t) = - f_j x_t\n for the other player.\n\n\nThe solution computed in this routine is the \nf_i\n and \np_i\n of the associated\ndouble optimal linear regulator problem.\n\n\nArguments\n\n\n\n\nA\n : Corresponds to the above equation, should be of size (n, n)\n\n\nB1\n : As above, size (n, k_1)\n\n\nB2\n : As above, size (n, k_2)\n\n\nR1\n : As above, size (n, n)\n\n\nR2\n : As above, size (n, n)\n\n\nQ1\n : As above, size (k_1, k_1)\n\n\nQ2\n : As above, size (k_2, k_2)\n\n\nS1\n : As above, size (k_1, k_1)\n\n\nS2\n : As above, size (k_2, k_2)\n\n\nW1\n : As above, size (n, k_1)\n\n\nW2\n : As above, size (n, k_2)\n\n\nM1\n : As above, size (k_2, k_1)\n\n\nM2\n : As above, size (k_1, k_2)\n\n\n;beta::Float64(1.0)\n Discount rate\n\n\n;tol::Float64(1e-8)\n : Tolerance level for convergence\n\n\n;max_iter::Int(1000)\n : Maximum number of iterations allowed\n\n\n\n\nReturns\n\n\n\n\nF1::Matrix{Float64}\n: (k_1, n) matrix representing feedback law for agent 1\n\n\nF2::Matrix{Float64}\n: (k_2, n) matrix representing feedback law for agent 2\n\n\nP1::Matrix{Float64}\n: (n, n) matrix representing the steady-state solution to the associated discrete matrix ticcati equation for agent 1\n\n\nP2::Matrix{Float64}\n: (n, n) matrix representing the steady-state solution to the associated discrete matrix riccati equation for agent 2\n\n\n\n\nsource:\n\n\nQuantEcon/src/lqnash.jl:57\n\n\n\n\n\n\npdf(d::QuantEcon.BetaBinomial) \n\u00b6\n\n\nEvaluate the pdf of the distributions at the points 0, 1, ..., k\n\n\nArguments\n\n\nd::BetaBinomial\n: Instance of \nBetaBinomial\n type\n\n\nReturns\n\n\n\n\nprobs::vector{Float64}\n: pdf of the distribution \nd\n, at \n0:d.k\n\n\n\n\nsource:\n\n\nQuantEcon/src/distributions.jl:64\n\n\n\n\n\n\nqnwlogn(n,  mu,  sig2) \n\u00b6\n\n\nComputes quadrature nodes and weights for multivariate uniform distribution\n\n\nArguments\n\n\n\n\nn::Union(Int, Vector{Int})\n : Number of desired nodes along each dimension\n\n\nmu::Union(Real, Vector{Real})\n : Mean along each dimension\n\n\nsig2::Union(Real, Vector{Real}, Matrix{Real})(eye(length(n)))\n : Covariance\nstructure\n\n\n\n\nReturns\n\n\n\n\nnodes::Array{Float64}\n : An array of quadrature nodes\n\n\nweights::Array{Float64}\n : An array of corresponding quadrature weights\n\n\n\n\nNotes\n\n\nSee also the documentation for \nqnwnorm\n\n\nReferences\n\n\nMiranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.\n\n\nsource:\n\n\nQuantEcon/src/quad.jl:693\n\n\n\n\n\n\nqnwunif(n,  a,  b) \n\u00b6\n\n\nComputes quadrature nodes and weights for multivariate uniform distribution\n\n\nArguments\n\n\n\n\nn::Union(Int, Vector{Int})\n : Number of desired nodes along each dimension\n\n\na::Union(Real, Vector{Real})\n : Lower endpoint along each dimension\n\n\nb::Union(Real, Vector{Real})\n : Upper endpoint along each dimension\n\n\n\n\nReturns\n\n\n\n\nnodes::Array{Float64}\n : An array of quadrature nodes\n\n\nweights::Array{Float64}\n : An array of corresponding quadrature weights\n\n\n\n\nNotes\n\n\nIf any of the parameters to this function are scalars while others are\n\nVector\ns of length \nn\n, the the scalar parameter is repeated \nn\n times.\n\n\nReferences\n\n\nMiranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.\n\n\nsource:\n\n\nQuantEcon/src/quad.jl:668\n\n\n\n\n\n\nrobust_rule(rlq::QuantEcon.RBLQ) \n\u00b6\n\n\nSolves the robust control problem.\n\n\nThe algorithm here tricks the problem into a stacked LQ problem, as described in\nchapter 2 of Hansen- Sargent's text \"Robustness.\"  The optimal control with\nobserved state is\n\n\nu_t = - F x_t\n\n\n\nAnd the value function is -x'Px\n\n\nArguments\n\n\n\n\nrlq::RBLQ\n: Instance of \nRBLQ\n type\n\n\n\n\nReturns\n\n\n\n\nF::Matrix{Float64}\n : The optimal control matrix from above\n\n\nP::Matrix{Float64}\n : The positive semi-definite matrix defining the value\nfunction\n\n\nK::Matrix{Float64}\n : the worst-case shock matrix \nK\n, where\n\nw_{t+1} = K x_t\n is the worst case shock\n\n\n\n\nsource:\n\n\nQuantEcon/src/robustlq.jl:154\n\n\n\n\n\n\nrobust_rule_simple(rlq::QuantEcon.RBLQ) \n\u00b6\n\n\nSolve the robust LQ problem\n\n\nA simple algorithm for computing the robust policy F and the\ncorresponding value function P, based around straightforward\niteration with the robust Bellman operator.  This function is\neasier to understand but one or two orders of magnitude slower\nthan self.robust_rule().  For more information see the docstring\nof that method.\n\n\nArguments\n\n\n\n\nrlq::RBLQ\n: Instance of \nRBLQ\n type\n\n\nP_init::Matrix{Float64}(zeros(rlq.n, rlq.n))\n : The initial guess for the\nvalue function matrix\n\n\n;max_iter::Int(80)\n: Maximum number of iterations that are allowed\n\n\n;tol::Real(1e-8)\n The tolerance for convergence\n\n\n\n\nReturns\n\n\n\n\nF::Matrix{Float64}\n : The optimal control matrix from above\n\n\nP::Matrix{Float64}\n : The positive semi-definite matrix defining the value\nfunction\n\n\nK::Matrix{Float64}\n : the worst-case shock matrix \nK\n, where\n\nw_{t+1} = K x_t\n is the worst case shock\n\n\n\n\nsource:\n\n\nQuantEcon/src/robustlq.jl:202\n\n\n\n\n\n\nrobust_rule_simple(rlq::QuantEcon.RBLQ,  P::Array{T, 2}) \n\u00b6\n\n\nSolve the robust LQ problem\n\n\nA simple algorithm for computing the robust policy F and the\ncorresponding value function P, based around straightforward\niteration with the robust Bellman operator.  This function is\neasier to understand but one or two orders of magnitude slower\nthan self.robust_rule().  For more information see the docstring\nof that method.\n\n\nArguments\n\n\n\n\nrlq::RBLQ\n: Instance of \nRBLQ\n type\n\n\nP_init::Matrix{Float64}(zeros(rlq.n, rlq.n))\n : The initial guess for the\nvalue function matrix\n\n\n;max_iter::Int(80)\n: Maximum number of iterations that are allowed\n\n\n;tol::Real(1e-8)\n The tolerance for convergence\n\n\n\n\nReturns\n\n\n\n\nF::Matrix{Float64}\n : The optimal control matrix from above\n\n\nP::Matrix{Float64}\n : The positive semi-definite matrix defining the value\nfunction\n\n\nK::Matrix{Float64}\n : the worst-case shock matrix \nK\n, where\n\nw_{t+1} = K x_t\n is the worst case shock\n\n\n\n\nsource:\n\n\nQuantEcon/src/robustlq.jl:202\n\n\n\n\n\n\nrouwenhorst(N::Int64,  \u03c1::Real,  \u03c3::Real) \n\u00b6\n\n\nRouwenhorst's method to approximate AR(1) processes.\n\n\nThe process follows\n\n\ny_t = \u03bc + \u03c1 y_{t-1} + \u03b5_t,\n\n\n\nwhere \u03b5_t ~ N (0, \u03c3^2)\n\n\nArguments\n\n\n\n\nN::Int\n : Number of points in markov process\n\n\n\u03c1::Real\n : Persistence parameter in AR(1) process\n\n\n\u03c3::Real\n : Standard deviation of random component of AR(1) process\n\n\n\u03bc::Real(0.0)\n :  Mean of AR(1) process\n\n\n\n\nReturns\n\n\n\n\ny::Vector{Float64}\n : Nodes in the state space\n\n\n\u0398::Matrix{Float64}\n Matrix transition probabilities for Markov Process\n\n\n\n\nsource:\n\n\nQuantEcon/src/markov_approx.jl:103\n\n\n\n\n\n\nrouwenhorst(N::Int64,  \u03c1::Real,  \u03c3::Real,  \u03bc::Real) \n\u00b6\n\n\nRouwenhorst's method to approximate AR(1) processes.\n\n\nThe process follows\n\n\ny_t = \u03bc + \u03c1 y_{t-1} + \u03b5_t,\n\n\n\nwhere \u03b5_t ~ N (0, \u03c3^2)\n\n\nArguments\n\n\n\n\nN::Int\n : Number of points in markov process\n\n\n\u03c1::Real\n : Persistence parameter in AR(1) process\n\n\n\u03c3::Real\n : Standard deviation of random component of AR(1) process\n\n\n\u03bc::Real(0.0)\n :  Mean of AR(1) process\n\n\n\n\nReturns\n\n\n\n\ny::Vector{Float64}\n : Nodes in the state space\n\n\n\u0398::Matrix{Float64}\n Matrix transition probabilities for Markov Process\n\n\n\n\nsource:\n\n\nQuantEcon/src/markov_approx.jl:103\n\n\n\n\n\n\nsimulation(arma::QuantEcon.ARMA) \n\u00b6\n\n\nCompute a simulated sample path assuming Gaussian shocks.\n\n\nArguments\n\n\n\n\narma::ARMA\n: Instance of \nARMA\n type\n\n\n;ts_length::Integer(90)\n: Length of simulation\n\n\n;impulse_length::Integer(30)\n: Horizon for calculating impulse response\n(see also docstring for \nimpulse_response\n)\n\n\n\n\nReturns\n\n\n\n\nX::Vector{Float64}\n: Simulation of the ARMA model \narma\n\n\n\n\nsource:\n\n\nQuantEcon/src/arma.jl:194\n\n\n\n\n\n\nsmooth(x::Array{T, N}) \n\u00b6\n\n\nVersion of \nsmooth\n where \nwindow_len\n and \nwindow\n are keyword arguments\n\n\nsource:\n\n\nQuantEcon/src/estspec.jl:70\n\n\n\n\n\n\nsmooth(x::Array{T, N},  window_len::Int64) \n\u00b6\n\n\nSmooth the data in x using convolution with a window of requested size and type.\n\n\nArguments\n\n\n\n\nx::Array\n: An array containing the data to smooth\n\n\nwindow_len::Int(7)\n: An odd integer giving the length of the window\n\n\nwindow::String(\"hanning\")\n: A string giving the window type. Possible values\nare \nflat\n, \nhanning\n, \nhamming\n, \nbartlett\n, or \nblackman\n\n\n\n\nReturns\n\n\n\n\nout::Array\n: The array of smoothed data\n\n\n\n\nsource:\n\n\nQuantEcon/src/estspec.jl:30\n\n\n\n\n\n\nsmooth(x::Array{T, N},  window_len::Int64,  window::AbstractString) \n\u00b6\n\n\nSmooth the data in x using convolution with a window of requested size and type.\n\n\nArguments\n\n\n\n\nx::Array\n: An array containing the data to smooth\n\n\nwindow_len::Int(7)\n: An odd integer giving the length of the window\n\n\nwindow::String(\"hanning\")\n: A string giving the window type. Possible values\nare \nflat\n, \nhanning\n, \nhamming\n, \nbartlett\n, or \nblackman\n\n\n\n\nReturns\n\n\n\n\nout::Array\n: The array of smoothed data\n\n\n\n\nsource:\n\n\nQuantEcon/src/estspec.jl:30\n\n\n\n\n\n\nsolve_discrete_lyapunov(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}}) \n\u00b6\n\n\nSolves the discrete lyapunov equation.\n\n\nThe problem is given by\n\n\nAXA' - X + B = 0\n\n\n\nX\n is computed by using a doubling algorithm. In particular, we iterate to\nconvergence on \nX_j\n with the following recursions for j = 1, 2,...\nstarting from X_0 = B, a_0 = A:\n\n\na_j = a_{j-1} a_{j-1}\nX_j = X_{j-1} + a_{j-1} X_{j-1} a_{j-1}'\n\n\n\nArguments\n\n\n\n\nA::Matrix{Float64}\n : An n x n matrix as described above.  We assume in order\nfor  convergence that the eigenvalues of \nA\n have moduli bounded by unity\n\n\nB::Matrix{Float64}\n :  An n x n matrix as described above.  We assume in order\nfor convergence that the eigenvalues of \nB\n have moduli bounded by unity\n\n\nmax_it::Int(50)\n :  Maximum number of iterations\n\n\n\n\nReturns\n\n\n\n\ngamma1::Matrix{Float64}\n Represents the value X\n\n\n\n\nsource:\n\n\nQuantEcon/src/matrix_eqn.jl:30\n\n\n\n\n\n\nsolve_discrete_lyapunov(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}},  max_it::Int64) \n\u00b6\n\n\nSolves the discrete lyapunov equation.\n\n\nThe problem is given by\n\n\nAXA' - X + B = 0\n\n\n\nX\n is computed by using a doubling algorithm. In particular, we iterate to\nconvergence on \nX_j\n with the following recursions for j = 1, 2,...\nstarting from X_0 = B, a_0 = A:\n\n\na_j = a_{j-1} a_{j-1}\nX_j = X_{j-1} + a_{j-1} X_{j-1} a_{j-1}'\n\n\n\nArguments\n\n\n\n\nA::Matrix{Float64}\n : An n x n matrix as described above.  We assume in order\nfor  convergence that the eigenvalues of \nA\n have moduli bounded by unity\n\n\nB::Matrix{Float64}\n :  An n x n matrix as described above.  We assume in order\nfor convergence that the eigenvalues of \nB\n have moduli bounded by unity\n\n\nmax_it::Int(50)\n :  Maximum number of iterations\n\n\n\n\nReturns\n\n\n\n\ngamma1::Matrix{Float64}\n Represents the value X\n\n\n\n\nsource:\n\n\nQuantEcon/src/matrix_eqn.jl:30\n\n\n\n\n\n\nsolve_discrete_riccati(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}},  Q::Union{T, Array{T, N}},  R::Union{T, Array{T, N}}) \n\u00b6\n\n\nSolves the discrete-time algebraic Riccati equation\n\n\nThe prolem is defined as\n\n\nX = A'XA - (N + B'XA)'(B'XB + R)^{-1}(N + B'XA) + Q\n\n\n\nvia a modified structured doubling algorithm.  An explanation of the algorithm\ncan be found in the reference below.\n\n\nArguments\n\n\n\n\nA\n : k x k array.\n\n\nB\n : k x n array\n\n\nR\n : n x n, should be symmetric and positive definite\n\n\nQ\n : k x k, should be symmetric and non-negative definite\n\n\nN::Matrix{Float64}(zeros(size(R, 1), size(Q, 1)))\n : n x k array\n\n\ntolerance::Float64(1e-10)\n Tolerance level for convergence\n\n\nmax_iter::Int(50)\n : The maximum number of iterations allowed\n\n\n\n\nNote that \nA, B, R, Q\n can either be real (i.e. k, n = 1) or matrices.\n\n\nReturns\n\n\n\n\nX::Matrix{Float64}\n The fixed point of the Riccati equation; a  k x k array\nrepresenting the approximate solution\n\n\n\n\nReferences\n\n\nChiang, Chun-Yueh, Hung-Yuan Fan, and Wen-Wei Lin. \"STRUCTURED DOUBLING\nALGORITHM FOR DISCRETE-TIME ALGEBRAIC RICCATI EQUATIONS WITH SINGULAR CONTROL\nWEIGHTING MATRICES.\" Taiwanese Journal of Mathematics 14, no. 3A (2010): pp-935.\n\n\nsource:\n\n\nQuantEcon/src/matrix_eqn.jl:96\n\n\n\n\n\n\nsolve_discrete_riccati(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}},  Q::Union{T, Array{T, N}},  R::Union{T, Array{T, N}},  N::Union{T, Array{T, N}}) \n\u00b6\n\n\nSolves the discrete-time algebraic Riccati equation\n\n\nThe prolem is defined as\n\n\nX = A'XA - (N + B'XA)'(B'XB + R)^{-1}(N + B'XA) + Q\n\n\n\nvia a modified structured doubling algorithm.  An explanation of the algorithm\ncan be found in the reference below.\n\n\nArguments\n\n\n\n\nA\n : k x k array.\n\n\nB\n : k x n array\n\n\nR\n : n x n, should be symmetric and positive definite\n\n\nQ\n : k x k, should be symmetric and non-negative definite\n\n\nN::Matrix{Float64}(zeros(size(R, 1), size(Q, 1)))\n : n x k array\n\n\ntolerance::Float64(1e-10)\n Tolerance level for convergence\n\n\nmax_iter::Int(50)\n : The maximum number of iterations allowed\n\n\n\n\nNote that \nA, B, R, Q\n can either be real (i.e. k, n = 1) or matrices.\n\n\nReturns\n\n\n\n\nX::Matrix{Float64}\n The fixed point of the Riccati equation; a  k x k array\nrepresenting the approximate solution\n\n\n\n\nReferences\n\n\nChiang, Chun-Yueh, Hung-Yuan Fan, and Wen-Wei Lin. \"STRUCTURED DOUBLING\nALGORITHM FOR DISCRETE-TIME ALGEBRAIC RICCATI EQUATIONS WITH SINGULAR CONTROL\nWEIGHTING MATRICES.\" Taiwanese Journal of Mathematics 14, no. 3A (2010): pp-935.\n\n\nsource:\n\n\nQuantEcon/src/matrix_eqn.jl:96\n\n\n\n\n\n\nspectral_density(arma::QuantEcon.ARMA) \n\u00b6\n\n\nCompute the spectral density function.\n\n\nThe spectral density is the discrete time Fourier transform of the\nautocovariance function. In particular,\n\n\nf(w) = sum_k gamma(k) exp(-ikw)\n\n\n\nwhere gamma is the autocovariance function and the sum is over\nthe set of all integers.\n\n\nArguments\n\n\n\n\narma::ARMA\n: Instance of \nARMA\n type\n\n\n;two_pi::Bool(true)\n: Compute the spectral density function over [0, pi] if\n  false and [0, 2 pi] otherwise.\n\n\n;res(1200)\n : If \nres\n is a scalar then the spectral density is computed at\n\nres\n frequencies evenly spaced around the unit circle, but if \nres\n is an array\nthen the function computes the response at the frequencies given by the array\n\n\n\n\nReturns\n\n\n\n\nw::Vector{Float64}\n: The normalized frequencies at which h was computed, in\n  radians/sample\n\n\nspect::Vector{Float64}\n : The frequency response\n\n\n\n\nsource:\n\n\nQuantEcon/src/arma.jl:116\n\n\n\n\n\n\ntauchen(N::Int64,  \u03c1::Real,  \u03c3::Real) \n\u00b6\n\n\nTauchen's (1996) method for approximating AR(1) process with finite markov chain\n\n\nThe process follows\n\n\ny_t = \u03bc + \u03c1 y_{t-1} + \u03b5_t,\n\n\n\nwhere \u03b5_t ~ N (0, \u03c3^2)\n\n\nArguments\n\n\n\n\nN::Int\n: Number of points in markov process\n\n\n\u03c1::Real\n : Persistence parameter in AR(1) process\n\n\n\u03c3::Real\n : Standard deviation of random component of AR(1) process\n\n\n\u03bc::Real(0.0)\n : Mean of AR(1) process\n\n\nn_std::Int(3)\n : The number of standard deviations to each side the process\nshould span\n\n\n\n\nReturns\n\n\n\n\ny::Vector{Float64}\n : Nodes in the state space\n\n\n\u03a0::Matrix{Float64}\n Matrix transition probabilities for Markov Process\n\n\n\n\nsource:\n\n\nQuantEcon/src/markov_approx.jl:41\n\n\n\n\n\n\ntauchen(N::Int64,  \u03c1::Real,  \u03c3::Real,  \u03bc::Real) \n\u00b6\n\n\nTauchen's (1996) method for approximating AR(1) process with finite markov chain\n\n\nThe process follows\n\n\ny_t = \u03bc + \u03c1 y_{t-1} + \u03b5_t,\n\n\n\nwhere \u03b5_t ~ N (0, \u03c3^2)\n\n\nArguments\n\n\n\n\nN::Int\n: Number of points in markov process\n\n\n\u03c1::Real\n : Persistence parameter in AR(1) process\n\n\n\u03c3::Real\n : Standard deviation of random component of AR(1) process\n\n\n\u03bc::Real(0.0)\n : Mean of AR(1) process\n\n\nn_std::Int(3)\n : The number of standard deviations to each side the process\nshould span\n\n\n\n\nReturns\n\n\n\n\ny::Vector{Float64}\n : Nodes in the state space\n\n\n\u03a0::Matrix{Float64}\n Matrix transition probabilities for Markov Process\n\n\n\n\nsource:\n\n\nQuantEcon/src/markov_approx.jl:41\n\n\n\n\n\n\ntauchen(N::Int64,  \u03c1::Real,  \u03c3::Real,  \u03bc::Real,  n_std::Int64) \n\u00b6\n\n\nTauchen's (1996) method for approximating AR(1) process with finite markov chain\n\n\nThe process follows\n\n\ny_t = \u03bc + \u03c1 y_{t-1} + \u03b5_t,\n\n\n\nwhere \u03b5_t ~ N (0, \u03c3^2)\n\n\nArguments\n\n\n\n\nN::Int\n: Number of points in markov process\n\n\n\u03c1::Real\n : Persistence parameter in AR(1) process\n\n\n\u03c3::Real\n : Standard deviation of random component of AR(1) process\n\n\n\u03bc::Real(0.0)\n : Mean of AR(1) process\n\n\nn_std::Int(3)\n : The number of standard deviations to each side the process\nshould span\n\n\n\n\nReturns\n\n\n\n\ny::Vector{Float64}\n : Nodes in the state space\n\n\n\u03a0::Matrix{Float64}\n Matrix transition probabilities for Markov Process\n\n\n\n\nsource:\n\n\nQuantEcon/src/markov_approx.jl:41\n\n\n\n\n\n\nvar_quadratic_sum(A::Union{T, Array{T, N}},  C::Union{T, Array{T, N}},  H::Union{T, Array{T, N}},  bet::Real,  x0::Union{T, Array{T, N}}) \n\u00b6\n\n\nComputes the expected discounted quadratic sum\n\n\nq(x_0) = E sum_{t=0}^{infty} beta^t x_t' H x_t\n\n\n\nHere {x_t} is the VAR process x_{t+1} = A x_t + C w_t with {w_t}\nstandard normal and x_0 the initial condition.\n\n\nArguments\n\n\n\n\nA::Union(Float64, Matrix{Float64})\n The n x n matrix described above (scalar)\nif n = 1\n\n\nC::Union(Float64, Matrix{Float64})\n The n x n matrix described above (scalar)\nif n = 1\n\n\nH::Union(Float64, Matrix{Float64})\n The n x n matrix described above (scalar)\nif n = 1\n\n\nbeta::Float64\n: Discount factor in (0, 1)\n\n\nx_0::Union(Float64, Vector{Float64})\n The initial condtion. A conformable\narray (of length n) or a scalar if n=1\n\n\n\n\nReturns\n\n\n\n\nq0::Float64\n : Represents the value q(x_0)\n\n\n\n\nNotes\n\n\nThe formula for computing q(x_0) is q(x_0) = x_0' Q x_0 + v where\n\n\n\n\nQ is the solution to Q = H + beta A' Q A and\n\n\nv =   race(C' Q C) \beta / (1 - \beta)\n\n\n\n\nsource:\n\n\nQuantEcon/src/quadsums.jl:41\n\n\n\n\n\n\nQuantEcon.ARMA \n\u00b6\n\n\nRepresents a scalar ARMA(p, q) process\n\n\nIf phi and theta are scalars, then the model is\nunderstood to be\n\n\nX_t = phi X_{t-1} + epsilon_t + theta epsilon_{t-1}\n\n\n\nwhere epsilon_t is a white noise process with standard\ndeviation sigma.\n\n\nIf phi and theta are arrays or sequences,\nthen the interpretation is the ARMA(p, q) model\n\n\nX_t = phi_1 X_{t-1} + ... + phi_p X_{t-p} +\nepsilon_t + theta_1 epsilon_{t-1} + ...  +\ntheta_q epsilon_{t-q}\n\n\n\nwhere\n\n\n\n\nphi = (phi_1, phi_2,..., phi_p)\n\n\ntheta = (theta_1, theta_2,..., theta_q)\n\n\nsigma is a scalar, the standard deviation of the white noise\n\n\n\n\nFields\n\n\n\n\nphi::Vector\n : AR parameters phi_1, ..., phi_p\n\n\ntheta::Vector\n : MA parameters theta_1, ..., theta_q\n\n\np::Integer\n : Number of AR coefficients\n\n\nq::Integer\n : Number of MA coefficients\n\n\nsigma::Real\n : Variance of white noise\n\n\nma_poly::Vector\n : MA polynomial --- filtering representatoin\n\n\nar_poly::Vector\n : AR polynomial --- filtering representation\n\n\n\n\nExamples\n\n\nusing QuantEcon\nphi = 0.5\ntheta = [0.0, -0.8]\nsigma = 1.0\nlp = ARMA(phi, theta, sigma)\nrequire(joinpath(Pkg.dir(\nQuantEcon\n), \nexamples\n, \narma_plots.jl\n))\nquad_plot(lp)\n\n\n\n\nsource:\n\n\nQuantEcon/src/arma.jl:64\n\n\n\n\n\n\nQuantEcon.BetaBinomial \n\u00b6\n\n\nThe Beta-Binomial distribution\n\n\nFields\n\n\n\n\nn, a, b::Float64\n The three paramters to the distribution\n\n\n\n\nNotes\n\n\nSee also http://en.wikipedia.org/wiki/Beta-binomial_distribution\n\n\nsource:\n\n\nQuantEcon/src/distributions.jl:27\n\n\n\n\n\n\nQuantEcon.DiscreteRV{T\n:Real} \n\u00b6\n\n\nGenerates an array of draws from a discrete random variable with\nvector of probabilities given by q.\n\n\nFields\n\n\n\n\nq::Vector{T\n:Real}\n: A vector of non-negative probabilities that sum to 1\n\n\nQ::Vector{T\n:Real}\n: The cumulative sum of q\n\n\n\n\nsource:\n\n\nQuantEcon/src/discrete_rv.jl:31\n\n\n\n\n\n\nQuantEcon.ECDF \n\u00b6\n\n\nOne-dimensional empirical distribution function given a vector of\nobservations.\n\n\nFields\n\n\n\n\nobservations::Vector\n: The vector of observations\n\n\n\n\nsource:\n\n\nQuantEcon/src/ecdf.jl:20\n\n\n\n\n\n\nQuantEcon.LAE \n\u00b6\n\n\nA look ahead estimator associated with a given stochastic kernel p and a vector\nof observations X.\n\n\nFields\n\n\n\n\np::Function\n: The stochastic kernel. Signature is \np(x, y)\n and it should be\nvectorized in both inputs\n\n\nX::Matrix\n: A vector containing observations. Note that this can be passed as\nany kind of \nAbstractArray\n and will be coerced into an \nn x 1\n vector.\n\n\n\n\nsource:\n\n\nQuantEcon/src/lae.jl:34\n\n\n\n\n\n\nQuantEcon.MarkovChain \n\u00b6\n\n\nFinite-state discrete-time Markov chain.\n\n\nIt stores useful information such as the stationary distributions, and\ncommunication, recurrent, and cyclic classes, and allows simulation of state\ntransitions.\n\n\nFields\n\n\n\n\np::Matrix\n The transition matrix. Must be square, all elements must be\npositive, and all rows must sum to unity\n\n\n\n\nsource:\n\n\nQuantEcon/src/mc_tools.jl:30\n\n\n\n\n\n\nQuantEcon.RBLQ \n\u00b6\n\n\nRepresents infinite horizon robust LQ control problems of the form\n\n\nmin_{u_t}  sum_t beta^t {x_t' R x_t + u_t' Q u_t }\n\n\n\nsubject to\n\n\nx_{t+1} = A x_t + B u_t + C w_{t+1}\n\n\n\nand with model misspecification parameter theta.\n\n\nFields\n\n\n\n\nQ::Matrix{Float64}\n :  The cost(payoff) matrix for the controls. See above\nfor more. \nQ\n should be k x k and symmetric and positive definite\n\n\nR::Matrix{Float64}\n :  The cost(payoff) matrix for the state. See above for\nmore. \nR\n should be n x n and symmetric and non-negative definite\n\n\nA::Matrix{Float64}\n :  The matrix that corresponds with the state in the\nstate space system. \nA\n should be n x n\n\n\nB::Matrix{Float64}\n :  The matrix that corresponds with the control in the\nstate space system.  \nB\n should be n x k\n\n\nC::Matrix{Float64}\n :  The matrix that corresponds with the random process in\nthe state space system. \nC\n should be n x j\n\n\nbeta::Real\n : The discount factor in the robust control problem\n\n\ntheta::Real\n The robustness factor in the robust control problem\n\n\nk, n, j::Int\n : Dimensions of input matrices\n\n\n\n\nsource:\n\n\nQuantEcon/src/robustlq.jl:44\n\n\nInternal\n\n\n\n\n\n\neigen_solve \n\u00b6\n\n\nsolve x(P-I)=0 using either an eigendecomposition, lu factorization, or an\nalgorithm presented by Grassmann-Taksar-Heyman (GTH)\n\n\nArguments\n\n\n\n\np::Matrix\n : valid stochastic matrix\n\n\n\n\nReturns\n\n\n\n\nx::Matrix\n: A matrix whose columns contain stationary vectors of \np\n\n\n\n\nReferences\n\n\nThe following references were consulted for the GTH algorithm\n\n\n\n\nW. K. Grassmann, M. I. Taksar and D. P. Heyman, \"Regenerative Analysis and\nSteady State Distributions for Markov Chains,\" Operations Research (1985),\n1107-1116.\n\n\nW. J. Stewart, Probability, Markov Chains, Queues, and Simulation, Princeton\nUniversity Press, 2009.\n\n\n\n\nsource:\n\n\nQuantEcon/src/mc_tools.jl:139\n\n\n\n\n\n\nlu_solve \n\u00b6\n\n\nsolve x(P-I)=0 using either an eigendecomposition, lu factorization, or an\nalgorithm presented by Grassmann-Taksar-Heyman (GTH)\n\n\nArguments\n\n\n\n\np::Matrix\n : valid stochastic matrix\n\n\n\n\nReturns\n\n\n\n\nx::Matrix\n: A matrix whose columns contain stationary vectors of \np\n\n\n\n\nReferences\n\n\nThe following references were consulted for the GTH algorithm\n\n\n\n\nW. K. Grassmann, M. I. Taksar and D. P. Heyman, \"Regenerative Analysis and\nSteady State Distributions for Markov Chains,\" Operations Research (1985),\n1107-1116.\n\n\nW. J. Stewart, Probability, Markov Chains, Queues, and Simulation, Princeton\nUniversity Press, 2009.\n\n\n\n\nsource:\n\n\nQuantEcon/src/mc_tools.jl:139\n\n\n\n\n\n\nirreducible_subsets(mc::QuantEcon.MarkovChain) \n\u00b6\n\n\nFind the irreducible subsets of the \nMarkovChain\n\n\nArguments\n\n\n\n\nmc::MarkovChain\n : MarkovChain instance containing a valid stochastic matrix\n\n\n\n\nReturns\n\n\n\n\nx::Vector{Vector}\n: A \nVector\n containing \nVector{Int}\ns that describe the\nirreducible subsets of the transition matrix for p\n\n\n\n\nsource:\n\n\nQuantEcon/src/mc_tools.jl:154\n\n\n\n\n\n\nn_states(mc::QuantEcon.MarkovChain) \n\u00b6\n\n\nNumber of states in the markov chain \nmc\n\n\nsource:\n\n\nQuantEcon/src/mc_tools.jl:46", 
            "title": "QuantEcon"
        }, 
        {
            "location": "/api/QuantEcon/#quantecon", 
            "text": "", 
            "title": "QuantEcon"
        }, 
        {
            "location": "/api/QuantEcon/#exported", 
            "text": "do_quad  \u00b6  Approximate the integral of  f , given quadrature  nodes  and  weights  Arguments   f::Function : A callable function that is to be approximated over the domain\nspanned by  nodes .  nodes::Array : Quadrature nodes  weights::Array : Quadrature nodes  ;args... : additional positional arguments to pass to  f  ;kwargs... : additional keyword arguments to pass to  f   Returns   out::Float64  : The scalar that approximates integral of  f  on the hypercube\nformed by  [a, b]   source:  QuantEcon/src/quad.jl:811    ecdf  \u00b6  Evaluate the empirical cdf at one or more points  Arguments   e::ECDF : The  ECDF  instance  x::Union{Real, Array} : The point(s) at which to evaluate the ECDF   source:  QuantEcon/src/ecdf.jl:35    gth_solve  \u00b6  solve x(P-I)=0 using either an eigendecomposition, lu factorization, or an\nalgorithm presented by Grassmann-Taksar-Heyman (GTH)  Arguments   p::Matrix  : valid stochastic matrix   Returns   x::Matrix : A matrix whose columns contain stationary vectors of  p   References  The following references were consulted for the GTH algorithm   W. K. Grassmann, M. I. Taksar and D. P. Heyman, \"Regenerative Analysis and\nSteady State Distributions for Markov Chains,\" Operations Research (1985),\n1107-1116.  W. J. Stewart, Probability, Markov Chains, Queues, and Simulation, Princeton\nUniversity Press, 2009.   source:  QuantEcon/src/mc_tools.jl:139    periodogram  \u00b6  Computes the periodogram  I(w) = (1 / n) | sum_{t=0}^{n-1} x_t e^{itw} |^2  at the Fourier frequences w_j := 2 pi j / n, j = 0, ..., n - 1, using the fast\nFourier transform.  Only the frequences w_j in [0, pi] and corresponding values\nI(w_j) are returned.  If a window type is given then smoothing is performed.  Arguments   x::Array : An array containing the data to smooth  window_len::Int(7) : An odd integer giving the length of the window  window::String(\"hanning\") : A string giving the window type. Possible values\nare  flat ,  hanning ,  hamming ,  bartlett , or  blackman   Returns   w::Array{Float64} : Fourier frequencies at which the periodogram is evaluated  I_w::Array{Float64} : The periodogram at frequences  w   source:  QuantEcon/src/estspec.jl:115    qnwbeta  \u00b6  Computes nodes and weights for beta distribution  Arguments   n::Union(Int, Vector{Int})  : Number of desired nodes along each dimension  a::Union(Real, Vector{Real})  : First parameter of the beta distribution,\nalong each dimension  b::Union(Real, Vector{Real})  : Second parameter of the beta distribution,\nalong each dimension   Returns   nodes::Array{Float64}  : An array of quadrature nodes  weights::Array{Float64}  : An array of corresponding quadrature weights   Notes  If any of the parameters to this function are scalars while others are Vector s of length  n , the the scalar parameter is repeated  n  times.  References  Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.  source:  QuantEcon/src/quad.jl:354    qnwcheb  \u00b6  Computes multivariate Guass-Checbychev quadrature nodes and weights.  Arguments   n::Union(Int, Vector{Int})  : Number of desired nodes along each dimension  a::Union(Real, Vector{Real})  : Lower endpoint along each dimension  b::Union(Real, Vector{Real})  : Upper endpoint along each dimension   Returns   nodes::Array{Float64}  : An array of quadrature nodes  weights::Array{Float64}  : An array of corresponding quadrature weights   Notes  If any of the parameters to this function are scalars while others are Vector s of length  n , the the scalar parameter is repeated  n  times.  References  Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.  source:  QuantEcon/src/quad.jl:167    qnwequi  \u00b6  Generates equidistributed sequences with property that averages\nvalue of integrable function evaluated over the sequence converges\nto the integral as n goes to infinity.  Arguments   n::Union(Int, Vector{Int})  : Number of desired nodes along each dimension  a::Union(Real, Vector{Real})  : Lower endpoint along each dimension  b::Union(Real, Vector{Real})  : Upper endpoint along each dimension  kind::String(\"N\") : One of the following:  N - Neiderreiter (default)  W - Weyl  H - Haber  R - pseudo Random     Returns   nodes::Array{Float64}  : An array of quadrature nodes  weights::Array{Float64}  : An array of corresponding quadrature weights   Notes  If any of the parameters to this function are scalars while others are Vector s of length  n , the the scalar parameter is repeated  n  times.  References  Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.  source:  QuantEcon/src/quad.jl:726    qnwgamma  \u00b6  Computes nodes and weights for beta distribution  Arguments   n::Union(Int, Vector{Int})  : Number of desired nodes along each dimension  a::Union(Real, Vector{Real})  : First parameter of the gamma distribution,\nalong each dimension  b::Union(Real, Vector{Real})  : Second parameter of the gamma distribution,\nalong each dimension   Returns   nodes::Array{Float64}  : An array of quadrature nodes  weights::Array{Float64}  : An array of corresponding quadrature weights   Notes  If any of the parameters to this function are scalars while others are Vector s of length  n , the the scalar parameter is repeated  n  times.  References  Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.  source:  QuantEcon/src/quad.jl:464    qnwlege  \u00b6  Computes multivariate Guass-Legendre  quadrature nodes and weights.  Arguments   n::Union(Int, Vector{Int})  : Number of desired nodes along each dimension  a::Union(Real, Vector{Real})  : Lower endpoint along each dimension  b::Union(Real, Vector{Real})  : Upper endpoint along each dimension   Returns   nodes::Array{Float64}  : An array of quadrature nodes  weights::Array{Float64}  : An array of corresponding quadrature weights   Notes  If any of the parameters to this function are scalars while others are Vector s of length  n , the the scalar parameter is repeated  n  times.  References  Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.  source:  QuantEcon/src/quad.jl:99    qnwnorm  \u00b6  Computes nodes and weights for multivariate normal distribution  Arguments   n::Union(Int, Vector{Int})  : Number of desired nodes along each dimension  mu::Union(Real, Vector{Real})  : Mean along each dimension  sig2::Union(Real, Vector{Real}, Matrix{Real})(eye(length(n)))  : Covariance\nstructure   Returns   nodes::Array{Float64}  : An array of quadrature nodes  weights::Array{Float64}  : An array of corresponding quadrature weights   Notes  This function has many methods. I try to describe them here.  n  or  mu  can be a vector or a scalar. If just one is a scalar the other is\nrepeated to match the length of the other. If both are scalars, then the number\nof repeats is inferred from  sig2 .  sig2  can be a matrix, vector or scalar. If it is a matrix, it is treated as\nthe covariance matrix. If it is a vector, it is considered the diagonal of a\ndiagonal covariance matrix. If it is a scalar it is repeated along the diagonal\nas many times as necessary, where the number of repeats is determined by the\nlength of either n and/or mu (which ever is a vector).  If all 3 are scalars, then 1d nodes are computed.  mu  and  sig2  are treated as\nthe mean and variance of a 1d normal distribution  References  Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.  source:  QuantEcon/src/quad.jl:207    qnwsimp  \u00b6  Computes multivariate Simpson quadrature nodes and weights.  Arguments   n::Union(Int, Vector{Int})  : Number of desired nodes along each dimension  a::Union(Real, Vector{Real})  : Lower endpoint along each dimension  b::Union(Real, Vector{Real})  : Upper endpoint along each dimension   Returns   nodes::Array{Float64}  : An array of quadrature nodes  weights::Array{Float64}  : An array of corresponding quadrature weights   Notes  If any of the parameters to this function are scalars while others are Vector s of length  n , the the scalar parameter is repeated  n  times.  References  Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.  source:  QuantEcon/src/quad.jl:286    qnwtrap  \u00b6  Computes multivariate trapezoid quadrature nodes and weights.  Arguments   n::Union(Int, Vector{Int})  : Number of desired nodes along each dimension  a::Union(Real, Vector{Real})  : Lower endpoint along each dimension  b::Union(Real, Vector{Real})  : Upper endpoint along each dimension   Returns   nodes::Array{Float64}  : An array of quadrature nodes  weights::Array{Float64}  : An array of corresponding quadrature weights   Notes  If any of the parameters to this function are scalars while others are Vector s of length  n , the the scalar parameter is repeated  n  times.  References  Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.  source:  QuantEcon/src/quad.jl:323    quadrect  \u00b6  Integrate the d-dimensional function f on a rectangle with lower and upper bound\nfor dimension i defined by a[i] and b[i], respectively; using n[i] points.  Arguments   f::Function  The function to integrate over. This should be a function that\naccepts as its first argument a matrix representing points along each dimension\n(each dimension is a column). Other arguments that need to be passed to the\nfunction are caught by  args...  and `kwargs...``  n::Union(Int, Vector{Int})  : Number of desired nodes along each dimension  a::Union(Real, Vector{Real})  : Lower endpoint along each dimension  b::Union(Real, Vector{Real})  : Upper endpoint along each dimension  kind::String(\"lege\")  Specifies which type of integration to perform. Valid\nvalues are:  \"lege\"  : Gauss-Legendre  \"cheb\"  : Gauss-Chebyshev  \"trap\"  : trapezoid rule  \"simp\"  : Simpson rule  \"N\"  : Neiderreiter equidistributed sequence  \"W\"  : Weyl equidistributed sequence  \"H\"  : Haber  equidistributed sequence  \"R\"  : Monte Carlo    ;args... : additional positional arguments to pass to  f  ;kwargs... : additional keyword arguments to pass to  f   Returns   out::Float64  : The scalar that approximates integral of  f  on the hypercube\nformed by  [a, b]   References  Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.  source:  QuantEcon/src/quad.jl:853    F_to_K(rlq::QuantEcon.RBLQ,  F::Array{T, 2})  \u00b6  Compute agent 2's best cost-minimizing response  K , given  F .  Arguments   rlq::RBLQ : Instance of  RBLQ  type  F::Matrix{Float64} : A k x n array representing agent 1's policy   Returns   K::Matrix{Float64}  : Agent's best cost minimizing response corresponding to F  P::Matrix{Float64}  : The value function corresponding to  F   source:  QuantEcon/src/robustlq.jl:245    K_to_F(rlq::QuantEcon.RBLQ,  K::Array{T, 2})  \u00b6  Compute agent 1's best cost-minimizing response  K , given  F .  Arguments   rlq::RBLQ : Instance of  RBLQ  type  K::Matrix{Float64} : A k x n array representing the worst case matrix   Returns   F::Matrix{Float64}  : Agent's best cost minimizing response corresponding to K  P::Matrix{Float64}  : The value function corresponding to  K   source:  QuantEcon/src/robustlq.jl:277    ar_periodogram(x::Array{T, N})  \u00b6  Compute periodogram from data  x , using prewhitening, smoothing and recoloring.\nThe data is fitted to an AR(1) model for prewhitening, and the residuals are\nused to compute a first-pass periodogram with smoothing.  The fitted\ncoefficients are then used for recoloring.  Arguments   x::Array : An array containing the data to smooth  window_len::Int(7) : An odd integer giving the length of the window  window::String(\"hanning\") : A string giving the window type. Possible values\nare  flat ,  hanning ,  hamming ,  bartlett , or  blackman   Returns   w::Array{Float64} : Fourier frequencies at which the periodogram is evaluated  I_w::Array{Float64} : The periodogram at frequences  w   source:  QuantEcon/src/estspec.jl:136    ar_periodogram(x::Array{T, N},  window::AbstractString)  \u00b6  Compute periodogram from data  x , using prewhitening, smoothing and recoloring.\nThe data is fitted to an AR(1) model for prewhitening, and the residuals are\nused to compute a first-pass periodogram with smoothing.  The fitted\ncoefficients are then used for recoloring.  Arguments   x::Array : An array containing the data to smooth  window_len::Int(7) : An odd integer giving the length of the window  window::String(\"hanning\") : A string giving the window type. Possible values\nare  flat ,  hanning ,  hamming ,  bartlett , or  blackman   Returns   w::Array{Float64} : Fourier frequencies at which the periodogram is evaluated  I_w::Array{Float64} : The periodogram at frequences  w   source:  QuantEcon/src/estspec.jl:136    ar_periodogram(x::Array{T, N},  window::AbstractString,  window_len::Int64)  \u00b6  Compute periodogram from data  x , using prewhitening, smoothing and recoloring.\nThe data is fitted to an AR(1) model for prewhitening, and the residuals are\nused to compute a first-pass periodogram with smoothing.  The fitted\ncoefficients are then used for recoloring.  Arguments   x::Array : An array containing the data to smooth  window_len::Int(7) : An odd integer giving the length of the window  window::String(\"hanning\") : A string giving the window type. Possible values\nare  flat ,  hanning ,  hamming ,  bartlett , or  blackman   Returns   w::Array{Float64} : Fourier frequencies at which the periodogram is evaluated  I_w::Array{Float64} : The periodogram at frequences  w   source:  QuantEcon/src/estspec.jl:136    autocovariance(arma::QuantEcon.ARMA)  \u00b6  Compute the autocovariance function from the ARMA parameters\nover the integers range(num_autocov) using the spectral density\nand the inverse Fourier transform.  Arguments   arma::ARMA : Instance of  ARMA  type  ;num_autocov::Integer(16)  : The number of autocovariances to calculate   source:  QuantEcon/src/arma.jl:137    b_operator(rlq::QuantEcon.RBLQ,  P::Array{T, 2})  \u00b6  The D operator, mapping P into  B(P) := R - beta^2 A'PB(Q + beta B'PB)^{-1}B'PA + beta A'PA  and also returning  F := (Q + beta B'PB)^{-1} beta B'PA  Arguments   rlq::RBLQ : Instance of  RBLQ  type  P::Matrix{Float64}  :  size  is n x n   Returns   F::Matrix{Float64}  : The F matrix as defined above  new_p::Matrix{Float64}  : The matrix P after applying the B operator   source:  QuantEcon/src/robustlq.jl:116    compute_deterministic_entropy(rlq::QuantEcon.RBLQ,  F,  K,  x0)  \u00b6  Given  K  and  F , compute the value of deterministic entropy, which is sum_t\nbeta^t x_t' K'K x_t with x_{t+1} = (A - BF + CK) x_t.  Arguments   rlq::RBLQ : Instance of  RBLQ  type  F::Matrix{Float64}  The policy function, a k x n array  K::Matrix{Float64}  The worst case matrix, a j x n array  x0::Vector{Float64}  : The initial condition for state   Returns   e::Float64  The deterministic entropy   source:  QuantEcon/src/robustlq.jl:305    compute_fixed_point{TV}(T::Function,  v::TV)  \u00b6  Repeatedly apply a function to search for a fixed point  Approximates  T^\u221e v , where  T  is an operator (function) and  v  is an initial\nguess for the fixed point. Will terminate either when  T^{k+1}(v) - T^k v  \nerr_tol  or  max_iter  iterations has been exceeded.  Provided that  T  is a contraction mapping or similar,  the return value will\nbe an approximation to the fixed point of  T .  Arguments   T : A function representing the operator  T  v::TV : The initial condition. An object of type  TV  ;err_tol(1e-3) : Stopping tolerance for iterations  ;max_iter(50) : Maximum number of iterations  ;verbose(true) : Whether or not to print status updates to the user  ;print_skip(10)  : if  verbose  is true, how many iterations to apply between\n  print messages   Returns    '::TV': The fixed point of the operator  T . Has type  TV   Example  using QuantEcon\nT(x, \u03bc) = 4.0 * \u03bc * x * (1.0 - x)\nx_star = compute_fixed_point(x- T(x, 0.3), 0.4)  # (4\u03bc - 1)/(4\u03bc)  source:  QuantEcon/src/compute_fp.jl:50    d_operator(rlq::QuantEcon.RBLQ,  P::Array{T, 2})  \u00b6  The D operator, mapping P into  D(P) := P + PC(theta I - C'PC)^{-1} C'P.  Arguments   rlq::RBLQ : Instance of  RBLQ  type  P::Matrix{Float64}  :  size  is n x n   Returns   dP::Matrix{Float64}  : The matrix P after applying the D operator   source:  QuantEcon/src/robustlq.jl:87    draw(d::QuantEcon.DiscreteRV{T :Real})  \u00b6  Make a single draw from the discrete distribution  Arguments   d::DiscreteRV : The  DiscreteRV  type represetning the distribution   Returns   out::Int : One draw from the discrete distribution   source:  QuantEcon/src/discrete_rv.jl:51    draw{T}(d::QuantEcon.DiscreteRV{T},  k::Int64)  \u00b6  Make multiple draws from the discrete distribution represented by a DiscreteRV  instance  Arguments   d::DiscreteRV : The  DiscreteRV  type representing the distribution  k::Int :   Returns   out::Vector{Int} :  k  draws from  d   source:  QuantEcon/src/discrete_rv.jl:66    evaluate_F(rlq::QuantEcon.RBLQ,  F::Array{T, 2})  \u00b6  Given a fixed policy  F , with the interpretation u = -F x, this function\ncomputes the matrix P_F and constant d_F associated with discounted cost J_F(x) =\nx' P_F x + d_F.  Arguments   rlq::RBLQ : Instance of  RBLQ  type  F::Matrix{Float64}  :  The policy function, a k x n array   Returns   P_F::Matrix{Float64}  : Matrix for discounted cost  d_F::Float64  : Constant for discounted cost  K_F::Matrix{Float64}  : Worst case policy  O_F::Matrix{Float64}  : Matrix for discounted entropy  o_F::Float64  : Constant for discounted entropy   source:  QuantEcon/src/robustlq.jl:332    impulse_response(arma::QuantEcon.ARMA)  \u00b6  Get the impulse response corresponding to our model.  Arguments   arma::ARMA : Instance of  ARMA  type  ;impulse_length::Integer(30) : Length of horizon for calucluating impulse\nreponse. Must be at least as long as the  p  fields of  arma   Returns   psi::Vector{Float64} :  psi[j]  is the response at lag j of the impulse\nresponse. We take psi[1] as unity.   source:  QuantEcon/src/arma.jl:162    lae_est{T}(l::QuantEcon.LAE,  y::AbstractArray{T, N})  \u00b6  A vectorized function that returns the value of the look ahead estimate at the\nvalues in the array y.  Arguments   l::LAE : Instance of  LAE  type  y::Array : Array that becomes the  y  in  l.p(l.x, y)   Returns   psi_vals::Vector : Density at  (x, y)   source:  QuantEcon/src/lae.jl:58    m_quadratic_sum(A::Array{T, 2},  B::Array{T, 2})  \u00b6  Computes the quadratic sum  V = sum_{j=0}^{infty} A^j B A^{j'}  V is computed by solving the corresponding discrete lyapunov equation using the\ndoubling algorithm.  See the documentation of  solve_discrete_lyapunov  for\nmore information.  Arguments   A::Matrix{Float64}  : An n x n matrix as described above.  We assume in order\nfor convergence that the eigenvalues of A have moduli bounded by unity  B::Matrix{Float64}  : An n x n matrix as described above.  We assume in order\nfor convergence that the eigenvalues of B have moduli bounded by unity  max_it::Int(50)  : Maximum number of iterations   Returns   gamma1::Matrix{Float64}  : Represents the value V   source:  QuantEcon/src/quadsums.jl:81    mc_compute_stationary(mc::QuantEcon.MarkovChain)  \u00b6  calculate the stationary distributions associated with a N-state markov chain  Arguments   mc::MarkovChain  : MarkovChain instance containing a valid stochastic matrix  ;method::Symbol(:gth) : One of  gth ,  lu , and  eigen ; specifying which\nof the three  _solve  methods to use.   Returns   dists::Matrix{Float64} : N x M matrix where each column is a stationary\ndistribution of  mc.p   source:  QuantEcon/src/mc_tools.jl:197    mc_sample_path!(mc::QuantEcon.MarkovChain,  samples::Array{T, N})  \u00b6  Fill  samples  with samples from the Markov chain  mc  Arguments   mc::MarkovChain  : MarkovChain instance containing a valid stochastic matrix  samples::Array{Int}  : Pre-allocated vector of integers to be filled with\nsamples from the markov chain  mc . The first element will be used as the\ninitial state and all other elements will be over-written.   Returns  None modifies  samples  in place  source:  QuantEcon/src/mc_tools.jl:286    mc_sample_path(mc::QuantEcon.MarkovChain)  \u00b6  Simulate a Markov chain starting from an initial state  Arguments   mc::MarkovChain  : MarkovChain instance containing a valid stochastic matrix  init::Int(rand(1:n_states(mc)))  : The index of the initial state. This should\nbe an integer between 1 and  n_states(mc)  sample_size::Int(1000) : The number of samples to collect  ;burn::Int(0) : The burn in length. Routine drops first  burn  of the sample_size  total samples collected   Returns   samples::Vector{Int} : Vector of simulated states   source:  QuantEcon/src/mc_tools.jl:238    mc_sample_path(mc::QuantEcon.MarkovChain,  init::Array{T, 1})  \u00b6  Simulate a Markov chain starting from an initial distribution  Arguments   mc::MarkovChain  : MarkovChain instance containing a valid stochastic matrix  init::Vector  : A vector of length  n_state(mc)  specifying the number\nprobability of being in seach state in the initial period  sample_size::Int(1000) : The number of samples to collect  ;burn::Int(0) : The burn in length. Routine drops first  burn  of the sample_size  total samples collected   Returns   samples::Vector{Int} : Vector of simulated states   source:  QuantEcon/src/mc_tools.jl:265    mc_sample_path(mc::QuantEcon.MarkovChain,  init::Array{T, 1},  sample_size::Int64)  \u00b6  Simulate a Markov chain starting from an initial distribution  Arguments   mc::MarkovChain  : MarkovChain instance containing a valid stochastic matrix  init::Vector  : A vector of length  n_state(mc)  specifying the number\nprobability of being in seach state in the initial period  sample_size::Int(1000) : The number of samples to collect  ;burn::Int(0) : The burn in length. Routine drops first  burn  of the sample_size  total samples collected   Returns   samples::Vector{Int} : Vector of simulated states   source:  QuantEcon/src/mc_tools.jl:265    mc_sample_path(mc::QuantEcon.MarkovChain,  init::Int64)  \u00b6  Simulate a Markov chain starting from an initial state  Arguments   mc::MarkovChain  : MarkovChain instance containing a valid stochastic matrix  init::Int(rand(1:n_states(mc)))  : The index of the initial state. This should\nbe an integer between 1 and  n_states(mc)  sample_size::Int(1000) : The number of samples to collect  ;burn::Int(0) : The burn in length. Routine drops first  burn  of the sample_size  total samples collected   Returns   samples::Vector{Int} : Vector of simulated states   source:  QuantEcon/src/mc_tools.jl:238    mc_sample_path(mc::QuantEcon.MarkovChain,  init::Int64,  sample_size::Int64)  \u00b6  Simulate a Markov chain starting from an initial state  Arguments   mc::MarkovChain  : MarkovChain instance containing a valid stochastic matrix  init::Int(rand(1:n_states(mc)))  : The index of the initial state. This should\nbe an integer between 1 and  n_states(mc)  sample_size::Int(1000) : The number of samples to collect  ;burn::Int(0) : The burn in length. Routine drops first  burn  of the sample_size  total samples collected   Returns   samples::Vector{Int} : Vector of simulated states   source:  QuantEcon/src/mc_tools.jl:238    nnash(a,  b1,  b2,  r1,  r2,  q1,  q2,  s1,  s2,  w1,  w2,  m1,  m2)  \u00b6  Compute the limit of a Nash linear quadratic dynamic game.  Player  i  minimizes  sum_{t=1}^{inf}(x_t' r_i x_t + 2 x_t' w_i\nu_{it} +u_{it}' q_i u_{it} + u_{jt}' s_i u_{jt} + 2 u_{jt}'\nm_i u_{it})  subject to the law of motion  x_{t+1} = A x_t + b_1 u_{1t} + b_2 u_{2t}  and a perceived control law :math: u_j(t) = - f_j x_t  for the other player.  The solution computed in this routine is the  f_i  and  p_i  of the associated\ndouble optimal linear regulator problem.  Arguments   A  : Corresponds to the above equation, should be of size (n, n)  B1  : As above, size (n, k_1)  B2  : As above, size (n, k_2)  R1  : As above, size (n, n)  R2  : As above, size (n, n)  Q1  : As above, size (k_1, k_1)  Q2  : As above, size (k_2, k_2)  S1  : As above, size (k_1, k_1)  S2  : As above, size (k_2, k_2)  W1  : As above, size (n, k_1)  W2  : As above, size (n, k_2)  M1  : As above, size (k_2, k_1)  M2  : As above, size (k_1, k_2)  ;beta::Float64(1.0)  Discount rate  ;tol::Float64(1e-8)  : Tolerance level for convergence  ;max_iter::Int(1000)  : Maximum number of iterations allowed   Returns   F1::Matrix{Float64} : (k_1, n) matrix representing feedback law for agent 1  F2::Matrix{Float64} : (k_2, n) matrix representing feedback law for agent 2  P1::Matrix{Float64} : (n, n) matrix representing the steady-state solution to the associated discrete matrix ticcati equation for agent 1  P2::Matrix{Float64} : (n, n) matrix representing the steady-state solution to the associated discrete matrix riccati equation for agent 2   source:  QuantEcon/src/lqnash.jl:57    pdf(d::QuantEcon.BetaBinomial)  \u00b6  Evaluate the pdf of the distributions at the points 0, 1, ..., k  Arguments  d::BetaBinomial : Instance of  BetaBinomial  type  Returns   probs::vector{Float64} : pdf of the distribution  d , at  0:d.k   source:  QuantEcon/src/distributions.jl:64    qnwlogn(n,  mu,  sig2)  \u00b6  Computes quadrature nodes and weights for multivariate uniform distribution  Arguments   n::Union(Int, Vector{Int})  : Number of desired nodes along each dimension  mu::Union(Real, Vector{Real})  : Mean along each dimension  sig2::Union(Real, Vector{Real}, Matrix{Real})(eye(length(n)))  : Covariance\nstructure   Returns   nodes::Array{Float64}  : An array of quadrature nodes  weights::Array{Float64}  : An array of corresponding quadrature weights   Notes  See also the documentation for  qnwnorm  References  Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.  source:  QuantEcon/src/quad.jl:693    qnwunif(n,  a,  b)  \u00b6  Computes quadrature nodes and weights for multivariate uniform distribution  Arguments   n::Union(Int, Vector{Int})  : Number of desired nodes along each dimension  a::Union(Real, Vector{Real})  : Lower endpoint along each dimension  b::Union(Real, Vector{Real})  : Upper endpoint along each dimension   Returns   nodes::Array{Float64}  : An array of quadrature nodes  weights::Array{Float64}  : An array of corresponding quadrature weights   Notes  If any of the parameters to this function are scalars while others are Vector s of length  n , the the scalar parameter is repeated  n  times.  References  Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and\nFinance, MIT Press, 2002.  source:  QuantEcon/src/quad.jl:668    robust_rule(rlq::QuantEcon.RBLQ)  \u00b6  Solves the robust control problem.  The algorithm here tricks the problem into a stacked LQ problem, as described in\nchapter 2 of Hansen- Sargent's text \"Robustness.\"  The optimal control with\nobserved state is  u_t = - F x_t  And the value function is -x'Px  Arguments   rlq::RBLQ : Instance of  RBLQ  type   Returns   F::Matrix{Float64}  : The optimal control matrix from above  P::Matrix{Float64}  : The positive semi-definite matrix defining the value\nfunction  K::Matrix{Float64}  : the worst-case shock matrix  K , where w_{t+1} = K x_t  is the worst case shock   source:  QuantEcon/src/robustlq.jl:154    robust_rule_simple(rlq::QuantEcon.RBLQ)  \u00b6  Solve the robust LQ problem  A simple algorithm for computing the robust policy F and the\ncorresponding value function P, based around straightforward\niteration with the robust Bellman operator.  This function is\neasier to understand but one or two orders of magnitude slower\nthan self.robust_rule().  For more information see the docstring\nof that method.  Arguments   rlq::RBLQ : Instance of  RBLQ  type  P_init::Matrix{Float64}(zeros(rlq.n, rlq.n))  : The initial guess for the\nvalue function matrix  ;max_iter::Int(80) : Maximum number of iterations that are allowed  ;tol::Real(1e-8)  The tolerance for convergence   Returns   F::Matrix{Float64}  : The optimal control matrix from above  P::Matrix{Float64}  : The positive semi-definite matrix defining the value\nfunction  K::Matrix{Float64}  : the worst-case shock matrix  K , where w_{t+1} = K x_t  is the worst case shock   source:  QuantEcon/src/robustlq.jl:202    robust_rule_simple(rlq::QuantEcon.RBLQ,  P::Array{T, 2})  \u00b6  Solve the robust LQ problem  A simple algorithm for computing the robust policy F and the\ncorresponding value function P, based around straightforward\niteration with the robust Bellman operator.  This function is\neasier to understand but one or two orders of magnitude slower\nthan self.robust_rule().  For more information see the docstring\nof that method.  Arguments   rlq::RBLQ : Instance of  RBLQ  type  P_init::Matrix{Float64}(zeros(rlq.n, rlq.n))  : The initial guess for the\nvalue function matrix  ;max_iter::Int(80) : Maximum number of iterations that are allowed  ;tol::Real(1e-8)  The tolerance for convergence   Returns   F::Matrix{Float64}  : The optimal control matrix from above  P::Matrix{Float64}  : The positive semi-definite matrix defining the value\nfunction  K::Matrix{Float64}  : the worst-case shock matrix  K , where w_{t+1} = K x_t  is the worst case shock   source:  QuantEcon/src/robustlq.jl:202    rouwenhorst(N::Int64,  \u03c1::Real,  \u03c3::Real)  \u00b6  Rouwenhorst's method to approximate AR(1) processes.  The process follows  y_t = \u03bc + \u03c1 y_{t-1} + \u03b5_t,  where \u03b5_t ~ N (0, \u03c3^2)  Arguments   N::Int  : Number of points in markov process  \u03c1::Real  : Persistence parameter in AR(1) process  \u03c3::Real  : Standard deviation of random component of AR(1) process  \u03bc::Real(0.0)  :  Mean of AR(1) process   Returns   y::Vector{Float64}  : Nodes in the state space  \u0398::Matrix{Float64}  Matrix transition probabilities for Markov Process   source:  QuantEcon/src/markov_approx.jl:103    rouwenhorst(N::Int64,  \u03c1::Real,  \u03c3::Real,  \u03bc::Real)  \u00b6  Rouwenhorst's method to approximate AR(1) processes.  The process follows  y_t = \u03bc + \u03c1 y_{t-1} + \u03b5_t,  where \u03b5_t ~ N (0, \u03c3^2)  Arguments   N::Int  : Number of points in markov process  \u03c1::Real  : Persistence parameter in AR(1) process  \u03c3::Real  : Standard deviation of random component of AR(1) process  \u03bc::Real(0.0)  :  Mean of AR(1) process   Returns   y::Vector{Float64}  : Nodes in the state space  \u0398::Matrix{Float64}  Matrix transition probabilities for Markov Process   source:  QuantEcon/src/markov_approx.jl:103    simulation(arma::QuantEcon.ARMA)  \u00b6  Compute a simulated sample path assuming Gaussian shocks.  Arguments   arma::ARMA : Instance of  ARMA  type  ;ts_length::Integer(90) : Length of simulation  ;impulse_length::Integer(30) : Horizon for calculating impulse response\n(see also docstring for  impulse_response )   Returns   X::Vector{Float64} : Simulation of the ARMA model  arma   source:  QuantEcon/src/arma.jl:194    smooth(x::Array{T, N})  \u00b6  Version of  smooth  where  window_len  and  window  are keyword arguments  source:  QuantEcon/src/estspec.jl:70    smooth(x::Array{T, N},  window_len::Int64)  \u00b6  Smooth the data in x using convolution with a window of requested size and type.  Arguments   x::Array : An array containing the data to smooth  window_len::Int(7) : An odd integer giving the length of the window  window::String(\"hanning\") : A string giving the window type. Possible values\nare  flat ,  hanning ,  hamming ,  bartlett , or  blackman   Returns   out::Array : The array of smoothed data   source:  QuantEcon/src/estspec.jl:30    smooth(x::Array{T, N},  window_len::Int64,  window::AbstractString)  \u00b6  Smooth the data in x using convolution with a window of requested size and type.  Arguments   x::Array : An array containing the data to smooth  window_len::Int(7) : An odd integer giving the length of the window  window::String(\"hanning\") : A string giving the window type. Possible values\nare  flat ,  hanning ,  hamming ,  bartlett , or  blackman   Returns   out::Array : The array of smoothed data   source:  QuantEcon/src/estspec.jl:30    solve_discrete_lyapunov(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}})  \u00b6  Solves the discrete lyapunov equation.  The problem is given by  AXA' - X + B = 0  X  is computed by using a doubling algorithm. In particular, we iterate to\nconvergence on  X_j  with the following recursions for j = 1, 2,...\nstarting from X_0 = B, a_0 = A:  a_j = a_{j-1} a_{j-1}\nX_j = X_{j-1} + a_{j-1} X_{j-1} a_{j-1}'  Arguments   A::Matrix{Float64}  : An n x n matrix as described above.  We assume in order\nfor  convergence that the eigenvalues of  A  have moduli bounded by unity  B::Matrix{Float64}  :  An n x n matrix as described above.  We assume in order\nfor convergence that the eigenvalues of  B  have moduli bounded by unity  max_it::Int(50)  :  Maximum number of iterations   Returns   gamma1::Matrix{Float64}  Represents the value X   source:  QuantEcon/src/matrix_eqn.jl:30    solve_discrete_lyapunov(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}},  max_it::Int64)  \u00b6  Solves the discrete lyapunov equation.  The problem is given by  AXA' - X + B = 0  X  is computed by using a doubling algorithm. In particular, we iterate to\nconvergence on  X_j  with the following recursions for j = 1, 2,...\nstarting from X_0 = B, a_0 = A:  a_j = a_{j-1} a_{j-1}\nX_j = X_{j-1} + a_{j-1} X_{j-1} a_{j-1}'  Arguments   A::Matrix{Float64}  : An n x n matrix as described above.  We assume in order\nfor  convergence that the eigenvalues of  A  have moduli bounded by unity  B::Matrix{Float64}  :  An n x n matrix as described above.  We assume in order\nfor convergence that the eigenvalues of  B  have moduli bounded by unity  max_it::Int(50)  :  Maximum number of iterations   Returns   gamma1::Matrix{Float64}  Represents the value X   source:  QuantEcon/src/matrix_eqn.jl:30    solve_discrete_riccati(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}},  Q::Union{T, Array{T, N}},  R::Union{T, Array{T, N}})  \u00b6  Solves the discrete-time algebraic Riccati equation  The prolem is defined as  X = A'XA - (N + B'XA)'(B'XB + R)^{-1}(N + B'XA) + Q  via a modified structured doubling algorithm.  An explanation of the algorithm\ncan be found in the reference below.  Arguments   A  : k x k array.  B  : k x n array  R  : n x n, should be symmetric and positive definite  Q  : k x k, should be symmetric and non-negative definite  N::Matrix{Float64}(zeros(size(R, 1), size(Q, 1)))  : n x k array  tolerance::Float64(1e-10)  Tolerance level for convergence  max_iter::Int(50)  : The maximum number of iterations allowed   Note that  A, B, R, Q  can either be real (i.e. k, n = 1) or matrices.  Returns   X::Matrix{Float64}  The fixed point of the Riccati equation; a  k x k array\nrepresenting the approximate solution   References  Chiang, Chun-Yueh, Hung-Yuan Fan, and Wen-Wei Lin. \"STRUCTURED DOUBLING\nALGORITHM FOR DISCRETE-TIME ALGEBRAIC RICCATI EQUATIONS WITH SINGULAR CONTROL\nWEIGHTING MATRICES.\" Taiwanese Journal of Mathematics 14, no. 3A (2010): pp-935.  source:  QuantEcon/src/matrix_eqn.jl:96    solve_discrete_riccati(A::Union{T, Array{T, N}},  B::Union{T, Array{T, N}},  Q::Union{T, Array{T, N}},  R::Union{T, Array{T, N}},  N::Union{T, Array{T, N}})  \u00b6  Solves the discrete-time algebraic Riccati equation  The prolem is defined as  X = A'XA - (N + B'XA)'(B'XB + R)^{-1}(N + B'XA) + Q  via a modified structured doubling algorithm.  An explanation of the algorithm\ncan be found in the reference below.  Arguments   A  : k x k array.  B  : k x n array  R  : n x n, should be symmetric and positive definite  Q  : k x k, should be symmetric and non-negative definite  N::Matrix{Float64}(zeros(size(R, 1), size(Q, 1)))  : n x k array  tolerance::Float64(1e-10)  Tolerance level for convergence  max_iter::Int(50)  : The maximum number of iterations allowed   Note that  A, B, R, Q  can either be real (i.e. k, n = 1) or matrices.  Returns   X::Matrix{Float64}  The fixed point of the Riccati equation; a  k x k array\nrepresenting the approximate solution   References  Chiang, Chun-Yueh, Hung-Yuan Fan, and Wen-Wei Lin. \"STRUCTURED DOUBLING\nALGORITHM FOR DISCRETE-TIME ALGEBRAIC RICCATI EQUATIONS WITH SINGULAR CONTROL\nWEIGHTING MATRICES.\" Taiwanese Journal of Mathematics 14, no. 3A (2010): pp-935.  source:  QuantEcon/src/matrix_eqn.jl:96    spectral_density(arma::QuantEcon.ARMA)  \u00b6  Compute the spectral density function.  The spectral density is the discrete time Fourier transform of the\nautocovariance function. In particular,  f(w) = sum_k gamma(k) exp(-ikw)  where gamma is the autocovariance function and the sum is over\nthe set of all integers.  Arguments   arma::ARMA : Instance of  ARMA  type  ;two_pi::Bool(true) : Compute the spectral density function over [0, pi] if\n  false and [0, 2 pi] otherwise.  ;res(1200)  : If  res  is a scalar then the spectral density is computed at res  frequencies evenly spaced around the unit circle, but if  res  is an array\nthen the function computes the response at the frequencies given by the array   Returns   w::Vector{Float64} : The normalized frequencies at which h was computed, in\n  radians/sample  spect::Vector{Float64}  : The frequency response   source:  QuantEcon/src/arma.jl:116    tauchen(N::Int64,  \u03c1::Real,  \u03c3::Real)  \u00b6  Tauchen's (1996) method for approximating AR(1) process with finite markov chain  The process follows  y_t = \u03bc + \u03c1 y_{t-1} + \u03b5_t,  where \u03b5_t ~ N (0, \u03c3^2)  Arguments   N::Int : Number of points in markov process  \u03c1::Real  : Persistence parameter in AR(1) process  \u03c3::Real  : Standard deviation of random component of AR(1) process  \u03bc::Real(0.0)  : Mean of AR(1) process  n_std::Int(3)  : The number of standard deviations to each side the process\nshould span   Returns   y::Vector{Float64}  : Nodes in the state space  \u03a0::Matrix{Float64}  Matrix transition probabilities for Markov Process   source:  QuantEcon/src/markov_approx.jl:41    tauchen(N::Int64,  \u03c1::Real,  \u03c3::Real,  \u03bc::Real)  \u00b6  Tauchen's (1996) method for approximating AR(1) process with finite markov chain  The process follows  y_t = \u03bc + \u03c1 y_{t-1} + \u03b5_t,  where \u03b5_t ~ N (0, \u03c3^2)  Arguments   N::Int : Number of points in markov process  \u03c1::Real  : Persistence parameter in AR(1) process  \u03c3::Real  : Standard deviation of random component of AR(1) process  \u03bc::Real(0.0)  : Mean of AR(1) process  n_std::Int(3)  : The number of standard deviations to each side the process\nshould span   Returns   y::Vector{Float64}  : Nodes in the state space  \u03a0::Matrix{Float64}  Matrix transition probabilities for Markov Process   source:  QuantEcon/src/markov_approx.jl:41    tauchen(N::Int64,  \u03c1::Real,  \u03c3::Real,  \u03bc::Real,  n_std::Int64)  \u00b6  Tauchen's (1996) method for approximating AR(1) process with finite markov chain  The process follows  y_t = \u03bc + \u03c1 y_{t-1} + \u03b5_t,  where \u03b5_t ~ N (0, \u03c3^2)  Arguments   N::Int : Number of points in markov process  \u03c1::Real  : Persistence parameter in AR(1) process  \u03c3::Real  : Standard deviation of random component of AR(1) process  \u03bc::Real(0.0)  : Mean of AR(1) process  n_std::Int(3)  : The number of standard deviations to each side the process\nshould span   Returns   y::Vector{Float64}  : Nodes in the state space  \u03a0::Matrix{Float64}  Matrix transition probabilities for Markov Process   source:  QuantEcon/src/markov_approx.jl:41    var_quadratic_sum(A::Union{T, Array{T, N}},  C::Union{T, Array{T, N}},  H::Union{T, Array{T, N}},  bet::Real,  x0::Union{T, Array{T, N}})  \u00b6  Computes the expected discounted quadratic sum  q(x_0) = E sum_{t=0}^{infty} beta^t x_t' H x_t  Here {x_t} is the VAR process x_{t+1} = A x_t + C w_t with {w_t}\nstandard normal and x_0 the initial condition.  Arguments   A::Union(Float64, Matrix{Float64})  The n x n matrix described above (scalar)\nif n = 1  C::Union(Float64, Matrix{Float64})  The n x n matrix described above (scalar)\nif n = 1  H::Union(Float64, Matrix{Float64})  The n x n matrix described above (scalar)\nif n = 1  beta::Float64 : Discount factor in (0, 1)  x_0::Union(Float64, Vector{Float64})  The initial condtion. A conformable\narray (of length n) or a scalar if n=1   Returns   q0::Float64  : Represents the value q(x_0)   Notes  The formula for computing q(x_0) is q(x_0) = x_0' Q x_0 + v where   Q is the solution to Q = H + beta A' Q A and  v =   race(C' Q C) \beta / (1 - \beta)   source:  QuantEcon/src/quadsums.jl:41    QuantEcon.ARMA  \u00b6  Represents a scalar ARMA(p, q) process  If phi and theta are scalars, then the model is\nunderstood to be  X_t = phi X_{t-1} + epsilon_t + theta epsilon_{t-1}  where epsilon_t is a white noise process with standard\ndeviation sigma.  If phi and theta are arrays or sequences,\nthen the interpretation is the ARMA(p, q) model  X_t = phi_1 X_{t-1} + ... + phi_p X_{t-p} +\nepsilon_t + theta_1 epsilon_{t-1} + ...  +\ntheta_q epsilon_{t-q}  where   phi = (phi_1, phi_2,..., phi_p)  theta = (theta_1, theta_2,..., theta_q)  sigma is a scalar, the standard deviation of the white noise   Fields   phi::Vector  : AR parameters phi_1, ..., phi_p  theta::Vector  : MA parameters theta_1, ..., theta_q  p::Integer  : Number of AR coefficients  q::Integer  : Number of MA coefficients  sigma::Real  : Variance of white noise  ma_poly::Vector  : MA polynomial --- filtering representatoin  ar_poly::Vector  : AR polynomial --- filtering representation   Examples  using QuantEcon\nphi = 0.5\ntheta = [0.0, -0.8]\nsigma = 1.0\nlp = ARMA(phi, theta, sigma)\nrequire(joinpath(Pkg.dir( QuantEcon ),  examples ,  arma_plots.jl ))\nquad_plot(lp)  source:  QuantEcon/src/arma.jl:64    QuantEcon.BetaBinomial  \u00b6  The Beta-Binomial distribution  Fields   n, a, b::Float64  The three paramters to the distribution   Notes  See also http://en.wikipedia.org/wiki/Beta-binomial_distribution  source:  QuantEcon/src/distributions.jl:27    QuantEcon.DiscreteRV{T :Real}  \u00b6  Generates an array of draws from a discrete random variable with\nvector of probabilities given by q.  Fields   q::Vector{T :Real} : A vector of non-negative probabilities that sum to 1  Q::Vector{T :Real} : The cumulative sum of q   source:  QuantEcon/src/discrete_rv.jl:31    QuantEcon.ECDF  \u00b6  One-dimensional empirical distribution function given a vector of\nobservations.  Fields   observations::Vector : The vector of observations   source:  QuantEcon/src/ecdf.jl:20    QuantEcon.LAE  \u00b6  A look ahead estimator associated with a given stochastic kernel p and a vector\nof observations X.  Fields   p::Function : The stochastic kernel. Signature is  p(x, y)  and it should be\nvectorized in both inputs  X::Matrix : A vector containing observations. Note that this can be passed as\nany kind of  AbstractArray  and will be coerced into an  n x 1  vector.   source:  QuantEcon/src/lae.jl:34    QuantEcon.MarkovChain  \u00b6  Finite-state discrete-time Markov chain.  It stores useful information such as the stationary distributions, and\ncommunication, recurrent, and cyclic classes, and allows simulation of state\ntransitions.  Fields   p::Matrix  The transition matrix. Must be square, all elements must be\npositive, and all rows must sum to unity   source:  QuantEcon/src/mc_tools.jl:30    QuantEcon.RBLQ  \u00b6  Represents infinite horizon robust LQ control problems of the form  min_{u_t}  sum_t beta^t {x_t' R x_t + u_t' Q u_t }  subject to  x_{t+1} = A x_t + B u_t + C w_{t+1}  and with model misspecification parameter theta.  Fields   Q::Matrix{Float64}  :  The cost(payoff) matrix for the controls. See above\nfor more.  Q  should be k x k and symmetric and positive definite  R::Matrix{Float64}  :  The cost(payoff) matrix for the state. See above for\nmore.  R  should be n x n and symmetric and non-negative definite  A::Matrix{Float64}  :  The matrix that corresponds with the state in the\nstate space system.  A  should be n x n  B::Matrix{Float64}  :  The matrix that corresponds with the control in the\nstate space system.   B  should be n x k  C::Matrix{Float64}  :  The matrix that corresponds with the random process in\nthe state space system.  C  should be n x j  beta::Real  : The discount factor in the robust control problem  theta::Real  The robustness factor in the robust control problem  k, n, j::Int  : Dimensions of input matrices   source:  QuantEcon/src/robustlq.jl:44", 
            "title": "Exported"
        }, 
        {
            "location": "/api/QuantEcon/#internal", 
            "text": "eigen_solve  \u00b6  solve x(P-I)=0 using either an eigendecomposition, lu factorization, or an\nalgorithm presented by Grassmann-Taksar-Heyman (GTH)  Arguments   p::Matrix  : valid stochastic matrix   Returns   x::Matrix : A matrix whose columns contain stationary vectors of  p   References  The following references were consulted for the GTH algorithm   W. K. Grassmann, M. I. Taksar and D. P. Heyman, \"Regenerative Analysis and\nSteady State Distributions for Markov Chains,\" Operations Research (1985),\n1107-1116.  W. J. Stewart, Probability, Markov Chains, Queues, and Simulation, Princeton\nUniversity Press, 2009.   source:  QuantEcon/src/mc_tools.jl:139    lu_solve  \u00b6  solve x(P-I)=0 using either an eigendecomposition, lu factorization, or an\nalgorithm presented by Grassmann-Taksar-Heyman (GTH)  Arguments   p::Matrix  : valid stochastic matrix   Returns   x::Matrix : A matrix whose columns contain stationary vectors of  p   References  The following references were consulted for the GTH algorithm   W. K. Grassmann, M. I. Taksar and D. P. Heyman, \"Regenerative Analysis and\nSteady State Distributions for Markov Chains,\" Operations Research (1985),\n1107-1116.  W. J. Stewart, Probability, Markov Chains, Queues, and Simulation, Princeton\nUniversity Press, 2009.   source:  QuantEcon/src/mc_tools.jl:139    irreducible_subsets(mc::QuantEcon.MarkovChain)  \u00b6  Find the irreducible subsets of the  MarkovChain  Arguments   mc::MarkovChain  : MarkovChain instance containing a valid stochastic matrix   Returns   x::Vector{Vector} : A  Vector  containing  Vector{Int} s that describe the\nirreducible subsets of the transition matrix for p   source:  QuantEcon/src/mc_tools.jl:154    n_states(mc::QuantEcon.MarkovChain)  \u00b6  Number of states in the markov chain  mc  source:  QuantEcon/src/mc_tools.jl:46", 
            "title": "Internal"
        }, 
        {
            "location": "/api/QuantEcon.Models/", 
            "text": "QuantEcon.Models\n\n\nExported\n\n\n\n\n\n\nbellman_operator \n\u00b6\n\n\nApply the Bellman operator for a given model and initial value\n. See the specific methods of the mutating function for more details on arguments\n\n\nsource:\n\n\nQuantEcon/src/Models.jl:63\n\n\n\n\n\n\nbellman_operator! \n\u00b6\n\n\nApply the Bellman operator for a given model and initial value\n. See the specific methods of the mutating function for more details on arguments\n\n\nThe last positional argument passed to this function will be over-written\n\n\nsource:\n\n\nQuantEcon/src/Models.jl:70\n\n\n\n\n\n\nget_greedy \n\u00b6\n\n\nExtract the greedy policy (policy function) of the model\n. See the specific methods of the mutating function for more details on arguments\n\n\nsource:\n\n\nQuantEcon/src/Models.jl:75\n\n\n\n\n\n\nget_greedy! \n\u00b6\n\n\nExtract the greedy policy (policy function) of the model\n. See the specific methods of the mutating function for more details on arguments\n\n\nThe last positional argument passed to this function will be over-written\n\n\nsource:\n\n\nQuantEcon/src/Models.jl:82\n\n\n\n\n\n\nbellman_operator!(cp::QuantEcon.Models.CareerWorkerProblem,  v::Array{T, N},  out::Array{T, N}) \n\u00b6\n\n\nApply the Bellman operator for a given model and initial value\n.\n\n\nArguments\n\n\n\n\ncp::CareerWorkerProblem\n : Instance of \nCareerWorkerProblem\n\n\nv::Matrix\n: Current guess for the value function\n\n\nout::Matrix\n : Storage for output\n\n\n;ret_policy::Bool(false)\n: Toggles return of value or policy functions\n\n\n\n\nReturns\n\n\nNone, \nout\n is updated in place. If \nret_policy == true\n out is filled with the\npolicy function, otherwise the value function is stored in \nout\n.\n\n\nsource:\n\n\nQuantEcon/src/models/career.jl:96\n\n\n\n\n\n\nbellman_operator!(cp::QuantEcon.Models.ConsumerProblem,  V::Array{T, 2},  out::Array{T, 2}) \n\u00b6\n\n\nApply the Bellman operator for a given model and initial value\n.\n\n\nArguments\n\n\n\n\ncp::ConsumerProblem\n : Instance of \nConsumerProblem\n\n\nv::Matrix\n: Current guess for the value function\n\n\nout::Matrix\n : Storage for output\n\n\n;ret_policy::Bool(false)\n: Toggles return of value or policy functions\n\n\n\n\nReturns\n\n\nNone, \nout\n is updated in place. If \nret_policy == true\n out is filled with the\npolicy function, otherwise the value function is stored in \nout\n.\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:103\n\n\n\n\n\n\nbellman_operator!(g::QuantEcon.Models.GrowthModel,  w::Array{T, 1},  out::Array{T, 1}) \n\u00b6\n\n\nApply the Bellman operator for a given model and initial value\n.\n\n\nArguments\n\n\n\n\ng::GrowthModel\n : Instance of \nGrowthModel\n\n\nw::Vector\n: Current guess for the value function\n\n\nout::Vector\n : Storage for output.\n\n\n;ret_policy::Bool(false)\n: Toggles return of value or policy functions\n\n\n\n\nReturns\n\n\nNone, \nout\n is updated in place. If \nret_policy == true\n out is filled with the\npolicy function, otherwise the value function is stored in \nout\n.\n\n\nsource:\n\n\nQuantEcon/src/models/optgrowth.jl:85\n\n\n\n\n\n\nbellman_operator!(jv::QuantEcon.Models.JvWorker,  V::Array{T, 1},  out::Union{Tuple{Array{T, 1}, Array{T, 1}}, Array{T, 1}}) \n\u00b6\n\n\nApply the Bellman operator for a given model and initial value\n.\n\n\nArguments\n\n\n\n\njv::JvWorker\n : Instance of \nJvWorker\n\n\nV::Vector\n: Current guess for the value function\n\n\nout::Union(Vector, Tuple{Vector, Vector})\n : Storage for output. Note that\nthere are two policy rules, but one value function\n\n\n;brute_force::Bool(true)\n: Whether to use a brute force grid search\nalgorithm or a solver from scipy.\n\n\n;ret_policy::Bool(false)\n: Toggles return of value or policy functions\n\n\n\n\nReturns\n\n\nNone, \nout\n is updated in place. If \nret_policy == true\n out is filled with the\npolicy function, otherwise the value function is stored in \nout\n.\n\n\nNotes\n\n\nCurrently, the \nbrute_force\n parameter must be \ntrue\n. We are waiting for a\nconstrained optimization routine to emerge in pure Julia. Once that happens,\nwe will re-activate this option.\n\n\nsource:\n\n\nQuantEcon/src/models/jv.jl:151\n\n\n\n\n\n\nbellman_operator!(sp::QuantEcon.Models.SearchProblem,  v::Array{T, 2},  out::Array{T, 2}) \n\u00b6\n\n\nApply the Bellman operator for a given model and initial value\n.\n\n\nArguments\n\n\n\n\nsp::SearchProblem\n : Instance of \nSearchProblem\n\n\nv::Matrix\n: Current guess for the value function\n\n\nout::Matrix\n : Storage for output.\n\n\n;ret_policy::Bool(false)\n: Toggles return of value or policy functions\n\n\n\n\nReturns\n\n\nNone, \nout\n is updated in place. If \nret_policy == true\n out is filled with the\npolicy function, otherwise the value function is stored in \nout\n.\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:130\n\n\n\n\n\n\ncall_option(ap::QuantEcon.Models.AssetPrices,  zet::Real,  p_s::Real) \n\u00b6\n\n\nComputes price of a call option on a consol bond, both finite and infinite\nhorizon\n\n\nArguments\n\n\n\n\nzeta::Float64\n : Coupon of the console\n\n\np_s::Float64\n : Strike price\n\n\nT::Vector{Int}(Int[])\n: Time periods for which to store the price in the\nfinite horizon version\n\n\nepsilon::Float64\n : Tolerance for infinite horizon problem\n\n\n\n\nReturns\n\n\n\n\nw_bar::Vector{Float64}\n Infinite horizon call option prices\n\n\nw_bars::Dict{Int, Vector{Float64}}\n A dictionary of key-value pairs {t: vec},\nwhere t is one of the dates in the list T and vec is the option prices at that\ndate\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/asset_pricing.jl:121\n\n\n\n\n\n\ncall_option(ap::QuantEcon.Models.AssetPrices,  zet::Real,  p_s::Real,  T::Array{Int64, 1}) \n\u00b6\n\n\nComputes price of a call option on a consol bond, both finite and infinite\nhorizon\n\n\nArguments\n\n\n\n\nzeta::Float64\n : Coupon of the console\n\n\np_s::Float64\n : Strike price\n\n\nT::Vector{Int}(Int[])\n: Time periods for which to store the price in the\nfinite horizon version\n\n\nepsilon::Float64\n : Tolerance for infinite horizon problem\n\n\n\n\nReturns\n\n\n\n\nw_bar::Vector{Float64}\n Infinite horizon call option prices\n\n\nw_bars::Dict{Int, Vector{Float64}}\n A dictionary of key-value pairs {t: vec},\nwhere t is one of the dates in the list T and vec is the option prices at that\ndate\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/asset_pricing.jl:121\n\n\n\n\n\n\ncall_option(ap::QuantEcon.Models.AssetPrices,  zet::Real,  p_s::Real,  T::Array{Int64, 1},  epsilon) \n\u00b6\n\n\nComputes price of a call option on a consol bond, both finite and infinite\nhorizon\n\n\nArguments\n\n\n\n\nzeta::Float64\n : Coupon of the console\n\n\np_s::Float64\n : Strike price\n\n\nT::Vector{Int}(Int[])\n: Time periods for which to store the price in the\nfinite horizon version\n\n\nepsilon::Float64\n : Tolerance for infinite horizon problem\n\n\n\n\nReturns\n\n\n\n\nw_bar::Vector{Float64}\n Infinite horizon call option prices\n\n\nw_bars::Dict{Int, Vector{Float64}}\n A dictionary of key-value pairs {t: vec},\nwhere t is one of the dates in the list T and vec is the option prices at that\ndate\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/asset_pricing.jl:121\n\n\n\n\n\n\ncoleman_operator!(cp::QuantEcon.Models.ConsumerProblem,  c::Array{T, 2},  out::Array{T, 2}) \n\u00b6\n\n\nThe approximate Coleman operator.\n\n\nIteration with this operator corresponds to policy function\niteration. Computes and returns the updated consumption policy\nc.  The array c is replaced with a function cf that implements\nunivariate linear interpolation over the asset grid for each\npossible value of z.\n\n\nArguments\n\n\n\n\ncp::CareerWorkerProblem\n : Instance of \nCareerWorkerProblem\n\n\nc::Matrix\n: Current guess for the policy function\n\n\nout::Matrix\n : Storage for output\n\n\n\n\nReturns\n\n\nNone, \nout\n is updated in place to hold the policy function\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:190\n\n\n\n\n\n\ncoleman_operator(cp::QuantEcon.Models.ConsumerProblem,  c::Array{T, 2}) \n\u00b6\n\n\nApply the Coleman operator for a given model and initial value\n\n\nSee the specific methods of the mutating version of this function for more\ndetails on arguments\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:231\n\n\n\n\n\n\ncompute_lt_price(lt::QuantEcon.Models.LucasTree) \n\u00b6\n\n\nCompute the equilibrium price function associated with Lucas tree \nlt\n\n\nArguments\n\n\n\n\nlt::LucasTree\n : An instance of the \nLucasTree\n type\n\n\n;kwargs...\n : other arguments to be passed to \ncompute_fixed_point\n\n\n\n\nReturns\n\n\n\n\nprice::Vector{Float64}\n : The price at each point in \nlt.grid\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/lucastree.jl:169\n\n\n\n\n\n\nconsol_price(ap::QuantEcon.Models.AssetPrices,  zet::Real) \n\u00b6\n\n\nComputes price of a consol bond with payoff zeta\n\n\nArguments\n\n\n\n\nap::AssetPrices\n : An instance of the \nAssetPrices\n type\n\n\nzeta::Float64\n : Per period payoff of the consol\n\n\n\n\nReturns\n\n\n\n\npbar::Vector{Float64}\n : the pricing function for the lucas tree\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/asset_pricing.jl:90\n\n\n\n\n\n\nget_greedy!(cp::QuantEcon.Models.CareerWorkerProblem,  v::Array{T, N},  out::Array{T, N}) \n\u00b6\n\n\nExtract the greedy policy (policy function) of the model\n.\n\n\nArguments\n\n\n\n\ncp::CareerWorkerProblem\n : Instance of \nCareerWorkerProblem\n\n\nv::Matrix\n: Current guess for the value function\n\n\nout::Matrix\n : Storage for output\n\n\n\n\nReturns\n\n\nNone, \nout\n is updated in place to hold the policy function\n\n\nsource:\n\n\nQuantEcon/src/models/career.jl:149\n\n\n\n\n\n\nget_greedy!(cp::QuantEcon.Models.ConsumerProblem,  V::Array{T, 2},  out::Array{T, 2}) \n\u00b6\n\n\nExtract the greedy policy (policy function) of the model\n.\n\n\nArguments\n\n\n\n\ncp::CareerWorkerProblem\n : Instance of \nCareerWorkerProblem\n\n\nv::Matrix\n: Current guess for the value function\n\n\nout::Matrix\n : Storage for output\n\n\n\n\nReturns\n\n\nNone, \nout\n is updated in place to hold the policy function\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:160\n\n\n\n\n\n\nget_greedy!(g::QuantEcon.Models.GrowthModel,  w::Array{T, 1},  out::Array{T, 1}) \n\u00b6\n\n\nExtract the greedy policy (policy function) of the model\n.\n\n\nArguments\n\n\n\n\ng::GrowthModel\n : Instance of \nGrowthModel\n\n\nw::Vector\n: Current guess for the value function\n\n\nout::Vector\n : Storage for output\n\n\n\n\nReturns\n\n\nNone, \nout\n is updated in place to hold the policy function\n\n\nsource:\n\n\nQuantEcon/src/models/optgrowth.jl:127\n\n\n\n\n\n\nget_greedy!(jv::QuantEcon.Models.JvWorker,  V::Array{T, 1},  out::Tuple{Array{T, 1}, Array{T, 1}}) \n\u00b6\n\n\nExtract the greedy policy (policy function) of the model\n.\n\n\nArguments\n\n\n\n\ncp::CareerWorkerProblem\n : Instance of \nCareerWorkerProblem\n\n\nv::Vector\n: Current guess for the value function\n\n\nout::Tuple(Vector, Vector)\n : Storage for output of policy rule\n\n\n\n\nReturns\n\n\nNone, \nout\n is updated in place to hold the policy function\n\n\nsource:\n\n\nQuantEcon/src/models/jv.jl:267\n\n\n\n\n\n\nget_greedy!(sp::QuantEcon.Models.SearchProblem,  v::Array{T, 2},  out::Array{T, 2}) \n\u00b6\n\n\nExtract the greedy policy (policy function) of the model\n.\n\n\nArguments\n\n\n\n\nsp::SearchProblem\n : Instance of \nSearchProblem\n\n\nv::Matrix\n: Current guess for the value function\n\n\nout::Matrix\n : Storage for output\n\n\n\n\nReturns\n\n\nNone, \nout\n is updated in place to hold the policy function\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:193\n\n\n\n\n\n\nlucas_operator(lt::QuantEcon.Models.LucasTree,  f::AbstractArray{T, 1}) \n\u00b6\n\n\nThe approximate Lucas operator, which computes and returns the updated function\nTf on the grid points.\n\n\nArguments\n\n\n\n\nlt::LucasTree\n : An instance of the \nLucasTree\n type\n\n\nf::Vector{Float64}\n : A candidate function on R_+ represented as points on a\ngrid. It should be the same size as \nlt.grid\n\n\n\n\nReturns\n\n\n\n\nTf::Vector{Float64}\n : The updated function Tf\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/lucastree.jl:142\n\n\n\n\n\n\nres_wage_operator!(sp::QuantEcon.Models.SearchProblem,  phi::Array{T, 1},  out::Array{T, 1}) \n\u00b6\n\n\nUpdates the reservation wage function guess phi via the operator Q.\n\n\nArguments\n\n\n\n\nsp::SearchProblem\n : Instance of \nSearchProblem\n\n\nphi::Vector\n: Current guess for phi\n\n\nout::Vector\n : Storage for output\n\n\n\n\nReturns\n\n\nNone, \nout\n is updated in place to hold the updated levels of phi\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:214\n\n\n\n\n\n\nres_wage_operator(sp::QuantEcon.Models.SearchProblem,  phi::Array{T, 1}) \n\u00b6\n\n\nUpdates the reservation wage function guess phi via the operator Q.\n\n\nSee the documentation for the mutating method of this function for more details\non arguments\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:237\n\n\n\n\n\n\ntree_price(ap::QuantEcon.Models.AssetPrices) \n\u00b6\n\n\nComputes the function v such that the price of the lucas tree is v(lambda)C_t\n\n\nArguments\n\n\n\n\nap::AssetPrices\n : An instance of the \nAssetPrices\n type\n\n\n\n\nReturns\n\n\n\n\nv::Vector{Float64}\n : the pricing function for the lucas tree\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/asset_pricing.jl:66\n\n\n\n\n\n\nQuantEcon.Models.AssetPrices \n\u00b6\n\n\nA class to compute asset prices when the endowment follows a finite Markov chain\n\n\nFields\n\n\n\n\nbet::Float64\n : Discount factor in (0, 1)\n\n\nP::Matrix{Float64}\n A valid stochastic matrix\n\n\ns::Vector{Float64}\n : Growth rate of consumption in each state\n\n\ngamma::Float64\n : Coefficient of risk aversion\n\n\nn::Int(size(P, 1))\n: The numberof states\n\n\nP_tilde::Matrix{Float64}\n : modified transition matrix used in computing the\nprice of the lucas tree\n\n\nP_check::Matrix{Float64}\n : modified transition matrix used in computing the\nprice of the consol\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/asset_pricing.jl:34\n\n\n\n\n\n\nQuantEcon.Models.CareerWorkerProblem \n\u00b6\n\n\nCareer/job choice model fo Derek Neal (1999)\n\n\nFields\n\n\n\n\nbeta::Real\n : Discount factor in (0, 1)\n\n\nN::Int\n : Number of possible realizations of both epsilon and theta\n\n\nB::Real\n : upper bound for both epsilon and theta\n\n\ntheta::AbstractVector\n : A grid of values on [0, B]\n\n\nepsilon::AbstractVector\n : A grid of values on [0, B]\n\n\nF_probs::AbstractVector\n : The pdf of each value associated with of F\n\n\nG_probs::AbstractVector\n : The pdf of each value associated with of G\n\n\nF_mean::Real\n : The mean of the distribution F\n\n\nG_mean::Real\n : The mean of the distribution G\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/career.jl:33\n\n\n\n\n\n\nQuantEcon.Models.ConsumerProblem \n\u00b6\n\n\nIncome fluctuation problem\n\n\nFields\n\n\n\n\nu::Function\n : Utility \nfunction\n\n\ndu::Function\n : Marginal utility \nfunction\n\n\nr::Real\n : Strictly positive interest rate\n\n\nR::Real\n : The interest rate plus 1 (strictly greater than 1)\n\n\nbet::Real\n : Discount rate in (0, 1)\n\n\nb::Real\n :  The borrowing constraint\n\n\nPi::Matrix\n : Transition matrix for \nz\n\n\nz_vals::Vector\n : Levels of productivity\n\n\nasset_grid::AbstractVector\n : Grid of asset values\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:36\n\n\n\n\n\n\nQuantEcon.Models.GrowthModel \n\u00b6\n\n\nNeoclassical growth model\n\n\nFields\n\n\n\n\nf::Function\n : Production function\n\n\nbet::Real\n : Discount factor in (0, 1)\n\n\nu::Function\n : Utility function\n\n\ngrid_max::Int\n : Maximum for grid over savings values\n\n\ngrid_size::Int\n : Number of points in grid for savings values\n\n\ngrid::FloatRange\n : The grid for savings values\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/optgrowth.jl:38\n\n\n\n\n\n\nQuantEcon.Models.JvWorker \n\u00b6\n\n\nA Jovanovic-type model of employment with on-the-job search.\n\n\nThe value function is given by\n\n\n[V(x) = \\max_{\\phi, s} w(x, \\phi, s)]\n\n\nfor\n\n\nw(x, phi, s) := x(1 - phi - s) + beta (1 - pi(s)) V(G(x, phi)) +\n                beta pi(s) E V[ max(G(x, phi), U)\n\n\n\nwhere\n\n\n\n\nx\n: : human capital\n\n\ns\n : search effort\n\n\nphi\n : investment in human capital\n\n\npi(s)\n : probability of new offer given search level s\n\n\nx(1 - phi - s)\n : wage\n\n\nG(x, phi)\n : new human capital when current job retained\n\n\nU\n : Random variable with distribution F -- new draw of human capita\n\n\n\n\nFields\n\n\n\n\nA::Real\n : Parameter in human capital transition function\n\n\nalpha::Real\n : Parameter in human capital transition function\n\n\nbet::Real\n : Discount factor in (0, 1)\n\n\nx_grid::FloatRange\n : Grid for potential levels of x\n\n\nG::Function\n : Transition \nfunction\n for human captial\n\n\npi_func::Function\n : \nfunction\n mapping search effort to the probability of\ngetting a new job offer\n\n\nF::UnivariateDistribution\n : A univariate distribution from which the value\nof new job offers is drawn\n\n\nquad_nodes::Vector\n : Quadrature nodes for integrating over phi\n\n\nquad_weights::Vector\n : Quadrature weights for integrating over phi\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/jv.jl:63\n\n\n\n\n\n\nQuantEcon.Models.LucasTree \n\u00b6\n\n\nThe Lucas asset pricing model\n\n\nFields\n\n\n\n\ngam::Real\n : coefficient of risk aversion in the CRRA utility function\n\n\nbet::Real\n : Discount factor in (0, 1)\n\n\nalpha::Real\n : Correlation coefficient in the shock process\n\n\nsigma::Real\n : Volatility of shock process\n\n\nphi::Distribution\n : Distribution for shock process\n\n\ngrid::AbstractVector\n : Grid of points on which to evaluate the prices. Each\npoint should be non-negative\n\n\ngrid_min::Real\n : Lower bound on grid\n\n\ngrid_max::Real\n : Upper bound on grid\n\n\ngrid_size::Int\n : Number of points in the grid\n\n\nquad_nodes::Vector\n : Quadrature nodes for integrating over the shock\n\n\nquad_weights::Vector\n : Quadrature weights for integrating over the shock\n\n\nh::Vector\n : Storage array for the \nh\n vector in the lucas operator\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/lucastree.jl:50\n\n\n\n\n\n\nQuantEcon.Models.SearchProblem \n\u00b6\n\n\nUnemployment/search problem where offer distribution is unknown\n\n\nFields\n\n\n\n\nbet::Real\n : Discount factor on (0, 1)\n\n\nc::Real\n : Unemployment compensation\n\n\nF::Distribution\n : Offer distribution \nF\n\n\nG::Distribution\n : Offer distribution \nG\n\n\nf::Function\n : The pdf of \nF\n\n\ng::Function\n : The pdf of \nG\n\n\nn_w::Int\n : Number of points on the grid for w\n\n\nw_max::Real\n : Maximum wage offer\n\n\nw_grid::AbstractVector\n : Grid of wage offers w\n\n\nn_pi::Int\n : Number of points on grid for pi\n\n\npi_min::Real\n : Minimum of pi grid\n\n\npi_max::Real\n : Maximum of pi grid\n\n\npi_grid::AbstractVector\n : Grid of probabilities pi\n\n\nquad_nodes::Vector\n : Notes for quadrature ofer offers\n\n\nquad_weights::Vector\n : Weights for quadrature ofer offers\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:40\n\n\nInternal\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.AssetPrices},  bet::Real,  P::Array{T, 2},  s::Array{T, 1},  gamm::Real) \n\u00b6\n\n\nConstruct an instance of \nAssetPrices\n, where \nn\n, \nP_tilde\n, and \nP_check\n are\ncomputed automatically for you. See also the documentation for the type itself\n\n\nsource:\n\n\nQuantEcon/src/models/asset_pricing.jl:48\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real) \n\u00b6\n\n\nConstructor with default values for \nCareerWorkerProblem\n\n\nArguments\n\n\n\n\nbeta::Real(0.95)\n : Discount factor in (0, 1)\n\n\nB::Real(5.0)\n : upper bound for both epsilon and theta\n\n\nN::Real(50)\n : Number of possible realizations of both epsilon and theta\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of the distribution F\n\n\nG_a::Real(1), G_b::Real(1)\n : Parameters of the distribution F\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/career.jl:60\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real) \n\u00b6\n\n\nConstructor with default values for \nCareerWorkerProblem\n\n\nArguments\n\n\n\n\nbeta::Real(0.95)\n : Discount factor in (0, 1)\n\n\nB::Real(5.0)\n : upper bound for both epsilon and theta\n\n\nN::Real(50)\n : Number of possible realizations of both epsilon and theta\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of the distribution F\n\n\nG_a::Real(1), G_b::Real(1)\n : Parameters of the distribution F\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/career.jl:60\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real) \n\u00b6\n\n\nConstructor with default values for \nCareerWorkerProblem\n\n\nArguments\n\n\n\n\nbeta::Real(0.95)\n : Discount factor in (0, 1)\n\n\nB::Real(5.0)\n : upper bound for both epsilon and theta\n\n\nN::Real(50)\n : Number of possible realizations of both epsilon and theta\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of the distribution F\n\n\nG_a::Real(1), G_b::Real(1)\n : Parameters of the distribution F\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/career.jl:60\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real) \n\u00b6\n\n\nConstructor with default values for \nCareerWorkerProblem\n\n\nArguments\n\n\n\n\nbeta::Real(0.95)\n : Discount factor in (0, 1)\n\n\nB::Real(5.0)\n : upper bound for both epsilon and theta\n\n\nN::Real(50)\n : Number of possible realizations of both epsilon and theta\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of the distribution F\n\n\nG_a::Real(1), G_b::Real(1)\n : Parameters of the distribution F\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/career.jl:60\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real,  F_b::Real) \n\u00b6\n\n\nConstructor with default values for \nCareerWorkerProblem\n\n\nArguments\n\n\n\n\nbeta::Real(0.95)\n : Discount factor in (0, 1)\n\n\nB::Real(5.0)\n : upper bound for both epsilon and theta\n\n\nN::Real(50)\n : Number of possible realizations of both epsilon and theta\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of the distribution F\n\n\nG_a::Real(1), G_b::Real(1)\n : Parameters of the distribution F\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/career.jl:60\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real,  F_b::Real,  G_a::Real) \n\u00b6\n\n\nConstructor with default values for \nCareerWorkerProblem\n\n\nArguments\n\n\n\n\nbeta::Real(0.95)\n : Discount factor in (0, 1)\n\n\nB::Real(5.0)\n : upper bound for both epsilon and theta\n\n\nN::Real(50)\n : Number of possible realizations of both epsilon and theta\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of the distribution F\n\n\nG_a::Real(1), G_b::Real(1)\n : Parameters of the distribution F\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/career.jl:60\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real,  F_b::Real,  G_a::Real,  G_b::Real) \n\u00b6\n\n\nConstructor with default values for \nCareerWorkerProblem\n\n\nArguments\n\n\n\n\nbeta::Real(0.95)\n : Discount factor in (0, 1)\n\n\nB::Real(5.0)\n : upper bound for both epsilon and theta\n\n\nN::Real(50)\n : Number of possible realizations of both epsilon and theta\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of the distribution F\n\n\nG_a::Real(1), G_b::Real(1)\n : Parameters of the distribution F\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/career.jl:60\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r) \n\u00b6\n\n\nConstructor with default values for \nConsumerProblem\n\n\nArguments\n\n\n\n\nr::Real(0.01)\n : Strictly positive interest rate\n\n\nbet::Real(0.96)\n : Discount rate in (0, 1)\n\n\nPi::Matrix{Float64}([0.6 0.4; 0.05 0.95])\n : Transition matrix for \nz\n\n\nz_vals::Vector{Float64}([0.5, 1.0])\n : Levels of productivity\n\n\nb::Real(0.0)\n : Borrowing constraint\n\n\ngrid_max::Real(16)\n : Maximum in grid for asset holdings\n\n\ngrid_size::Int(50)\n : Number of points in grid for asset holdings\n\n\nu::Function(log)\n : Utility \nfunction\n\n\ndu::Function(x-\n1/x)\n : Marginal utility \nfunction\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:71\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet) \n\u00b6\n\n\nConstructor with default values for \nConsumerProblem\n\n\nArguments\n\n\n\n\nr::Real(0.01)\n : Strictly positive interest rate\n\n\nbet::Real(0.96)\n : Discount rate in (0, 1)\n\n\nPi::Matrix{Float64}([0.6 0.4; 0.05 0.95])\n : Transition matrix for \nz\n\n\nz_vals::Vector{Float64}([0.5, 1.0])\n : Levels of productivity\n\n\nb::Real(0.0)\n : Borrowing constraint\n\n\ngrid_max::Real(16)\n : Maximum in grid for asset holdings\n\n\ngrid_size::Int(50)\n : Number of points in grid for asset holdings\n\n\nu::Function(log)\n : Utility \nfunction\n\n\ndu::Function(x-\n1/x)\n : Marginal utility \nfunction\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:71\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi) \n\u00b6\n\n\nConstructor with default values for \nConsumerProblem\n\n\nArguments\n\n\n\n\nr::Real(0.01)\n : Strictly positive interest rate\n\n\nbet::Real(0.96)\n : Discount rate in (0, 1)\n\n\nPi::Matrix{Float64}([0.6 0.4; 0.05 0.95])\n : Transition matrix for \nz\n\n\nz_vals::Vector{Float64}([0.5, 1.0])\n : Levels of productivity\n\n\nb::Real(0.0)\n : Borrowing constraint\n\n\ngrid_max::Real(16)\n : Maximum in grid for asset holdings\n\n\ngrid_size::Int(50)\n : Number of points in grid for asset holdings\n\n\nu::Function(log)\n : Utility \nfunction\n\n\ndu::Function(x-\n1/x)\n : Marginal utility \nfunction\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:71\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals) \n\u00b6\n\n\nConstructor with default values for \nConsumerProblem\n\n\nArguments\n\n\n\n\nr::Real(0.01)\n : Strictly positive interest rate\n\n\nbet::Real(0.96)\n : Discount rate in (0, 1)\n\n\nPi::Matrix{Float64}([0.6 0.4; 0.05 0.95])\n : Transition matrix for \nz\n\n\nz_vals::Vector{Float64}([0.5, 1.0])\n : Levels of productivity\n\n\nb::Real(0.0)\n : Borrowing constraint\n\n\ngrid_max::Real(16)\n : Maximum in grid for asset holdings\n\n\ngrid_size::Int(50)\n : Number of points in grid for asset holdings\n\n\nu::Function(log)\n : Utility \nfunction\n\n\ndu::Function(x-\n1/x)\n : Marginal utility \nfunction\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:71\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b) \n\u00b6\n\n\nConstructor with default values for \nConsumerProblem\n\n\nArguments\n\n\n\n\nr::Real(0.01)\n : Strictly positive interest rate\n\n\nbet::Real(0.96)\n : Discount rate in (0, 1)\n\n\nPi::Matrix{Float64}([0.6 0.4; 0.05 0.95])\n : Transition matrix for \nz\n\n\nz_vals::Vector{Float64}([0.5, 1.0])\n : Levels of productivity\n\n\nb::Real(0.0)\n : Borrowing constraint\n\n\ngrid_max::Real(16)\n : Maximum in grid for asset holdings\n\n\ngrid_size::Int(50)\n : Number of points in grid for asset holdings\n\n\nu::Function(log)\n : Utility \nfunction\n\n\ndu::Function(x-\n1/x)\n : Marginal utility \nfunction\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:71\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max) \n\u00b6\n\n\nConstructor with default values for \nConsumerProblem\n\n\nArguments\n\n\n\n\nr::Real(0.01)\n : Strictly positive interest rate\n\n\nbet::Real(0.96)\n : Discount rate in (0, 1)\n\n\nPi::Matrix{Float64}([0.6 0.4; 0.05 0.95])\n : Transition matrix for \nz\n\n\nz_vals::Vector{Float64}([0.5, 1.0])\n : Levels of productivity\n\n\nb::Real(0.0)\n : Borrowing constraint\n\n\ngrid_max::Real(16)\n : Maximum in grid for asset holdings\n\n\ngrid_size::Int(50)\n : Number of points in grid for asset holdings\n\n\nu::Function(log)\n : Utility \nfunction\n\n\ndu::Function(x-\n1/x)\n : Marginal utility \nfunction\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:71\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max,  grid_size) \n\u00b6\n\n\nConstructor with default values for \nConsumerProblem\n\n\nArguments\n\n\n\n\nr::Real(0.01)\n : Strictly positive interest rate\n\n\nbet::Real(0.96)\n : Discount rate in (0, 1)\n\n\nPi::Matrix{Float64}([0.6 0.4; 0.05 0.95])\n : Transition matrix for \nz\n\n\nz_vals::Vector{Float64}([0.5, 1.0])\n : Levels of productivity\n\n\nb::Real(0.0)\n : Borrowing constraint\n\n\ngrid_max::Real(16)\n : Maximum in grid for asset holdings\n\n\ngrid_size::Int(50)\n : Number of points in grid for asset holdings\n\n\nu::Function(log)\n : Utility \nfunction\n\n\ndu::Function(x-\n1/x)\n : Marginal utility \nfunction\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:71\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max,  grid_size,  u) \n\u00b6\n\n\nConstructor with default values for \nConsumerProblem\n\n\nArguments\n\n\n\n\nr::Real(0.01)\n : Strictly positive interest rate\n\n\nbet::Real(0.96)\n : Discount rate in (0, 1)\n\n\nPi::Matrix{Float64}([0.6 0.4; 0.05 0.95])\n : Transition matrix for \nz\n\n\nz_vals::Vector{Float64}([0.5, 1.0])\n : Levels of productivity\n\n\nb::Real(0.0)\n : Borrowing constraint\n\n\ngrid_max::Real(16)\n : Maximum in grid for asset holdings\n\n\ngrid_size::Int(50)\n : Number of points in grid for asset holdings\n\n\nu::Function(log)\n : Utility \nfunction\n\n\ndu::Function(x-\n1/x)\n : Marginal utility \nfunction\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:71\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max,  grid_size,  u,  du) \n\u00b6\n\n\nConstructor with default values for \nConsumerProblem\n\n\nArguments\n\n\n\n\nr::Real(0.01)\n : Strictly positive interest rate\n\n\nbet::Real(0.96)\n : Discount rate in (0, 1)\n\n\nPi::Matrix{Float64}([0.6 0.4; 0.05 0.95])\n : Transition matrix for \nz\n\n\nz_vals::Vector{Float64}([0.5, 1.0])\n : Levels of productivity\n\n\nb::Real(0.0)\n : Borrowing constraint\n\n\ngrid_max::Real(16)\n : Maximum in grid for asset holdings\n\n\ngrid_size::Int(50)\n : Number of points in grid for asset holdings\n\n\nu::Function(log)\n : Utility \nfunction\n\n\ndu::Function(x-\n1/x)\n : Marginal utility \nfunction\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:71\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.GrowthModel}) \n\u00b6\n\n\nConstructor of \nGrowthModel\n\n\nArguments\n\n\n\n\nf::Function(k-\nk^0.65)\n : Production function\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nu::Function(log)\n : Utility function\n\n\ngrid_max::Int(2)\n : Maximum for grid over savings values\n\n\ngrid_size::Int(150)\n : Number of points in grid for savings values\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/optgrowth.jl:63\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.GrowthModel},  f) \n\u00b6\n\n\nConstructor of \nGrowthModel\n\n\nArguments\n\n\n\n\nf::Function(k-\nk^0.65)\n : Production function\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nu::Function(log)\n : Utility function\n\n\ngrid_max::Int(2)\n : Maximum for grid over savings values\n\n\ngrid_size::Int(150)\n : Number of points in grid for savings values\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/optgrowth.jl:63\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.GrowthModel},  f,  bet) \n\u00b6\n\n\nConstructor of \nGrowthModel\n\n\nArguments\n\n\n\n\nf::Function(k-\nk^0.65)\n : Production function\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nu::Function(log)\n : Utility function\n\n\ngrid_max::Int(2)\n : Maximum for grid over savings values\n\n\ngrid_size::Int(150)\n : Number of points in grid for savings values\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/optgrowth.jl:63\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.GrowthModel},  f,  bet,  u) \n\u00b6\n\n\nConstructor of \nGrowthModel\n\n\nArguments\n\n\n\n\nf::Function(k-\nk^0.65)\n : Production function\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nu::Function(log)\n : Utility function\n\n\ngrid_max::Int(2)\n : Maximum for grid over savings values\n\n\ngrid_size::Int(150)\n : Number of points in grid for savings values\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/optgrowth.jl:63\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.GrowthModel},  f,  bet,  u,  grid_max) \n\u00b6\n\n\nConstructor of \nGrowthModel\n\n\nArguments\n\n\n\n\nf::Function(k-\nk^0.65)\n : Production function\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nu::Function(log)\n : Utility function\n\n\ngrid_max::Int(2)\n : Maximum for grid over savings values\n\n\ngrid_size::Int(150)\n : Number of points in grid for savings values\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/optgrowth.jl:63\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.GrowthModel},  f,  bet,  u,  grid_max,  grid_size) \n\u00b6\n\n\nConstructor of \nGrowthModel\n\n\nArguments\n\n\n\n\nf::Function(k-\nk^0.65)\n : Production function\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nu::Function(log)\n : Utility function\n\n\ngrid_max::Int(2)\n : Maximum for grid over savings values\n\n\ngrid_size::Int(150)\n : Number of points in grid for savings values\n\n\n\n\nsource:\n\n\nQuantEcon/src/models/optgrowth.jl:63\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.JvWorker},  A) \n\u00b6\n\n\nConstructor with default values for \nJvWorker\n\n\nArguments\n\n\n\n\nA::Real(1.4)\n : Parameter in human capital transition function\n\n\nalpha::Real(0.6)\n : Parameter in human capital transition function\n\n\nbet::Real(0.96)\n : Discount factor in (0, 1)\n\n\ngrid_size::Int(50)\n : Number of points in discrete grid for \nx\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/jv.jl:90\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.JvWorker},  A,  alpha) \n\u00b6\n\n\nConstructor with default values for \nJvWorker\n\n\nArguments\n\n\n\n\nA::Real(1.4)\n : Parameter in human capital transition function\n\n\nalpha::Real(0.6)\n : Parameter in human capital transition function\n\n\nbet::Real(0.96)\n : Discount factor in (0, 1)\n\n\ngrid_size::Int(50)\n : Number of points in discrete grid for \nx\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/jv.jl:90\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.JvWorker},  A,  alpha,  bet) \n\u00b6\n\n\nConstructor with default values for \nJvWorker\n\n\nArguments\n\n\n\n\nA::Real(1.4)\n : Parameter in human capital transition function\n\n\nalpha::Real(0.6)\n : Parameter in human capital transition function\n\n\nbet::Real(0.96)\n : Discount factor in (0, 1)\n\n\ngrid_size::Int(50)\n : Number of points in discrete grid for \nx\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/jv.jl:90\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.JvWorker},  A,  alpha,  bet,  grid_size) \n\u00b6\n\n\nConstructor with default values for \nJvWorker\n\n\nArguments\n\n\n\n\nA::Real(1.4)\n : Parameter in human capital transition function\n\n\nalpha::Real(0.6)\n : Parameter in human capital transition function\n\n\nbet::Real(0.96)\n : Discount factor in (0, 1)\n\n\ngrid_size::Int(50)\n : Number of points in discrete grid for \nx\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/jv.jl:90\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.LucasTree},  gam::Real,  bet::Real,  alpha::Real,  sigma::Real) \n\u00b6\n\n\nConstructor for LucasTree\n\n\nArguments\n\n\n\n\ngam::Real\n : coefficient of risk aversion in the CRRA utility function\n\n\nbet::Real\n : Discount factor in (0, 1)\n\n\nalpha::Real\n : Correlation coefficient in the shock process\n\n\nsigma::Real\n : Volatility of shock process\n\n\n\n\nNotes\n\n\nAll other fields of the type are instantiated within the constructor\n\n\nsource:\n\n\nQuantEcon/src/models/lucastree.jl:80\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet) \n\u00b6\n\n\nConstructor for \nSearchProblem\n with default values\n\n\nArguments\n\n\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nc::Real(0.6)\n : Unemployment compensation\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of \nBeta\n distribution for \nF\n\n\nG_a::Real(3), G_b::Real(1.2)\n : Parameters of \nBeta\n distribution for \nG\n\n\nw_max::Real(2)\n : Maximum of wage offer grid\n\n\nw_grid_size::Int(40)\n : Number of points in wage offer grid\n\n\npi_grid_size::Int(40)\n : Number of points in probability grid\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:76\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c) \n\u00b6\n\n\nConstructor for \nSearchProblem\n with default values\n\n\nArguments\n\n\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nc::Real(0.6)\n : Unemployment compensation\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of \nBeta\n distribution for \nF\n\n\nG_a::Real(3), G_b::Real(1.2)\n : Parameters of \nBeta\n distribution for \nG\n\n\nw_max::Real(2)\n : Maximum of wage offer grid\n\n\nw_grid_size::Int(40)\n : Number of points in wage offer grid\n\n\npi_grid_size::Int(40)\n : Number of points in probability grid\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:76\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a) \n\u00b6\n\n\nConstructor for \nSearchProblem\n with default values\n\n\nArguments\n\n\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nc::Real(0.6)\n : Unemployment compensation\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of \nBeta\n distribution for \nF\n\n\nG_a::Real(3), G_b::Real(1.2)\n : Parameters of \nBeta\n distribution for \nG\n\n\nw_max::Real(2)\n : Maximum of wage offer grid\n\n\nw_grid_size::Int(40)\n : Number of points in wage offer grid\n\n\npi_grid_size::Int(40)\n : Number of points in probability grid\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:76\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b) \n\u00b6\n\n\nConstructor for \nSearchProblem\n with default values\n\n\nArguments\n\n\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nc::Real(0.6)\n : Unemployment compensation\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of \nBeta\n distribution for \nF\n\n\nG_a::Real(3), G_b::Real(1.2)\n : Parameters of \nBeta\n distribution for \nG\n\n\nw_max::Real(2)\n : Maximum of wage offer grid\n\n\nw_grid_size::Int(40)\n : Number of points in wage offer grid\n\n\npi_grid_size::Int(40)\n : Number of points in probability grid\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:76\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a) \n\u00b6\n\n\nConstructor for \nSearchProblem\n with default values\n\n\nArguments\n\n\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nc::Real(0.6)\n : Unemployment compensation\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of \nBeta\n distribution for \nF\n\n\nG_a::Real(3), G_b::Real(1.2)\n : Parameters of \nBeta\n distribution for \nG\n\n\nw_max::Real(2)\n : Maximum of wage offer grid\n\n\nw_grid_size::Int(40)\n : Number of points in wage offer grid\n\n\npi_grid_size::Int(40)\n : Number of points in probability grid\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:76\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b) \n\u00b6\n\n\nConstructor for \nSearchProblem\n with default values\n\n\nArguments\n\n\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nc::Real(0.6)\n : Unemployment compensation\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of \nBeta\n distribution for \nF\n\n\nG_a::Real(3), G_b::Real(1.2)\n : Parameters of \nBeta\n distribution for \nG\n\n\nw_max::Real(2)\n : Maximum of wage offer grid\n\n\nw_grid_size::Int(40)\n : Number of points in wage offer grid\n\n\npi_grid_size::Int(40)\n : Number of points in probability grid\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:76\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b,  w_max) \n\u00b6\n\n\nConstructor for \nSearchProblem\n with default values\n\n\nArguments\n\n\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nc::Real(0.6)\n : Unemployment compensation\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of \nBeta\n distribution for \nF\n\n\nG_a::Real(3), G_b::Real(1.2)\n : Parameters of \nBeta\n distribution for \nG\n\n\nw_max::Real(2)\n : Maximum of wage offer grid\n\n\nw_grid_size::Int(40)\n : Number of points in wage offer grid\n\n\npi_grid_size::Int(40)\n : Number of points in probability grid\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:76\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b,  w_max,  w_grid_size) \n\u00b6\n\n\nConstructor for \nSearchProblem\n with default values\n\n\nArguments\n\n\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nc::Real(0.6)\n : Unemployment compensation\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of \nBeta\n distribution for \nF\n\n\nG_a::Real(3), G_b::Real(1.2)\n : Parameters of \nBeta\n distribution for \nG\n\n\nw_max::Real(2)\n : Maximum of wage offer grid\n\n\nw_grid_size::Int(40)\n : Number of points in wage offer grid\n\n\npi_grid_size::Int(40)\n : Number of points in probability grid\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:76\n\n\n\n\n\n\ncall(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b,  w_max,  w_grid_size,  pi_grid_size) \n\u00b6\n\n\nConstructor for \nSearchProblem\n with default values\n\n\nArguments\n\n\n\n\nbet::Real(0.95)\n : Discount factor in (0, 1)\n\n\nc::Real(0.6)\n : Unemployment compensation\n\n\nF_a::Real(1), F_b::Real(1)\n : Parameters of \nBeta\n distribution for \nF\n\n\nG_a::Real(3), G_b::Real(1.2)\n : Parameters of \nBeta\n distribution for \nG\n\n\nw_max::Real(2)\n : Maximum of wage offer grid\n\n\nw_grid_size::Int(40)\n : Number of points in wage offer grid\n\n\npi_grid_size::Int(40)\n : Number of points in probability grid\n\n\n\n\nNotes\n\n\nThere is also a version of this function that accepts keyword arguments for\neach parameter\n\n\nsource:\n\n\nQuantEcon/src/models/odu.jl:76\n\n\n\n\n\n\ndefault_du{T\n:Real}(x::T\n:Real) \n\u00b6\n\n\nMarginal utility for log utility function\n\n\nsource:\n\n\nQuantEcon/src/models/ifp.jl:49", 
            "title": "Models"
        }, 
        {
            "location": "/api/QuantEcon.Models/#quanteconmodels", 
            "text": "", 
            "title": "QuantEcon.Models"
        }, 
        {
            "location": "/api/QuantEcon.Models/#exported", 
            "text": "bellman_operator  \u00b6  Apply the Bellman operator for a given model and initial value\n. See the specific methods of the mutating function for more details on arguments  source:  QuantEcon/src/Models.jl:63    bellman_operator!  \u00b6  Apply the Bellman operator for a given model and initial value\n. See the specific methods of the mutating function for more details on arguments  The last positional argument passed to this function will be over-written  source:  QuantEcon/src/Models.jl:70    get_greedy  \u00b6  Extract the greedy policy (policy function) of the model\n. See the specific methods of the mutating function for more details on arguments  source:  QuantEcon/src/Models.jl:75    get_greedy!  \u00b6  Extract the greedy policy (policy function) of the model\n. See the specific methods of the mutating function for more details on arguments  The last positional argument passed to this function will be over-written  source:  QuantEcon/src/Models.jl:82    bellman_operator!(cp::QuantEcon.Models.CareerWorkerProblem,  v::Array{T, N},  out::Array{T, N})  \u00b6  Apply the Bellman operator for a given model and initial value\n.  Arguments   cp::CareerWorkerProblem  : Instance of  CareerWorkerProblem  v::Matrix : Current guess for the value function  out::Matrix  : Storage for output  ;ret_policy::Bool(false) : Toggles return of value or policy functions   Returns  None,  out  is updated in place. If  ret_policy == true  out is filled with the\npolicy function, otherwise the value function is stored in  out .  source:  QuantEcon/src/models/career.jl:96    bellman_operator!(cp::QuantEcon.Models.ConsumerProblem,  V::Array{T, 2},  out::Array{T, 2})  \u00b6  Apply the Bellman operator for a given model and initial value\n.  Arguments   cp::ConsumerProblem  : Instance of  ConsumerProblem  v::Matrix : Current guess for the value function  out::Matrix  : Storage for output  ;ret_policy::Bool(false) : Toggles return of value or policy functions   Returns  None,  out  is updated in place. If  ret_policy == true  out is filled with the\npolicy function, otherwise the value function is stored in  out .  source:  QuantEcon/src/models/ifp.jl:103    bellman_operator!(g::QuantEcon.Models.GrowthModel,  w::Array{T, 1},  out::Array{T, 1})  \u00b6  Apply the Bellman operator for a given model and initial value\n.  Arguments   g::GrowthModel  : Instance of  GrowthModel  w::Vector : Current guess for the value function  out::Vector  : Storage for output.  ;ret_policy::Bool(false) : Toggles return of value or policy functions   Returns  None,  out  is updated in place. If  ret_policy == true  out is filled with the\npolicy function, otherwise the value function is stored in  out .  source:  QuantEcon/src/models/optgrowth.jl:85    bellman_operator!(jv::QuantEcon.Models.JvWorker,  V::Array{T, 1},  out::Union{Tuple{Array{T, 1}, Array{T, 1}}, Array{T, 1}})  \u00b6  Apply the Bellman operator for a given model and initial value\n.  Arguments   jv::JvWorker  : Instance of  JvWorker  V::Vector : Current guess for the value function  out::Union(Vector, Tuple{Vector, Vector})  : Storage for output. Note that\nthere are two policy rules, but one value function  ;brute_force::Bool(true) : Whether to use a brute force grid search\nalgorithm or a solver from scipy.  ;ret_policy::Bool(false) : Toggles return of value or policy functions   Returns  None,  out  is updated in place. If  ret_policy == true  out is filled with the\npolicy function, otherwise the value function is stored in  out .  Notes  Currently, the  brute_force  parameter must be  true . We are waiting for a\nconstrained optimization routine to emerge in pure Julia. Once that happens,\nwe will re-activate this option.  source:  QuantEcon/src/models/jv.jl:151    bellman_operator!(sp::QuantEcon.Models.SearchProblem,  v::Array{T, 2},  out::Array{T, 2})  \u00b6  Apply the Bellman operator for a given model and initial value\n.  Arguments   sp::SearchProblem  : Instance of  SearchProblem  v::Matrix : Current guess for the value function  out::Matrix  : Storage for output.  ;ret_policy::Bool(false) : Toggles return of value or policy functions   Returns  None,  out  is updated in place. If  ret_policy == true  out is filled with the\npolicy function, otherwise the value function is stored in  out .  source:  QuantEcon/src/models/odu.jl:130    call_option(ap::QuantEcon.Models.AssetPrices,  zet::Real,  p_s::Real)  \u00b6  Computes price of a call option on a consol bond, both finite and infinite\nhorizon  Arguments   zeta::Float64  : Coupon of the console  p_s::Float64  : Strike price  T::Vector{Int}(Int[]) : Time periods for which to store the price in the\nfinite horizon version  epsilon::Float64  : Tolerance for infinite horizon problem   Returns   w_bar::Vector{Float64}  Infinite horizon call option prices  w_bars::Dict{Int, Vector{Float64}}  A dictionary of key-value pairs {t: vec},\nwhere t is one of the dates in the list T and vec is the option prices at that\ndate   source:  QuantEcon/src/models/asset_pricing.jl:121    call_option(ap::QuantEcon.Models.AssetPrices,  zet::Real,  p_s::Real,  T::Array{Int64, 1})  \u00b6  Computes price of a call option on a consol bond, both finite and infinite\nhorizon  Arguments   zeta::Float64  : Coupon of the console  p_s::Float64  : Strike price  T::Vector{Int}(Int[]) : Time periods for which to store the price in the\nfinite horizon version  epsilon::Float64  : Tolerance for infinite horizon problem   Returns   w_bar::Vector{Float64}  Infinite horizon call option prices  w_bars::Dict{Int, Vector{Float64}}  A dictionary of key-value pairs {t: vec},\nwhere t is one of the dates in the list T and vec is the option prices at that\ndate   source:  QuantEcon/src/models/asset_pricing.jl:121    call_option(ap::QuantEcon.Models.AssetPrices,  zet::Real,  p_s::Real,  T::Array{Int64, 1},  epsilon)  \u00b6  Computes price of a call option on a consol bond, both finite and infinite\nhorizon  Arguments   zeta::Float64  : Coupon of the console  p_s::Float64  : Strike price  T::Vector{Int}(Int[]) : Time periods for which to store the price in the\nfinite horizon version  epsilon::Float64  : Tolerance for infinite horizon problem   Returns   w_bar::Vector{Float64}  Infinite horizon call option prices  w_bars::Dict{Int, Vector{Float64}}  A dictionary of key-value pairs {t: vec},\nwhere t is one of the dates in the list T and vec is the option prices at that\ndate   source:  QuantEcon/src/models/asset_pricing.jl:121    coleman_operator!(cp::QuantEcon.Models.ConsumerProblem,  c::Array{T, 2},  out::Array{T, 2})  \u00b6  The approximate Coleman operator.  Iteration with this operator corresponds to policy function\niteration. Computes and returns the updated consumption policy\nc.  The array c is replaced with a function cf that implements\nunivariate linear interpolation over the asset grid for each\npossible value of z.  Arguments   cp::CareerWorkerProblem  : Instance of  CareerWorkerProblem  c::Matrix : Current guess for the policy function  out::Matrix  : Storage for output   Returns  None,  out  is updated in place to hold the policy function  source:  QuantEcon/src/models/ifp.jl:190    coleman_operator(cp::QuantEcon.Models.ConsumerProblem,  c::Array{T, 2})  \u00b6  Apply the Coleman operator for a given model and initial value  See the specific methods of the mutating version of this function for more\ndetails on arguments  source:  QuantEcon/src/models/ifp.jl:231    compute_lt_price(lt::QuantEcon.Models.LucasTree)  \u00b6  Compute the equilibrium price function associated with Lucas tree  lt  Arguments   lt::LucasTree  : An instance of the  LucasTree  type  ;kwargs...  : other arguments to be passed to  compute_fixed_point   Returns   price::Vector{Float64}  : The price at each point in  lt.grid   source:  QuantEcon/src/models/lucastree.jl:169    consol_price(ap::QuantEcon.Models.AssetPrices,  zet::Real)  \u00b6  Computes price of a consol bond with payoff zeta  Arguments   ap::AssetPrices  : An instance of the  AssetPrices  type  zeta::Float64  : Per period payoff of the consol   Returns   pbar::Vector{Float64}  : the pricing function for the lucas tree   source:  QuantEcon/src/models/asset_pricing.jl:90    get_greedy!(cp::QuantEcon.Models.CareerWorkerProblem,  v::Array{T, N},  out::Array{T, N})  \u00b6  Extract the greedy policy (policy function) of the model\n.  Arguments   cp::CareerWorkerProblem  : Instance of  CareerWorkerProblem  v::Matrix : Current guess for the value function  out::Matrix  : Storage for output   Returns  None,  out  is updated in place to hold the policy function  source:  QuantEcon/src/models/career.jl:149    get_greedy!(cp::QuantEcon.Models.ConsumerProblem,  V::Array{T, 2},  out::Array{T, 2})  \u00b6  Extract the greedy policy (policy function) of the model\n.  Arguments   cp::CareerWorkerProblem  : Instance of  CareerWorkerProblem  v::Matrix : Current guess for the value function  out::Matrix  : Storage for output   Returns  None,  out  is updated in place to hold the policy function  source:  QuantEcon/src/models/ifp.jl:160    get_greedy!(g::QuantEcon.Models.GrowthModel,  w::Array{T, 1},  out::Array{T, 1})  \u00b6  Extract the greedy policy (policy function) of the model\n.  Arguments   g::GrowthModel  : Instance of  GrowthModel  w::Vector : Current guess for the value function  out::Vector  : Storage for output   Returns  None,  out  is updated in place to hold the policy function  source:  QuantEcon/src/models/optgrowth.jl:127    get_greedy!(jv::QuantEcon.Models.JvWorker,  V::Array{T, 1},  out::Tuple{Array{T, 1}, Array{T, 1}})  \u00b6  Extract the greedy policy (policy function) of the model\n.  Arguments   cp::CareerWorkerProblem  : Instance of  CareerWorkerProblem  v::Vector : Current guess for the value function  out::Tuple(Vector, Vector)  : Storage for output of policy rule   Returns  None,  out  is updated in place to hold the policy function  source:  QuantEcon/src/models/jv.jl:267    get_greedy!(sp::QuantEcon.Models.SearchProblem,  v::Array{T, 2},  out::Array{T, 2})  \u00b6  Extract the greedy policy (policy function) of the model\n.  Arguments   sp::SearchProblem  : Instance of  SearchProblem  v::Matrix : Current guess for the value function  out::Matrix  : Storage for output   Returns  None,  out  is updated in place to hold the policy function  source:  QuantEcon/src/models/odu.jl:193    lucas_operator(lt::QuantEcon.Models.LucasTree,  f::AbstractArray{T, 1})  \u00b6  The approximate Lucas operator, which computes and returns the updated function\nTf on the grid points.  Arguments   lt::LucasTree  : An instance of the  LucasTree  type  f::Vector{Float64}  : A candidate function on R_+ represented as points on a\ngrid. It should be the same size as  lt.grid   Returns   Tf::Vector{Float64}  : The updated function Tf   source:  QuantEcon/src/models/lucastree.jl:142    res_wage_operator!(sp::QuantEcon.Models.SearchProblem,  phi::Array{T, 1},  out::Array{T, 1})  \u00b6  Updates the reservation wage function guess phi via the operator Q.  Arguments   sp::SearchProblem  : Instance of  SearchProblem  phi::Vector : Current guess for phi  out::Vector  : Storage for output   Returns  None,  out  is updated in place to hold the updated levels of phi  source:  QuantEcon/src/models/odu.jl:214    res_wage_operator(sp::QuantEcon.Models.SearchProblem,  phi::Array{T, 1})  \u00b6  Updates the reservation wage function guess phi via the operator Q.  See the documentation for the mutating method of this function for more details\non arguments  source:  QuantEcon/src/models/odu.jl:237    tree_price(ap::QuantEcon.Models.AssetPrices)  \u00b6  Computes the function v such that the price of the lucas tree is v(lambda)C_t  Arguments   ap::AssetPrices  : An instance of the  AssetPrices  type   Returns   v::Vector{Float64}  : the pricing function for the lucas tree   source:  QuantEcon/src/models/asset_pricing.jl:66    QuantEcon.Models.AssetPrices  \u00b6  A class to compute asset prices when the endowment follows a finite Markov chain  Fields   bet::Float64  : Discount factor in (0, 1)  P::Matrix{Float64}  A valid stochastic matrix  s::Vector{Float64}  : Growth rate of consumption in each state  gamma::Float64  : Coefficient of risk aversion  n::Int(size(P, 1)) : The numberof states  P_tilde::Matrix{Float64}  : modified transition matrix used in computing the\nprice of the lucas tree  P_check::Matrix{Float64}  : modified transition matrix used in computing the\nprice of the consol   source:  QuantEcon/src/models/asset_pricing.jl:34    QuantEcon.Models.CareerWorkerProblem  \u00b6  Career/job choice model fo Derek Neal (1999)  Fields   beta::Real  : Discount factor in (0, 1)  N::Int  : Number of possible realizations of both epsilon and theta  B::Real  : upper bound for both epsilon and theta  theta::AbstractVector  : A grid of values on [0, B]  epsilon::AbstractVector  : A grid of values on [0, B]  F_probs::AbstractVector  : The pdf of each value associated with of F  G_probs::AbstractVector  : The pdf of each value associated with of G  F_mean::Real  : The mean of the distribution F  G_mean::Real  : The mean of the distribution G   source:  QuantEcon/src/models/career.jl:33    QuantEcon.Models.ConsumerProblem  \u00b6  Income fluctuation problem  Fields   u::Function  : Utility  function  du::Function  : Marginal utility  function  r::Real  : Strictly positive interest rate  R::Real  : The interest rate plus 1 (strictly greater than 1)  bet::Real  : Discount rate in (0, 1)  b::Real  :  The borrowing constraint  Pi::Matrix  : Transition matrix for  z  z_vals::Vector  : Levels of productivity  asset_grid::AbstractVector  : Grid of asset values   source:  QuantEcon/src/models/ifp.jl:36    QuantEcon.Models.GrowthModel  \u00b6  Neoclassical growth model  Fields   f::Function  : Production function  bet::Real  : Discount factor in (0, 1)  u::Function  : Utility function  grid_max::Int  : Maximum for grid over savings values  grid_size::Int  : Number of points in grid for savings values  grid::FloatRange  : The grid for savings values   source:  QuantEcon/src/models/optgrowth.jl:38    QuantEcon.Models.JvWorker  \u00b6  A Jovanovic-type model of employment with on-the-job search.  The value function is given by  [V(x) = \\max_{\\phi, s} w(x, \\phi, s)]  for  w(x, phi, s) := x(1 - phi - s) + beta (1 - pi(s)) V(G(x, phi)) +\n                beta pi(s) E V[ max(G(x, phi), U)  where   x : : human capital  s  : search effort  phi  : investment in human capital  pi(s)  : probability of new offer given search level s  x(1 - phi - s)  : wage  G(x, phi)  : new human capital when current job retained  U  : Random variable with distribution F -- new draw of human capita   Fields   A::Real  : Parameter in human capital transition function  alpha::Real  : Parameter in human capital transition function  bet::Real  : Discount factor in (0, 1)  x_grid::FloatRange  : Grid for potential levels of x  G::Function  : Transition  function  for human captial  pi_func::Function  :  function  mapping search effort to the probability of\ngetting a new job offer  F::UnivariateDistribution  : A univariate distribution from which the value\nof new job offers is drawn  quad_nodes::Vector  : Quadrature nodes for integrating over phi  quad_weights::Vector  : Quadrature weights for integrating over phi   source:  QuantEcon/src/models/jv.jl:63    QuantEcon.Models.LucasTree  \u00b6  The Lucas asset pricing model  Fields   gam::Real  : coefficient of risk aversion in the CRRA utility function  bet::Real  : Discount factor in (0, 1)  alpha::Real  : Correlation coefficient in the shock process  sigma::Real  : Volatility of shock process  phi::Distribution  : Distribution for shock process  grid::AbstractVector  : Grid of points on which to evaluate the prices. Each\npoint should be non-negative  grid_min::Real  : Lower bound on grid  grid_max::Real  : Upper bound on grid  grid_size::Int  : Number of points in the grid  quad_nodes::Vector  : Quadrature nodes for integrating over the shock  quad_weights::Vector  : Quadrature weights for integrating over the shock  h::Vector  : Storage array for the  h  vector in the lucas operator   source:  QuantEcon/src/models/lucastree.jl:50    QuantEcon.Models.SearchProblem  \u00b6  Unemployment/search problem where offer distribution is unknown  Fields   bet::Real  : Discount factor on (0, 1)  c::Real  : Unemployment compensation  F::Distribution  : Offer distribution  F  G::Distribution  : Offer distribution  G  f::Function  : The pdf of  F  g::Function  : The pdf of  G  n_w::Int  : Number of points on the grid for w  w_max::Real  : Maximum wage offer  w_grid::AbstractVector  : Grid of wage offers w  n_pi::Int  : Number of points on grid for pi  pi_min::Real  : Minimum of pi grid  pi_max::Real  : Maximum of pi grid  pi_grid::AbstractVector  : Grid of probabilities pi  quad_nodes::Vector  : Notes for quadrature ofer offers  quad_weights::Vector  : Weights for quadrature ofer offers   source:  QuantEcon/src/models/odu.jl:40", 
            "title": "Exported"
        }, 
        {
            "location": "/api/QuantEcon.Models/#internal", 
            "text": "call(::Type{QuantEcon.Models.AssetPrices},  bet::Real,  P::Array{T, 2},  s::Array{T, 1},  gamm::Real)  \u00b6  Construct an instance of  AssetPrices , where  n ,  P_tilde , and  P_check  are\ncomputed automatically for you. See also the documentation for the type itself  source:  QuantEcon/src/models/asset_pricing.jl:48    call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real)  \u00b6  Constructor with default values for  CareerWorkerProblem  Arguments   beta::Real(0.95)  : Discount factor in (0, 1)  B::Real(5.0)  : upper bound for both epsilon and theta  N::Real(50)  : Number of possible realizations of both epsilon and theta  F_a::Real(1), F_b::Real(1)  : Parameters of the distribution F  G_a::Real(1), G_b::Real(1)  : Parameters of the distribution F   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/career.jl:60    call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real)  \u00b6  Constructor with default values for  CareerWorkerProblem  Arguments   beta::Real(0.95)  : Discount factor in (0, 1)  B::Real(5.0)  : upper bound for both epsilon and theta  N::Real(50)  : Number of possible realizations of both epsilon and theta  F_a::Real(1), F_b::Real(1)  : Parameters of the distribution F  G_a::Real(1), G_b::Real(1)  : Parameters of the distribution F   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/career.jl:60    call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real)  \u00b6  Constructor with default values for  CareerWorkerProblem  Arguments   beta::Real(0.95)  : Discount factor in (0, 1)  B::Real(5.0)  : upper bound for both epsilon and theta  N::Real(50)  : Number of possible realizations of both epsilon and theta  F_a::Real(1), F_b::Real(1)  : Parameters of the distribution F  G_a::Real(1), G_b::Real(1)  : Parameters of the distribution F   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/career.jl:60    call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real)  \u00b6  Constructor with default values for  CareerWorkerProblem  Arguments   beta::Real(0.95)  : Discount factor in (0, 1)  B::Real(5.0)  : upper bound for both epsilon and theta  N::Real(50)  : Number of possible realizations of both epsilon and theta  F_a::Real(1), F_b::Real(1)  : Parameters of the distribution F  G_a::Real(1), G_b::Real(1)  : Parameters of the distribution F   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/career.jl:60    call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real,  F_b::Real)  \u00b6  Constructor with default values for  CareerWorkerProblem  Arguments   beta::Real(0.95)  : Discount factor in (0, 1)  B::Real(5.0)  : upper bound for both epsilon and theta  N::Real(50)  : Number of possible realizations of both epsilon and theta  F_a::Real(1), F_b::Real(1)  : Parameters of the distribution F  G_a::Real(1), G_b::Real(1)  : Parameters of the distribution F   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/career.jl:60    call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real,  F_b::Real,  G_a::Real)  \u00b6  Constructor with default values for  CareerWorkerProblem  Arguments   beta::Real(0.95)  : Discount factor in (0, 1)  B::Real(5.0)  : upper bound for both epsilon and theta  N::Real(50)  : Number of possible realizations of both epsilon and theta  F_a::Real(1), F_b::Real(1)  : Parameters of the distribution F  G_a::Real(1), G_b::Real(1)  : Parameters of the distribution F   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/career.jl:60    call(::Type{QuantEcon.Models.CareerWorkerProblem},  beta::Real,  B::Real,  N::Real,  F_a::Real,  F_b::Real,  G_a::Real,  G_b::Real)  \u00b6  Constructor with default values for  CareerWorkerProblem  Arguments   beta::Real(0.95)  : Discount factor in (0, 1)  B::Real(5.0)  : upper bound for both epsilon and theta  N::Real(50)  : Number of possible realizations of both epsilon and theta  F_a::Real(1), F_b::Real(1)  : Parameters of the distribution F  G_a::Real(1), G_b::Real(1)  : Parameters of the distribution F   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/career.jl:60    call(::Type{QuantEcon.Models.ConsumerProblem},  r)  \u00b6  Constructor with default values for  ConsumerProblem  Arguments   r::Real(0.01)  : Strictly positive interest rate  bet::Real(0.96)  : Discount rate in (0, 1)  Pi::Matrix{Float64}([0.6 0.4; 0.05 0.95])  : Transition matrix for  z  z_vals::Vector{Float64}([0.5, 1.0])  : Levels of productivity  b::Real(0.0)  : Borrowing constraint  grid_max::Real(16)  : Maximum in grid for asset holdings  grid_size::Int(50)  : Number of points in grid for asset holdings  u::Function(log)  : Utility  function  du::Function(x- 1/x)  : Marginal utility  function   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/ifp.jl:71    call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet)  \u00b6  Constructor with default values for  ConsumerProblem  Arguments   r::Real(0.01)  : Strictly positive interest rate  bet::Real(0.96)  : Discount rate in (0, 1)  Pi::Matrix{Float64}([0.6 0.4; 0.05 0.95])  : Transition matrix for  z  z_vals::Vector{Float64}([0.5, 1.0])  : Levels of productivity  b::Real(0.0)  : Borrowing constraint  grid_max::Real(16)  : Maximum in grid for asset holdings  grid_size::Int(50)  : Number of points in grid for asset holdings  u::Function(log)  : Utility  function  du::Function(x- 1/x)  : Marginal utility  function   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/ifp.jl:71    call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi)  \u00b6  Constructor with default values for  ConsumerProblem  Arguments   r::Real(0.01)  : Strictly positive interest rate  bet::Real(0.96)  : Discount rate in (0, 1)  Pi::Matrix{Float64}([0.6 0.4; 0.05 0.95])  : Transition matrix for  z  z_vals::Vector{Float64}([0.5, 1.0])  : Levels of productivity  b::Real(0.0)  : Borrowing constraint  grid_max::Real(16)  : Maximum in grid for asset holdings  grid_size::Int(50)  : Number of points in grid for asset holdings  u::Function(log)  : Utility  function  du::Function(x- 1/x)  : Marginal utility  function   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/ifp.jl:71    call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals)  \u00b6  Constructor with default values for  ConsumerProblem  Arguments   r::Real(0.01)  : Strictly positive interest rate  bet::Real(0.96)  : Discount rate in (0, 1)  Pi::Matrix{Float64}([0.6 0.4; 0.05 0.95])  : Transition matrix for  z  z_vals::Vector{Float64}([0.5, 1.0])  : Levels of productivity  b::Real(0.0)  : Borrowing constraint  grid_max::Real(16)  : Maximum in grid for asset holdings  grid_size::Int(50)  : Number of points in grid for asset holdings  u::Function(log)  : Utility  function  du::Function(x- 1/x)  : Marginal utility  function   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/ifp.jl:71    call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b)  \u00b6  Constructor with default values for  ConsumerProblem  Arguments   r::Real(0.01)  : Strictly positive interest rate  bet::Real(0.96)  : Discount rate in (0, 1)  Pi::Matrix{Float64}([0.6 0.4; 0.05 0.95])  : Transition matrix for  z  z_vals::Vector{Float64}([0.5, 1.0])  : Levels of productivity  b::Real(0.0)  : Borrowing constraint  grid_max::Real(16)  : Maximum in grid for asset holdings  grid_size::Int(50)  : Number of points in grid for asset holdings  u::Function(log)  : Utility  function  du::Function(x- 1/x)  : Marginal utility  function   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/ifp.jl:71    call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max)  \u00b6  Constructor with default values for  ConsumerProblem  Arguments   r::Real(0.01)  : Strictly positive interest rate  bet::Real(0.96)  : Discount rate in (0, 1)  Pi::Matrix{Float64}([0.6 0.4; 0.05 0.95])  : Transition matrix for  z  z_vals::Vector{Float64}([0.5, 1.0])  : Levels of productivity  b::Real(0.0)  : Borrowing constraint  grid_max::Real(16)  : Maximum in grid for asset holdings  grid_size::Int(50)  : Number of points in grid for asset holdings  u::Function(log)  : Utility  function  du::Function(x- 1/x)  : Marginal utility  function   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/ifp.jl:71    call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max,  grid_size)  \u00b6  Constructor with default values for  ConsumerProblem  Arguments   r::Real(0.01)  : Strictly positive interest rate  bet::Real(0.96)  : Discount rate in (0, 1)  Pi::Matrix{Float64}([0.6 0.4; 0.05 0.95])  : Transition matrix for  z  z_vals::Vector{Float64}([0.5, 1.0])  : Levels of productivity  b::Real(0.0)  : Borrowing constraint  grid_max::Real(16)  : Maximum in grid for asset holdings  grid_size::Int(50)  : Number of points in grid for asset holdings  u::Function(log)  : Utility  function  du::Function(x- 1/x)  : Marginal utility  function   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/ifp.jl:71    call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max,  grid_size,  u)  \u00b6  Constructor with default values for  ConsumerProblem  Arguments   r::Real(0.01)  : Strictly positive interest rate  bet::Real(0.96)  : Discount rate in (0, 1)  Pi::Matrix{Float64}([0.6 0.4; 0.05 0.95])  : Transition matrix for  z  z_vals::Vector{Float64}([0.5, 1.0])  : Levels of productivity  b::Real(0.0)  : Borrowing constraint  grid_max::Real(16)  : Maximum in grid for asset holdings  grid_size::Int(50)  : Number of points in grid for asset holdings  u::Function(log)  : Utility  function  du::Function(x- 1/x)  : Marginal utility  function   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/ifp.jl:71    call(::Type{QuantEcon.Models.ConsumerProblem},  r,  bet,  Pi,  z_vals,  b,  grid_max,  grid_size,  u,  du)  \u00b6  Constructor with default values for  ConsumerProblem  Arguments   r::Real(0.01)  : Strictly positive interest rate  bet::Real(0.96)  : Discount rate in (0, 1)  Pi::Matrix{Float64}([0.6 0.4; 0.05 0.95])  : Transition matrix for  z  z_vals::Vector{Float64}([0.5, 1.0])  : Levels of productivity  b::Real(0.0)  : Borrowing constraint  grid_max::Real(16)  : Maximum in grid for asset holdings  grid_size::Int(50)  : Number of points in grid for asset holdings  u::Function(log)  : Utility  function  du::Function(x- 1/x)  : Marginal utility  function   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/ifp.jl:71    call(::Type{QuantEcon.Models.GrowthModel})  \u00b6  Constructor of  GrowthModel  Arguments   f::Function(k- k^0.65)  : Production function  bet::Real(0.95)  : Discount factor in (0, 1)  u::Function(log)  : Utility function  grid_max::Int(2)  : Maximum for grid over savings values  grid_size::Int(150)  : Number of points in grid for savings values   source:  QuantEcon/src/models/optgrowth.jl:63    call(::Type{QuantEcon.Models.GrowthModel},  f)  \u00b6  Constructor of  GrowthModel  Arguments   f::Function(k- k^0.65)  : Production function  bet::Real(0.95)  : Discount factor in (0, 1)  u::Function(log)  : Utility function  grid_max::Int(2)  : Maximum for grid over savings values  grid_size::Int(150)  : Number of points in grid for savings values   source:  QuantEcon/src/models/optgrowth.jl:63    call(::Type{QuantEcon.Models.GrowthModel},  f,  bet)  \u00b6  Constructor of  GrowthModel  Arguments   f::Function(k- k^0.65)  : Production function  bet::Real(0.95)  : Discount factor in (0, 1)  u::Function(log)  : Utility function  grid_max::Int(2)  : Maximum for grid over savings values  grid_size::Int(150)  : Number of points in grid for savings values   source:  QuantEcon/src/models/optgrowth.jl:63    call(::Type{QuantEcon.Models.GrowthModel},  f,  bet,  u)  \u00b6  Constructor of  GrowthModel  Arguments   f::Function(k- k^0.65)  : Production function  bet::Real(0.95)  : Discount factor in (0, 1)  u::Function(log)  : Utility function  grid_max::Int(2)  : Maximum for grid over savings values  grid_size::Int(150)  : Number of points in grid for savings values   source:  QuantEcon/src/models/optgrowth.jl:63    call(::Type{QuantEcon.Models.GrowthModel},  f,  bet,  u,  grid_max)  \u00b6  Constructor of  GrowthModel  Arguments   f::Function(k- k^0.65)  : Production function  bet::Real(0.95)  : Discount factor in (0, 1)  u::Function(log)  : Utility function  grid_max::Int(2)  : Maximum for grid over savings values  grid_size::Int(150)  : Number of points in grid for savings values   source:  QuantEcon/src/models/optgrowth.jl:63    call(::Type{QuantEcon.Models.GrowthModel},  f,  bet,  u,  grid_max,  grid_size)  \u00b6  Constructor of  GrowthModel  Arguments   f::Function(k- k^0.65)  : Production function  bet::Real(0.95)  : Discount factor in (0, 1)  u::Function(log)  : Utility function  grid_max::Int(2)  : Maximum for grid over savings values  grid_size::Int(150)  : Number of points in grid for savings values   source:  QuantEcon/src/models/optgrowth.jl:63    call(::Type{QuantEcon.Models.JvWorker},  A)  \u00b6  Constructor with default values for  JvWorker  Arguments   A::Real(1.4)  : Parameter in human capital transition function  alpha::Real(0.6)  : Parameter in human capital transition function  bet::Real(0.96)  : Discount factor in (0, 1)  grid_size::Int(50)  : Number of points in discrete grid for  x   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/jv.jl:90    call(::Type{QuantEcon.Models.JvWorker},  A,  alpha)  \u00b6  Constructor with default values for  JvWorker  Arguments   A::Real(1.4)  : Parameter in human capital transition function  alpha::Real(0.6)  : Parameter in human capital transition function  bet::Real(0.96)  : Discount factor in (0, 1)  grid_size::Int(50)  : Number of points in discrete grid for  x   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/jv.jl:90    call(::Type{QuantEcon.Models.JvWorker},  A,  alpha,  bet)  \u00b6  Constructor with default values for  JvWorker  Arguments   A::Real(1.4)  : Parameter in human capital transition function  alpha::Real(0.6)  : Parameter in human capital transition function  bet::Real(0.96)  : Discount factor in (0, 1)  grid_size::Int(50)  : Number of points in discrete grid for  x   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/jv.jl:90    call(::Type{QuantEcon.Models.JvWorker},  A,  alpha,  bet,  grid_size)  \u00b6  Constructor with default values for  JvWorker  Arguments   A::Real(1.4)  : Parameter in human capital transition function  alpha::Real(0.6)  : Parameter in human capital transition function  bet::Real(0.96)  : Discount factor in (0, 1)  grid_size::Int(50)  : Number of points in discrete grid for  x   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/jv.jl:90    call(::Type{QuantEcon.Models.LucasTree},  gam::Real,  bet::Real,  alpha::Real,  sigma::Real)  \u00b6  Constructor for LucasTree  Arguments   gam::Real  : coefficient of risk aversion in the CRRA utility function  bet::Real  : Discount factor in (0, 1)  alpha::Real  : Correlation coefficient in the shock process  sigma::Real  : Volatility of shock process   Notes  All other fields of the type are instantiated within the constructor  source:  QuantEcon/src/models/lucastree.jl:80    call(::Type{QuantEcon.Models.SearchProblem},  bet)  \u00b6  Constructor for  SearchProblem  with default values  Arguments   bet::Real(0.95)  : Discount factor in (0, 1)  c::Real(0.6)  : Unemployment compensation  F_a::Real(1), F_b::Real(1)  : Parameters of  Beta  distribution for  F  G_a::Real(3), G_b::Real(1.2)  : Parameters of  Beta  distribution for  G  w_max::Real(2)  : Maximum of wage offer grid  w_grid_size::Int(40)  : Number of points in wage offer grid  pi_grid_size::Int(40)  : Number of points in probability grid   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/odu.jl:76    call(::Type{QuantEcon.Models.SearchProblem},  bet,  c)  \u00b6  Constructor for  SearchProblem  with default values  Arguments   bet::Real(0.95)  : Discount factor in (0, 1)  c::Real(0.6)  : Unemployment compensation  F_a::Real(1), F_b::Real(1)  : Parameters of  Beta  distribution for  F  G_a::Real(3), G_b::Real(1.2)  : Parameters of  Beta  distribution for  G  w_max::Real(2)  : Maximum of wage offer grid  w_grid_size::Int(40)  : Number of points in wage offer grid  pi_grid_size::Int(40)  : Number of points in probability grid   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/odu.jl:76    call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a)  \u00b6  Constructor for  SearchProblem  with default values  Arguments   bet::Real(0.95)  : Discount factor in (0, 1)  c::Real(0.6)  : Unemployment compensation  F_a::Real(1), F_b::Real(1)  : Parameters of  Beta  distribution for  F  G_a::Real(3), G_b::Real(1.2)  : Parameters of  Beta  distribution for  G  w_max::Real(2)  : Maximum of wage offer grid  w_grid_size::Int(40)  : Number of points in wage offer grid  pi_grid_size::Int(40)  : Number of points in probability grid   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/odu.jl:76    call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b)  \u00b6  Constructor for  SearchProblem  with default values  Arguments   bet::Real(0.95)  : Discount factor in (0, 1)  c::Real(0.6)  : Unemployment compensation  F_a::Real(1), F_b::Real(1)  : Parameters of  Beta  distribution for  F  G_a::Real(3), G_b::Real(1.2)  : Parameters of  Beta  distribution for  G  w_max::Real(2)  : Maximum of wage offer grid  w_grid_size::Int(40)  : Number of points in wage offer grid  pi_grid_size::Int(40)  : Number of points in probability grid   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/odu.jl:76    call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a)  \u00b6  Constructor for  SearchProblem  with default values  Arguments   bet::Real(0.95)  : Discount factor in (0, 1)  c::Real(0.6)  : Unemployment compensation  F_a::Real(1), F_b::Real(1)  : Parameters of  Beta  distribution for  F  G_a::Real(3), G_b::Real(1.2)  : Parameters of  Beta  distribution for  G  w_max::Real(2)  : Maximum of wage offer grid  w_grid_size::Int(40)  : Number of points in wage offer grid  pi_grid_size::Int(40)  : Number of points in probability grid   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/odu.jl:76    call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b)  \u00b6  Constructor for  SearchProblem  with default values  Arguments   bet::Real(0.95)  : Discount factor in (0, 1)  c::Real(0.6)  : Unemployment compensation  F_a::Real(1), F_b::Real(1)  : Parameters of  Beta  distribution for  F  G_a::Real(3), G_b::Real(1.2)  : Parameters of  Beta  distribution for  G  w_max::Real(2)  : Maximum of wage offer grid  w_grid_size::Int(40)  : Number of points in wage offer grid  pi_grid_size::Int(40)  : Number of points in probability grid   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/odu.jl:76    call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b,  w_max)  \u00b6  Constructor for  SearchProblem  with default values  Arguments   bet::Real(0.95)  : Discount factor in (0, 1)  c::Real(0.6)  : Unemployment compensation  F_a::Real(1), F_b::Real(1)  : Parameters of  Beta  distribution for  F  G_a::Real(3), G_b::Real(1.2)  : Parameters of  Beta  distribution for  G  w_max::Real(2)  : Maximum of wage offer grid  w_grid_size::Int(40)  : Number of points in wage offer grid  pi_grid_size::Int(40)  : Number of points in probability grid   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/odu.jl:76    call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b,  w_max,  w_grid_size)  \u00b6  Constructor for  SearchProblem  with default values  Arguments   bet::Real(0.95)  : Discount factor in (0, 1)  c::Real(0.6)  : Unemployment compensation  F_a::Real(1), F_b::Real(1)  : Parameters of  Beta  distribution for  F  G_a::Real(3), G_b::Real(1.2)  : Parameters of  Beta  distribution for  G  w_max::Real(2)  : Maximum of wage offer grid  w_grid_size::Int(40)  : Number of points in wage offer grid  pi_grid_size::Int(40)  : Number of points in probability grid   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/odu.jl:76    call(::Type{QuantEcon.Models.SearchProblem},  bet,  c,  F_a,  F_b,  G_a,  G_b,  w_max,  w_grid_size,  pi_grid_size)  \u00b6  Constructor for  SearchProblem  with default values  Arguments   bet::Real(0.95)  : Discount factor in (0, 1)  c::Real(0.6)  : Unemployment compensation  F_a::Real(1), F_b::Real(1)  : Parameters of  Beta  distribution for  F  G_a::Real(3), G_b::Real(1.2)  : Parameters of  Beta  distribution for  G  w_max::Real(2)  : Maximum of wage offer grid  w_grid_size::Int(40)  : Number of points in wage offer grid  pi_grid_size::Int(40)  : Number of points in probability grid   Notes  There is also a version of this function that accepts keyword arguments for\neach parameter  source:  QuantEcon/src/models/odu.jl:76    default_du{T :Real}(x::T :Real)  \u00b6  Marginal utility for log utility function  source:  QuantEcon/src/models/ifp.jl:49", 
            "title": "Internal"
        }
    ]
}